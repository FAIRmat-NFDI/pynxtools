{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc36981-1bd8-4621-bb1c-e80bf4983fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterlab_h5web import H5Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d473dc-6984-4a1e-be28-083f88ef7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "a = struct.pack('I', 0x04034b50)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a4fc9d-a51d-4b96-aa9f-bf540034c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5Web(\"jsmap.nxs\")\n",
    "H5Web(\"SuperScan (HADF).nxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6335a8-28d0-4755-b84c-b1a1552bb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af10a1-65a7-4d64-9f97-69c2df7eb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(\"2022-02-18_Metadata_Kuehbach.nsproj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df86fc-8c03-4c7e-b58e-148d78a260e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import flatdict as fd\n",
    "file_name = \"2022-02-18_Metadata_Kuehbach.nsproj\"\n",
    "with open(file_name, 'r') as stream:\n",
    "    yml = fd.FlatDict(yaml.safe_load(stream), delimiter='/')\n",
    "    for serialized_path in yml.keys():\n",
    "        print(f\"{serialized_path}\\t\\t\\t{yml[serialized_path]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b31cad-33d2-4156-99fd-9b40d9d92cc8",
   "metadata": {},
   "source": [
    "1. Load nsproj walk display_items and compute data_alphabet_value check if such files exist\n",
    "2. For each such file perform the mapping into an own NXevent_data_em instance\n",
    "   For the H5 read attribute try to figure out what conceptually the item is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0f955-95a1-4ef7-b581-784a4ef291b2",
   "metadata": {},
   "source": [
    "Reproducibly recover the uuid management choices from ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc921d-18f5-4321-b5c7-ae8bfb3609d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def encode(uuid_: uuid.UUID, alphabet: str) -> str:\n",
    "    result = str()\n",
    "    uuid_int = uuid_.int\n",
    "    while uuid_int:\n",
    "        uuid_int, digit = divmod(uuid_int, len(alphabet))\n",
    "        result += alphabet[digit]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1d9b7-f93a-4ee7-befd-b6730e54f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_uuid_str = \"e4900934-9332-4706-94cc-6fbe989647d9\"\n",
    "data_item_uuid_str = \"72f1cda3-dea5-4a1b-bb85-ee34d5009860\"\n",
    "data_item_uuid_str = \"8506c02c-8ba8-48ef-b22f-5e2878abe2d9\"\n",
    "data_item_uuid_str = \"b753bea8-2526-4770-875d-52a262c3d9c4\"\n",
    "data_item_uuid_str = \"7e19bb9e-78a5-4d1c-8bd3-b60e6cebae42\"\n",
    "# data_item_uuid_str = \"9c48aa2a-c910-4200-a625-0f01a09a3578\"\n",
    "data_item_uuid_uuid = uuid.UUID(f'{data_item_uuid_str}')\n",
    "print(f'data_{encode(data_item_uuid_uuid, \"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\")}')  # 25 character results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586fdf0-ada9-42b6-a02d-f56075f5c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5Web(\"data_7EPPSHNUFKH6F6A4JCR45J03G.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd737cf-3092-4884-a48a-0343ba581473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "fnm = \"data_7EPPSHNUFKH6F6A4JCR45J03G.h5\"\n",
    "# fnm = \"data_O4W29EVTX4DPTR33VRYHLI2QH.h5\"\n",
    "# fnm = \"data_24ZGOFFSF7NVOP322TBCKF0YF.h5\"\n",
    "h5r = h5py.File(fnm, \"r\")\n",
    "metadata = h5r[\"data\"].attrs[\"properties\"]\n",
    "print(type(metadata))\n",
    "h5r.close()\n",
    "# with open(\"data_7EPPSHNUFKH6F6A4JCR45J03G.h5.metadata.json\", \"w\") as f:\n",
    "#     f.write(metadata)\n",
    "import json\n",
    "print(type(metadata))\n",
    "json_object = json.loads(metadata)\n",
    "print(type(json_object))\n",
    "with open(f\"{fnm}.metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ff92d-b56d-47af-9f97-bd6ae754f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1fb97-1d3b-4ecf-8c2c-5e5e97a3daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5Web(fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7dc63-97bf-4d60-8b0c-322d544116cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, value in enumerate([0], start=1):\n",
    "    print(count, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65580cd-ad6a-427a-a23b-98bf0b5b9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = []\n",
    "not new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582fbe1-75f0-4595-88ec-23c13b03eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatdict as fd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# file://///wsl.localhost/Ubuntu/home/mkuehbach/SPRINT-8/nexus_code_camp_2022/parser-nexus/nexusparser/tools/yaml2nxdl/sprint9_update_nx_em/test_manual_building/nexus_definitions/build/manual/build/html/classes/contributed_definitions/NXem.html#nxem\n",
    "\n",
    "# https://stackoverflow.com/questions/3663450/remove-substring-only-at-the-end-of-string\n",
    "def rchop(s, suffix):\n",
    "    if suffix and s.endswith(suffix):\n",
    "        return s[:-len(suffix)]\n",
    "    return s\n",
    "\n",
    "# import metadata from nionswift json file\n",
    "wkdir = os.getcwd()\n",
    "file_names = [\n",
    "    \"MultiAcquire (Dectris ELA) #1.json\",\n",
    "    \"MultiAcquire (HADF) #1.json\",\n",
    "    \"Recording of SuperScan (BF).json\",\n",
    "    \"Recording of SuperScan (HADF).json\",\n",
    "    \"RonchiCam1.json\",\n",
    "    \"RonchiCam2.json\",\n",
    "    \"Spectrum Image EELS.json\",\n",
    "    \"Spectrum Image HADF.json\",\n",
    "    \"SuperScan (BF).json\",\n",
    "    \"SuperScan (HADF).json\",\n",
    "    \"SuperScan (MADF).json\"\n",
    "    ]\n",
    "file_names = [\"HAADF_01.json\"]\n",
    "# file_names = [f\"{fnm}.metadata.json\"]\n",
    "\n",
    "# first of all create a global namespace of all keywords\n",
    "nion_path_id = 1\n",
    "all_uniq_path_to_id = {}\n",
    "all_uniq_id_to_path = {}\n",
    "\n",
    "for f in file_names:\n",
    "    file_name = f\"{wkdir}/{f}\"\n",
    "    print(file_name)\n",
    "\n",
    "    with open(file_name, 'r') as stream:\n",
    "        yml = fd.FlatDict(yaml.safe_load(stream), delimiter='/')\n",
    "\n",
    "    for serialized_path in yml.keys():\n",
    "        print(f\"{serialized_path}\\t\\t\\t{yml[serialized_path]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475f64a-f433-44c5-a314-94c786efc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # nionswift metadata have the subtility that some paths have lists as values\n",
    "    # which contain again dictionaries of the next deeper layer with metadata\n",
    "    # these we also would like to flatten\n",
    "    # nion_path_id = 1\n",
    "    # ns_uniq_path_to_id = {}\n",
    "    # ns_uniq_id_to_path = {}\n",
    "    for path in yml.keys():\n",
    "        prefix = path\n",
    "        if isinstance(yml[prefix], list):\n",
    "            only_dicts = True\n",
    "            for obj in yml[prefix]:\n",
    "                if type(obj) is not dict:\n",
    "                    only_dicts = False\n",
    "                # all obj have to be tested\n",
    "\n",
    "            if only_dicts is True:\n",
    "                for obj in yml[prefix]:\n",
    "                    flat = fd.FlatDict(obj, delimiter='/')\n",
    "                    for key, val in flat.items():\n",
    "                        keyword = prefix + '/' + key\n",
    "                        value = val\n",
    "                        if keyword not in all_uniq_path_to_id.keys():\n",
    "                            all_uniq_path_to_id[keyword] = (nion_path_id, file_name)\n",
    "                            # ns_uniq_path_to_id[keyword] = (nion_path_id, value)\n",
    "                            # ns_uniq_id_to_path[nion_path_id] = (keyword, value)\n",
    "                            nion_path_id += 1\n",
    "        # else:\n",
    "        keyword = path\n",
    "        value = yml[path]\n",
    "        if keyword not in all_uniq_path_to_id.keys():\n",
    "            all_uniq_path_to_id[keyword] = (nion_path_id, file_name)\n",
    "            # ns_uniq_path_to_id[keyword] = (nion_path_id, value)\n",
    "            # ns_uniq_id_to_path[nion_path_id] = (keyword, value)\n",
    "            nion_path_id += 1\n",
    "\n",
    "    # next file\n",
    "\n",
    "# create a table for pandas to export to excel/odfpy\n",
    "nion_path_id = []\n",
    "nion_path_name = []\n",
    "nion_path_file = []\n",
    "for key, val in all_uniq_path_to_id.items():\n",
    "    nion_path_id.append(val[0])\n",
    "    nion_path_name.append(key)\n",
    "    nion_path_file.append(val[1])\n",
    "\n",
    "df_ns = pd.DataFrame(\n",
    "    {'nion_path_id_nionswift': nion_path_id,\n",
    "     'flattened_path_in_nionswift.json': nion_path_name})\n",
    "df_ns = df_ns.sort_values(by=['flattened_path_in_nionswift.json'])\n",
    "# 'file_name first found': c})\n",
    "\n",
    "# remove temporary variables # all_uniq_id_to_path\n",
    "variables = [\n",
    "    file_name, file_names, flat, key, keyword, nion_path_file,\\\n",
    "    nion_path_id, nion_path_name, nx_em_id_to_path, nx_em_path_id, \\\n",
    "    nx_em_path_name, nx_em_path_to_id, obj, only_dicts, \\\n",
    "    path, prefix, serialized_path, stream, val, value]\n",
    "for i in variables:\n",
    "    del i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
