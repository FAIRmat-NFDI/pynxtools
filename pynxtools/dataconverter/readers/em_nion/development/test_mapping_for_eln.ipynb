{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862760e-3e3a-4b7e-9878-55088ce17c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import flatdict as fd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a219c-8587-4f85-bd8a-9627dbb5c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"eln_data.yaml\"\n",
    "with open(file_name, \"r\", encoding=\"utf-8\") as stream:\n",
    "    yml = fd.FlatDict(yaml.safe_load(stream), delimiter=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13a07b-ee84-4070-b644-aa8e2843610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in yml.items():\n",
    "    print(f\"{key}, {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847df55-534d-47f9-874e-db408d25e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "yml[\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31dfe23-2092-4554-bf34-f126d5b0b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"user\" in yml.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b034a7a4-5b43-42db-bf89-ee7f18c97b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"user\" in yml.keys()\n",
    "#isinstance(yml[\"user\"], list)\n",
    "#(all(isinstance(entry, dict) for entry in yml[\"user\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67be75-0a3e-46e1-9033-883d22788a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dct in yml[\"user\"]:\n",
    "    print(f\"{dct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654bd96-8b18-453d-92d6-e71b6f11edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NxSample = {\"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"sample/atom_types\"},\n",
    "            \"/ENTRY[entry*]/sample/description\": {\"fun\": \"load_from\", \"terms\": \"sample/description\"},\n",
    "            \"/ENTRY[entry*]/sample/method\": {\"fun\": \"load_from\", \"terms\": \"sample/method\"},\n",
    "            \"/ENTRY[entry*]/sample/name\": {\"fun\": \"load_from\", \"terms\": \"sample/name\"},\n",
    "            \"/ENTRY[entry*]/sample/preparation_date\": {\"fun\": \"load_from\", \"terms\": \"sample/preparation_date\"},\n",
    "            \"/ENTRY[entry*]/sample/sample_history\": {\"fun\": \"load_from\", \"terms\": \"sample/sample_history\"},\n",
    "            \"/ENTRY[entry*]/sample/short_title\": {\"fun\": \"load_from\", \"terms\": \"sample/short_title\"},\n",
    "            \"/ENTRY[entry*]/sample/thickness\": {\"fun\": \"load_from\", \"terms\": \"sample/thickness/unit\"},\n",
    "            \"/ENTRY[entry*]/sample/thickness/@units\": {\"fun\": \"load_from\", \"terms\": \"sample/thickness/value\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495df6ad-6cbc-464c-a547-58ff2795a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def load_from_modifier(terms, fd_dct):\n",
    "    \"\"\"Implement modifier which reads values of different type from fd_dct.\"\"\"\n",
    "    if isinstance(terms, str):\n",
    "        if terms in fd_dct.keys():\n",
    "            return fd_dct[terms]\n",
    "    if all(isinstance(entry, str) for entry in terms) is True:\n",
    "        if isinstance(terms, list):\n",
    "            lst = []\n",
    "            for entry in terms:\n",
    "                lst.append(fd_dct[entry])\n",
    "            return lst\n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_iso8601_modifier(terms, dct: dict):\n",
    "    \"\"\"Implement modifier which transforms nionswift time stamps to proper UTC ISO8601.\"\"\"\n",
    "    if terms is not None:\n",
    "        if isinstance(terms, str):\n",
    "            if terms in dct.keys():\n",
    "                return None\n",
    "        elif (isinstance(terms, list)) and (len(terms) == 2) \\\n",
    "                and (all(isinstance(entry, str) for entry in terms) is True):\n",
    "            # assume the first argument is a local time\n",
    "            # assume the second argument is a timezone string\n",
    "            if terms[0] in dct.keys() and terms[1] in dct.keys():\n",
    "                # handle the case that these times can be arbitrarily formatted\n",
    "                # for now we let ourselves be guided\n",
    "                # by how time stamps are returned in Christoph Koch's\n",
    "                # nionswift instances also formatting-wise\n",
    "                date_time_str = dct[terms[0]].replace(\"T\", \" \")\n",
    "                time_zone_str = dct[terms[1]]\n",
    "                if time_zone_str in pytz.all_timezones:\n",
    "                    date_time_obj \\\n",
    "                        = datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "                    utc_time_zone_aware \\\n",
    "                        = pytz.timezone(time_zone_str).localize(date_time_obj)\n",
    "                    return utc_time_zone_aware\n",
    "                else:\n",
    "                    raise ValueError('Invalid timezone string!')\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def apply_modifier(modifier, dct: dict):\n",
    "    \"\"\"Interpret a functional mapping using data from dct via calling modifiers.\"\"\"\n",
    "    if isinstance(modifier, dict):\n",
    "        # different commands are available\n",
    "        if set([\"fun\", \"terms\"]) == set(modifier.keys()):\n",
    "            if modifier[\"fun\"] == \"load_from\":\n",
    "                return load_from_modifier(modifier[\"terms\"], dct)\n",
    "            if modifier[\"fun\"] == \"convert_iso8601\":\n",
    "                return convert_iso8601_modifier(modifier[\"terms\"], dct)\n",
    "        elif set([\"link\"]) == set(modifier.keys()):\n",
    "            # CURRENTLY NOT IMPLEMENTED\n",
    "            # with the jsonmap reader Sherjeel conceptualized \"link\"\n",
    "            return None\n",
    "        else:\n",
    "            return None\n",
    "    if isinstance(modifier, str):\n",
    "        return modifier\n",
    "    return None\n",
    "\n",
    "\n",
    "# examples/tests how to use modifiers\n",
    "# modd = \"Âµs\"\n",
    "# modd = {\"link\": \"some_link_to_somewhere\"}\n",
    "# modd = {\"fun\": \"load_from\", \"terms\": \"metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 11\"}\n",
    "# modd = {\"fun\": \"load_from\", \"terms\": [\"metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 11\",\n",
    "#     \"metadata/scan/scan_device_properties/mag_boards/MagBoard 1 Relay\"]}\n",
    "# modd = {\"fun\": \"convert_iso8601\", \"terms\": [\"data_modified\", \"timezone\"]}\n",
    "# print(apply_modifier(modd, yml))\n",
    "\n",
    "def variadic_path_to_specific_path(path: str, instance_identifier: list):\n",
    "    \"\"\"Transforms a variadic path to an actual path with instances.\"\"\"\n",
    "    if (path is not None) and (path != \"\"):\n",
    "        narguments = path.count(\"*\")\n",
    "        if narguments == 0:  # path is not variadic\n",
    "            return path\n",
    "        if len(instance_identifier) >= narguments:\n",
    "            tmp = path.split(\"*\")\n",
    "            if len(tmp) == narguments + 1:\n",
    "                nx_specific_path = \"\"\n",
    "                for idx in range(0, narguments):\n",
    "                    nx_specific_path += f\"{tmp[idx]}{instance_identifier[idx]}\"\n",
    "                    idx += 1\n",
    "                nx_specific_path += f\"{tmp[-1]}\"\n",
    "                return nx_specific_path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e90549-c405-4fa2-8514-28136190f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import flatdict as fd\n",
    "import yaml\n",
    "from ase.data import chemical_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d965e5-5014-4aed-9074-fa07c17620b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_id = 1\n",
    "template = {}\n",
    "src = \"sample/atom_types\"\n",
    "trg = f\"/ENTRY[entry{entry_id}]/{src}\"\n",
    "if \"sample/atom_types\" in yml.keys():\n",
    "    if (isinstance(yml[src], list)) and (len(yml[src]) >= 1):\n",
    "        atom_types_are_valid = True\n",
    "        for symbol in yml[src]:\n",
    "            valid = isinstance(symbol, str) \\\n",
    "                and (symbol in chemical_symbols) and (symbol != \"X\")\n",
    "            if valid is False:\n",
    "                atom_types_are_valid = False\n",
    "                break\n",
    "        if atom_types_are_valid is True:\n",
    "            template[trg] = \", \".join(list(yml[src]))\n",
    "\n",
    "for nx_path, modifier in NxSample.items():\n",
    "    print(f\"{nx_path}, {modifier}\")\n",
    "    if (nx_path != \"IGNORE\") and (nx_path != \"UNCLEAR\"):\n",
    "        trg = variadic_path_to_specific_path(nx_path, [entry_id])\n",
    "        print(trg)\n",
    "        res = apply_modifier(modifier, yml)\n",
    "        print(res)\n",
    "        if res is not None:\n",
    "            template[trg] = res\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc71476-0d35-468a-a5b1-15e095521103",
   "metadata": {},
   "outputs": [],
   "source": [
    "NxUserFromListOfDict = {\"/ENTRY[entry*]/USER[user*]/name\": {\"fun\": \"load_from\", \"terms\": \"name\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/affiliation\": {\"fun\": \"load_from\", \"terms\": \"affiliation\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/address\": {\"fun\": \"load_from\", \"terms\": \"address\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/email\": {\"fun\": \"load_from\", \"terms\": \"email\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/orcid\": {\"fun\": \"load_from\", \"terms\": \"orcid\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/orcid_platform\": {\"fun\": \"load_from\", \"terms\": \"orcid_platform\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/telephone_number\": {\"fun\": \"load_from\", \"terms\": \"telephone_number\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/role\": {\"fun\": \"load_from\", \"terms\": \"role\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/social_media_name\": {\"fun\": \"load_from\", \"terms\": \"social_media_name\"},\n",
    "                        \"/ENTRY[entry*]/USER[user*]/social_media_platform\": {\"fun\": \"load_from\", \"terms\": \"social_media_platform\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7c758-8b3f-4ae5-a8fa-a5a88221c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_id = 1\n",
    "template = {}\n",
    "if \"user\" in yml.keys():\n",
    "    if isinstance(yml[\"user\"], list):\n",
    "        if (all(isinstance(entry, dict) for entry in yml[\"user\"]) is True):\n",
    "            user_id = 1\n",
    "            # custom schema delivers a list of dictionaries...\n",
    "            for user_dict in yml[\"user\"]:\n",
    "                # ... for each of them inspect for fields mappable on NeXus\n",
    "                identifier = [entry_id, user_id]\n",
    "                # identifier to get instance NeXus path from variadic NeXus path\n",
    "                # try to find all quantities on the left-hand side of the mapping\n",
    "                # table and check if we can find these\n",
    "                for nx_path, modifier in NxUserFromListOfDict.items():\n",
    "                    if (nx_path != \"IGNORE\") and (nx_path != \"UNCLEAR\"):\n",
    "                        trg = variadic_path_to_specific_path(nx_path, identifier)\n",
    "                        res = apply_modifier(modifier, user_dict)\n",
    "                        if res is not None:\n",
    "                            template[trg] = res\n",
    "                user_id += 1\n",
    "for key, val in template.items():\n",
    "    print(f\"{key}, {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63353f3d-12b1-49f5-a5e4-c7170263360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NxEmElnInput = {\"IGNORE\": {\"fun\": \"load_from_dict_list\", \"terms\": \"em_lab/detector\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/ebeam_column/aberration_correction/applied\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from_dict_list\", \"terms\": \"em_lab/ebeam_column/aperture_em\"},\n",
    "                \"/ENTRY[entry*]/em_lab/EBEAM_COLUMN[ebeam_column]/electron_source/emitter_type\": {\"fun\": \"load_from\", \"terms\": \"em_lab/ebeam_column/electron_gun/emitter_type\"},\n",
    "                \"/ENTRY[entry*]/em_lab/EBEAM_COLUMN[ebeam_column]/electron_source/voltage/@units\": {\"fun\": \"load_from\", \"terms\": \"em_lab/ebeam_column/electron_gun/voltage/unit\"},\n",
    "                \"/ENTRY[entry*]/em_lab/EBEAM_COLUMN[ebeam_column]/electron_source/voltage\": {\"fun\": \"load_from\", \"terms\": \"em_lab/ebeam_column/electron_gun/voltage/value\"},\n",
    "                \"/ENTRY[entry*]/em_lab/FABRICATION[fabrication]/capabilities\": {\"fun\": \"load_from\", \"terms\": \"em_lab/fabrication/capabilities\"},\n",
    "                \"/ENTRY[entry*]/em_lab/FABRICATION[fabrication]/identifier\": {\"fun\": \"load_from\", \"terms\": \"em_lab/fabrication/identifier\"},\n",
    "                \"/ENTRY[entry*]/em_lab/FABRICATION[fabrication]/model\": {\"fun\": \"load_from\", \"terms\": \"em_lab/fabrication/model\"},\n",
    "                \"/ENTRY[entry*]/em_lab/FABRICATION[fabrication]/vendor\": {\"fun\": \"load_from\", \"terms\": \"em_lab/fabrication/vendor\"},\n",
    "                \"/ENTRY[entry*]/em_lab/instrument_name\": {\"fun\": \"load_from\", \"terms\": \"em_lab/instrument_name\"},\n",
    "                \"/ENTRY[entry*]/em_lab/location\": {\"fun\": \"load_from\", \"terms\": \"em_lab/location\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/optical_system_em/beam_current/unit\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/optical_system_em/beam_current/value\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/optical_system_em/beam_current_description\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/optical_system_em/magnification\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/optical_system_em/semi_convergence_angle/unit\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from\", \"terms\": \"em_lab/optical_system_em/semi_convergence_angle/value\"},\n",
    "                \"/ENTRY[entry*]/em_lab/stage_lab/description\": {\"fun\": \"load_from\", \"terms\": \"em_lab/stage_lab/description\"},\n",
    "                \"/ENTRY[entry*]/em_lab/stage_lab/name\": {\"fun\": \"load_from\", \"terms\": \"em_lab/stage_lab/name\"},\n",
    "                \"/ENTRY[entry*]/@version\": {\"fun\": \"load_from\", \"terms\": \"entry/attr_version\"},\n",
    "                \"/ENTRY[entry*]/definition\": {\"fun\": \"load_from\", \"terms\": \"entry/definition\"},\n",
    "                \"/ENTRY[entry*]/end_time\": {\"fun\": \"load_from\", \"terms\": \"entry/end_time\"},\n",
    "                \"/ENTRY[entry*]/experiment_description\": {\"fun\": \"load_from\", \"terms\": \"entry/experiment_description\"},\n",
    "                \"/ENTRY[entry*]/experiment_identifier\": {\"fun\": \"load_from\", \"terms\": \"entry/experiment_identifier\"},\n",
    "                \"/ENTRY[entry*]/PROGRAM[program*]/program\": {\"fun\": \"load_from\", \"terms\": \"entry/program\"},\n",
    "                \"/ENTRY[entry*]/PROGRAM[program*]/program/@version\": {\"fun\": \"load_from\", \"terms\": \"entry/program__attr_version\"},\n",
    "                \"/ENTRY[entry*]/start_time\": {\"fun\": \"load_from\", \"terms\": \"entry/start_time\"},\n",
    "                \"IGNORE\": {\"fun\": \"load_from_list_of_dict\", \"terms\": \"user\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd68b61b-6c38-479b-b297-6bb7eb1c18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_id = 1\n",
    "template = {}\n",
    "for nx_path, modifier in NxEmElnInput.items():\n",
    "    if (nx_path != \"IGNORE\") and (nx_path != \"UNCLEAR\"):\n",
    "        trg = variadic_path_to_specific_path(nx_path, [entry_id, 1])\n",
    "        res = apply_modifier(modifier, yml)\n",
    "        if res is not None:\n",
    "            template[trg] = res\n",
    "\n",
    "for key, val in template.items():\n",
    "    print(f\"{key}, {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275913b7-469c-4de7-9603-5df71ab60054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
