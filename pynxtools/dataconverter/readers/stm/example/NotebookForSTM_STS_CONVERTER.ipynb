{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd4e9ca-7618-4262-989b-53ccc4ebdac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/readers/stm/example\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d84b47-8f66-4a3e-821c-306e47f5039f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# STM ot SXM file\n",
    "\n",
    "!dataconverter \\\n",
    "--reader stm \\\n",
    "--nxdl NXiv_sweep2 \\\n",
    "--input-file TiSe2_2303a_annealing_300C_5min_evaporate_Pyrene_1_0070.sxm \\\n",
    "--input-file ../config_file_for_sxm.json \\\n",
    "--input-file ./Nanonis_Eln.yaml \\\n",
    "--output final_stm_dev_.nxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ed042e-0bbf-4299-aa71-c6269e0acc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stm reader to convert the given files:  \n",
      "• ./221122_Au_5K00014_from_Palma_team.dat\n",
      "• ../config_file_for_dat.json\n",
      "• Nanonis_Eln.yaml \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/.pyenv_3_10/bin/dataconverter\", line 8, in <module>\n",
      "    sys.exit(convert_cli())\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/.pyenv_3_10/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/.pyenv_3_10/lib/python3.10/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/.pyenv_3_10/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/.pyenv_3_10/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/convert.py\", line 202, in convert_cli\n",
      "    convert(input_file, reader, nxdl, output, generate_template, fair)\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/convert.py\", line 110, in convert\n",
      "    data = data_reader().read(  # type: ignore[operator]\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/readers/stm/reader.py\", line 131, in read\n",
      "    from_dat_file_into_template(template, dat_file, config_dict,\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/readers/stm/bias_spec_file_parser.py\", line 424, in from_dat_file_into_template\n",
      "    construct_nxdata_for_dat(template, flattened_dict,\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/readers/stm/bias_spec_file_parser.py\", line 389, in construct_nxdata_for_dat\n",
      "    indivisual_DATA_field()\n",
      "  File \"/home/rubel/NOMAD-FAIRmat/GH/pynxtools/pynxtools/dataconverter/readers/stm/bias_spec_file_parser.py\", line 318, in indivisual_DATA_field\n",
      "    axes_data.append(data_dict[path])\n",
      "KeyError: '/dat_mat_components/Bias/value'\n"
     ]
    }
   ],
   "source": [
    "!dataconverter \\\n",
    "--reader stm \\\n",
    "--nxdl NXiv_sweep2 \\\n",
    "--input-file ./221122_Au_5K00014_from_Palma_team.dat \\\n",
    "--input-file ../config_file_for_dat.json \\\n",
    "--input-file Nanonis_Eln.yaml \\\n",
    "--output ./final_sts_dev.nxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ca83a-488a-4587-a39a-9094f3bb505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To user definied data analysis\n",
    "\n",
    "def process_data_from_file_(flattened_dict):\n",
    "    \"\"\"Implement this function later.\n",
    "        TODO:\n",
    "        This functions mainly intended for automization of data manipulation\n",
    "         or data driven analytics. Try it out later.\n",
    "    \"\"\"\n",
    "    # This keys are collected from flatten_dict generated in\n",
    "    # nested_path_to_slash_separated_path()\n",
    "\n",
    "    # key_data_to_be_processed = {'0': {'/Bias/value': None,\n",
    "    #                                   '/Current/value': None}}\n",
    "\n",
    "    # for fla_key, fla_val in flattened_dict.items():\n",
    "    #     for pro_key, pro_val in key_data_to_be_processed.items():\n",
    "    #         for ele_key, ele_val in pro_val.items():\n",
    "    #             if ele_key in fla_key:\n",
    "    #                 pro_val[ele_key] = fla_val\n",
    "\n",
    "    # nx_data_info_dict = {'0': {'nx_data_group_name': '(Normal)',\n",
    "    #                         'nx_data_group_axes': ['Bias', 'dI/dV'],\n",
    "    #                         'action': [slice_before_last_element, cal_dx_by_dy],\n",
    "    #                         'action_variable':\n",
    "    #                         [[key_data_to_be_processed['0']['/Bias/value']],\n",
    "    #                         [key_data_to_be_processed['0']['/Current/value'],\n",
    "    #                             key_data_to_be_processed['0']['/Bias/value']]],\n",
    "    #                         'action_result': []}}\n",
    "\n",
    "    # # TODO: add the print optionality for flattend dict option inside bias_spec_data_parser.py\n",
    "    # later add this option inside README doc\n",
    "    # with open('./dict_from_dat_file.txt', mode='+w', encoding='utf-8',) as fl:\n",
    "    #     for key, val in flattened_dict.items():\n",
    "    #         print('## val', key)\n",
    "    #         fl.write(f\"{key} : ##### {val}\\n\")\n",
    "    # 0, 1,\n",
    "    # print('key_data_to_be_processed', key_data_to_be_processed)\n",
    "    # for key in key_data_to_be_processed.keys():\n",
    "    #     key_dict = nx_data_info_dict[key]\n",
    "    #     for action, action_variable in zip(key_dict['action'], key_dict['action_variable']):\n",
    "    #         key_dict['action_result'].append(action(*action_variable))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfd08d-febb-4d84-b8e6-0416db52439f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7888de-9587-4e2a-ab96-eaf87b436029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
