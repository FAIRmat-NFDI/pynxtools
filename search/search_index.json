{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to the FAIRmat NeXus documentation","text":"<p>Within FAIRmat, we are extending the NeXus data format standard to support the FAIR principles for experimental data in materials science.</p> <p>This documentation covers our contributions to the NeXus standard, and our supporting software tool, <code>pynxtools</code>. <code>pynxtools</code> maps data and metadata from diverse instruments and electronic lab notebooks (ELNs) into NeXus-compliant HDF5 files. It supports parsing, normalization, visualization, and ontology matching.</p> <p><code>pynxtools</code> offers scientists a convenient way to use the NeXus format and solves the challenge of unstructured and non-standardized data in experimental materials science. </p> <p>The software can also be used as a plugin in the research data management system NOMAD, an open-source platform for FAIR materials data management. Learn more in the NOMAD documentation.</p> <p>We are offering a small guide to getting started with NeXus, <code>pynxtools</code>, and NOMAD:</p> <ul> <li>Getting started</li> </ul>  Contact  <p>For questions or suggestions:</p> <ul> <li>Open an issue on the <code>pynxtools</code> GitHub</li> <li>Join our Discord channel </li> <li>Get in contact with our lead developers.</li> </ul> Project and community <p>The work is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 460197019 (FAIRmat).</p>"},{"location":"index.html#tutorial","title":"Tutorial","text":"<ul> <li>Installation guide</li> <li>Converting your research data to NeXus</li> <li>Uploading NeXus data to NOMAD</li> <li>Development guide</li> </ul>"},{"location":"index.html#how-to-guides","title":"How-to guides","text":""},{"location":"index.html#nexus-data-modelling","title":"NeXus data modelling","text":"<ul> <li>Writing an application definition</li> </ul>"},{"location":"index.html#pynxtools","title":"pynxtools","text":"<ul> <li>Build your own <code>pynxtools</code> plugin</li> <li>How to use the built-in <code>MultiFormatReader</code></li> <li>Test functionality for <code>pynxtools</code> plugins</li> <li>Running <code>pynxtools</code> tests in parallel</li> <li>Using Python to create NeXus files</li> <li>Validation of NeXus files</li> </ul>"},{"location":"index.html#learn","title":"Learn","text":""},{"location":"index.html#an-introduction-to-nexus-and-its-design-principles","title":"An introduction to NeXus and its design principles","text":"<ul> <li>A primer on NeXus</li> <li>Rules for storing data in NeXus</li> </ul>"},{"location":"index.html#pynxtools_1","title":"pynxtools","text":"<ul> <li>Data conversion in <code>pynxtools</code></li> <li>Validation of NeXus files</li> <li>The <code>MultiFormatReader</code> as a reader superclass</li> </ul>"},{"location":"index.html#reference","title":"Reference","text":""},{"location":"index.html#nexus-definitions","title":"NeXus definitions","text":"<p>Here, you find the detailed list of application definitions and base classes and their respective fields.</p>"},{"location":"index.html#pynxtools_2","title":"pynxtools","text":"<p><code>pynxtools</code> has a number of command line tools that can be used to convert data and verify NeXus files. You can find more information about the API here.</p> <p>Within FAIRmat, we maintain a number of generic built-in pynxtools readers, together with reader plugins for different experimental techniques. Here you can find more information:</p> <ul> <li>Built-in <code>pynxtools</code> readers</li> <li>FAIRmat-supported <code>pynxtools</code> plugins</li> </ul>"},{"location":"contact.html","title":"Get in contact","text":"<p>NOMAD and <code>pynxtools</code> are open source project that warmly welcome community projects, contributions, suggestions, bug fixes, and constructive feedback. <code>pynxtools</code> is build mainly within FAIRmat Area B - Experiment.</p> <p>You can reach us by different channels. You can send as directly an email to the main contributors list:</p> Name E-mail Github profiles Dr. Lukas Pielsticker lukas.pielsticker@physik.hu-berlin.de @lukaspie Dr. Markus K\u00fchbach markus.kuehbach@physik.hu-berlin.de @mkuehbach Rubel Mozumder rubel.mozumder@physik.hu-berlin.de @RubelMozumder Sherjeel Shabih sherjeel.shabih@physik.hu-berlin.de @sherjeelshabih Dr. Jos\u00e9 Marquez josemarquez@physik.hu-berlin.de @Pepe-Marquez <p>Alternatively, you can also:</p> <ul> <li>Open an issue on the pynxtools GitHub</li> <li>Join the NOMAD discord channel and ask us there directly.</li> </ul>"},{"location":"getting-started.html","title":"Getting started","text":"<p>This is the entry point for anybody that is new to the NeXus data format and to FAIRmat/NOMAD. It serves as a guide to getting started with the <code>pynxtools</code> software.</p>"},{"location":"getting-started.html#what-should-you-should-know-before-reading-this-guide","title":"What should you should know before reading this guide?","text":"<p>Nothing!</p> <p>However, to get started, it does not hurt to read the following explanations:</p> <ul> <li>A primer on NeXus</li> <li>What is FAIR data</li> </ul>"},{"location":"getting-started.html#what-you-will-know-at-the-end-of-this-guide","title":"What you will know at the end of this guide?","text":"<p>You will have</p> <ul> <li>a basic understanding of what this software is about and its capabilities</li> <li>how the different software tools are interconnected</li> </ul>"},{"location":"getting-started.html#what-is-nexus","title":"What is NeXus?","text":"<p>NeXus is a data format intended for describing and standardizing experimental data. NeXus provides a specific grammar and syntactic rules via NXDL (NeXus Definition Language) for organizing data within files in addition to a dictionary of well-defined domain-specific field concepts. Since each individual concept is properly documented, it allows communities to agree on terms describing their data. Thus, NeXus acts as a contract on which concepts have to be present and how to name them in a given dataset.</p> <p>For a more detailed description on the general principles of NeXus we recommend:</p> <ul> <li>our learning page for NeXus</li> <li>the official NeXus manual</li> </ul>"},{"location":"getting-started.html#what-is-fairmat","title":"What is FAIRmat?","text":"<p>FAIRmat is one of the consortia of the German National Research Data Infrastructure (NFDI). It is tasked with building a FAIR data infrastructure for condensed-matter physics and the chemical physics of solids.</p>"},{"location":"getting-started.html#what-is-nomad","title":"What is NOMAD?","text":"<p>Within FAIRmat, we develop NOMAD: an open source research data management system for making materials science data searchable and publishable. NOMAD hosts a wide variety of datasets from different domains of materials science - including, but not limited to, NeXus data.</p> <ul> <li>NOMAD Homepage</li> <li>NOMAD documentation</li> </ul>"},{"location":"getting-started.html#what-is-pynxtools","title":"What is pynxtools?","text":"<p><code>pynxtools</code> is our main software tool for end-to-end handling of data from experiments using NeXus. It contains a parser for combining various instrument output formats and electronic lab notebook (ELN) formats into an HDF5 file according to NeXus application definitions. It provides validation against these NeXus definitions and can be used to annotate existing NeXus files with semantic meaning.</p> <p><code>pynxtools</code> acts as a Python framework with a built-in API for writing reader plugins that provide specialized reading and conversion functionality for different domains of materials science.</p> <p><code>pynxtools</code> can be used for standalone NeXus conversion, but it can also be used as a plugin to NOMAD, extending NOMAD schemas and parsing capabilities with NeXus-specific capabilities.</p>"},{"location":"getting-started.html#how-can-i-install-pynxtools-how-can-i-contribute","title":"How can I install pynxtools? How can I contribute?","text":"<ul> <li>Installation tutorial</li> <li>Development tutorial</li> </ul>"},{"location":"getting-started.html#does-pynxtools-require-nomad-or-nomad-oasis","title":"Does <code>pynxtools</code> require NOMAD or NOMAD OASIS?","text":"<p>No. With the available plugins or community-developed plugins, you can use <code>pynxtools</code> as a standalone tool for converting raw data from experiments to NeXus-compliant files. Therefore, this tool acts as the framework to design instances of data within the NeXus universe. The software can, however, be used as a NOMAD plugin to parse NeXus files, please see the section below for details.</p>"},{"location":"getting-started.html#how-to-use-pynxtools-with-nomad","title":"How to use <code>pynxtools</code> with NOMAD","text":"<p>NeXus is supported by the research data management platform NOMAD (as a NOMAD plugin). Experimental data files that are compatible with a NeXus application definition can easily be uploaded to NOMAD and translated into the NOMAD Metainfo data model using <code>pynxtools</code>. Therefore, the data file can be recognized by NOMAD's search system. If you want to learn more about uploading NeXus data to NOMAD, please refer to the NeXus to NOMAD tutorial of this documentation.</p> <p>To use the <code>pynxtools</code> Python package with NOMAD, simply install it in the same Python environment as the <code>nomad-lab</code> package. NOMAD will recognize <code>pynxtools</code> as a plugin automatically and offer automatic parsing of <code>.nxs</code> files. In addition, NOMAD will automatically transform the NeXus definitions shipped with <code>pynxtools</code> into its own datamodel called <code>Metainfo</code>. By default, <code>pynxtools</code> is already included in the NOMAD [production]https://nomad-lab.eu/prod/v1/gui/ and staging deployments..</p> <p>A note on FAIR data</p> <p>FAIRmat's contribution to the existing NeXus standard, together with the tools provided through <code>pynxtools</code>, enable scientists and research groups working with data, as well as helping communities implement standardized FAIR research data.</p> <p>You can think of NeXus fulfilling the interoperability and reproducibility part and a research data management platform like NOMAD the findable and accessible part.</p> <p>We consider <code>pynxtools</code> particularly useful for meeting the following FAIR principle as defined in FAIR Principles: Interpretations and Implementation Considerations: F2-4, I2-I3, and R1.</p>"},{"location":"getting-started.html#where-to-go-next","title":"Where to go next?","text":"<p>We suggest you have a look at one of our tutorials:</p> <ul> <li>installing <code>pynxtools</code></li> <li>how go convert data to NeXus</li> </ul>"},{"location":"how-tos/nexus/transformations.html","title":"Representing experimental geometries","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p>"},{"location":"how-tos/nexus/using-multiple-appdefs.html","title":"Using multiple application definitions","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p>"},{"location":"how-tos/nexus/writing-an-appdef.html","title":"Writing an application definition","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p> <p>Concept of this How-to:</p> <p>Create an example file NXdouble_slit</p> <p>NXslit_experiments --&gt; NXdouble_slit NXslit_experiments --&gt; NXsingle_slit</p> <p>They should learn the basic principles of how nexus works, the different path notations</p> <ul> <li>Principles of nexus<ul> <li>concepts</li> <li>application definitions</li> <li>base classes</li> </ul> </li> <li>Inheritance of application definitions and base classes</li> <li>Connection of concept paths and instance paths</li> <li>Description of application definition/base class notation (upper and lower case)</li> <li>Basic tools for creation (pynxtools) and verification (pynxtools?) of nexus files</li> </ul> <p>Additional information (i.e., not in this tutorial but linked to this):</p> <ul> <li>Creating a reader in pynxtools</li> <li>Reading/writing nexus data in nomad</li> </ul> <p>The requirements are set by the community via workshops or at conferences. To initiate or propose changes/additions, you can comment the FAIRMat NeXus proposal by going to the NeXus definitions, and using the hypothes.is tool (sign-up/log-in) to give us some feedback (Red boxes in the image. Expand this panel on the left by clicking on the arrow symbol). </p>"},{"location":"how-tos/pynxtools/build-a-plugin.html","title":"Build your own pynxtools plugin","text":"<p>The pynxtools dataconverter is used to convert experimental data to NeXus/HDF5 files based on any of the provided NXDL schemas. The converter can be extending to support other data formats by allowing extensions called <code>readers</code>.  There exist a set of built-in pynxtools readers as well as <code>pynxtools</code> reader plugins to convert supported data files for some experimental techniques into NeXus-compliant files.</p> <p>Your current data is not supported yet by the built-in <code>pynxtools</code> readers or the officially supported <code>pynxtools</code> plugins?</p> <p>Don't worry, the following how-to will guide you through the steps of writing a reader for your own data.</p>"},{"location":"how-tos/pynxtools/build-a-plugin.html#getting-started","title":"Getting started","text":"<p>You should start by creating a clean repository that implements the following structure (for a plugin called <code>pynxtools-plugin</code>):</p> <pre><code>pynxtools-plugin\n\u251c\u2500\u2500 .github/workflows\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 explanation\n\u2502   \u251c\u2500\u2500 how-tos\n\u2502   \u251c\u2500\u2500 reference\n\u2502   \u251c\u2500\u2500 tutorial\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 pynxtools_plugin\n\u2502       \u251c\u2500\u2500 reader.py\n\u251c\u2500\u2500 tests\n\u2502   \u2514\u2500\u2500 data\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 mkdocs.yaml\n\u251c\u2500\u2500 dev-requirements.txt\n\u2514\u2500\u2500 pyproject.toml\n</code></pre> <p>To identify <code>pynxtools-plugin</code> as a plugin for <code>pynxtools</code>, an entry point must be established (in the <code>pyproject.toml</code> file):</p> pyproject.toml<pre><code>[project.entry-points.\"pynxtools.reader\"]\nmydatareader = \"pynxtools_plugin.reader:MyDataReader\"\n</code></pre> <p>Note that it is also possible that your plugin contains multiple readers. In that case, each reader must have its unique entry point.</p> <p>Here, we will focus mostly on the <code>reader.py</code> file and how to build a reader. For guidelines on how to build the other parts of your plugin, you can have a look here:</p> <ul> <li>Documentation writing guide</li> <li>Plugin testing framework</li> </ul>"},{"location":"how-tos/pynxtools/build-a-plugin.html#writing-a-reader","title":"Writing a Reader","text":"<p>After you have established the main structure, you can start writing your reader. The new reader shall be placed in <code>reader.py</code>.</p> <p>Then implement the reader function:</p> reader.py<pre><code>\"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\nfrom typing import Any\n\nfrom pynxtools.dataconverter.readers.base.reader import BaseReader\n\nclass MyDataReader(BaseReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    supported_nxdls = [\n        \"NXmynxdl\" # this needs to be changed during implementation.\n    ]\n\n    def read(\n        self,\n        template: dict = None,\n        file_paths: tuple[str] = None,\n        objects: tuple[Any] = None\n    ) -&gt; dict:\n        \"\"\"Reads data from given file and returns a filled template dictionary\"\"\"\n        # Here, you must provide functionality to fill the the template, see below.\n        # Example:\n        # template[\"/entry/instrument/name\"] = \"my_instrument\"\n\n        return template\n\n\n# This has to be set to allow the convert script to use this reader. Set it to \"MyDataReader\".\nREADER = MyDataReader\n</code></pre>"},{"location":"how-tos/pynxtools/build-a-plugin.html#the-reader-template-dictionary","title":"The reader template dictionary","text":"<p>The read function takes a <code>Template</code> dictionary, which is used to map from the measurement (meta)data to the concepts defined in the NeXus application definition. The template contains keys that match the concepts in the provided NXDL file.</p> <p>The returned template dictionary should contain keys that exist in the template as defined below. The values of these keys have to be data objects to populate the output NeXus file. They can be lists, numpy arrays, numpy bytes, numpy floats, numpy integers, ... . Practically you can pass any value that can be handled by the <code>h5py</code> package.</p> <p>Example for a template entry:</p> <pre><code>{\n  \"/entry/instrument/source/type\": \"None\"\n}\n</code></pre> <p>For a given NXDL schema, you can generate an empty template with the command</p> <pre><code>user@box:~$ dataconverter generate-template --nxdl NXmynxdl\n</code></pre>"},{"location":"how-tos/pynxtools/build-a-plugin.html#naming-of-groups","title":"Naming of groups","text":"<p>In case the NXDL does not define a <code>name</code> for the group the requested data belongs to, the template dictionary will list it as <code>/NAME_IN_NXDL[name_in_output_nexus]</code>. You can choose any name you prefer instead of the suggested <code>name_in_output_nexus</code> (see here for the naming conventions). This allows the reader function to repeat groups defined in the NXDL to be outputted to the NeXus file.</p> <pre><code>{\n  \"/ENTRY[my_entry]/INSTRUMENT[my_instrument]/SOURCE[my_source]/type\": \"None\"\n}\n</code></pre>"},{"location":"how-tos/pynxtools/build-a-plugin.html#attributes","title":"Attributes","text":"<p>For attributes defined in the NXDL, the reader template dictionary will have the associated key with a \"@\" prefix to the attributes name at the end of the path:</p> <pre><code>{\n  \"/entry/instrument/source/@attribute\": \"None\"\n}\n</code></pre>"},{"location":"how-tos/pynxtools/build-a-plugin.html#units","title":"Units","text":"<p>If there is a field defined in the NXDL, the converter expects a filled in <code>/data/@units</code> entry in the template dictionary corresponding to the right <code>/data</code> field unless it is specified as <code>NX_UNITLESS</code> in the NXDL. Otherwise, a warning will be shown.</p> <pre><code>{\n  \"/ENTRY[my_entry]/INSTRUMENT[my_instrument]/SOURCE[my_source]/data\": \"None\",\n  \"/ENTRY[my_entry]/INSTRUMENT[my_instrument]/SOURCE[my_source]/data/@units\": \"Should be set to a string value\"\n}\n</code></pre>"},{"location":"how-tos/pynxtools/build-a-plugin.html#links","title":"Links","text":"<p>You can also define links by setting the value to sub dictionary object with key <code>link</code>:</p> <pre><code>template[\"/entry/instrument/source\"] = {\"link\": \"/path/to/source/data\"}\n</code></pre>"},{"location":"how-tos/pynxtools/build-a-plugin.html#building-off-of-the-basereader","title":"Building off of the BaseReader","text":"<p>When building off the <code>BaseReader</code>, the developer has the most flexibility. Any new reader must implement the <code>read</code> function, which must return a filled template object.</p>"},{"location":"how-tos/pynxtools/build-a-plugin.html#building-off-of-the-multiformatreader","title":"Building off of the MultiFormatReader","text":"<p>While building on the <code>BaseReader</code> allows for the most flexibility, in most cases it is desirable to implement a reader that can read in multiple file formats and then populate the template based on the read data. For this purpose, <code>pynxtools</code> has the <code>MultiFormatReader</code>, which can be readily extended for your own data.</p> <p>You can find an extensive how-to guide to build off the <code>MultiFormatReader</code> here.</p>"},{"location":"how-tos/pynxtools/build-a-plugin.html#calling-the-reader-from-the-command-line","title":"Calling the reader from the command line","text":"<p>The dataconverter can be executed using:</p> <pre><code>dataconverter --reader mydatareader --nxdl NXmynxdl --output path_to_output.nxs\n</code></pre> <p>Here, the <code>--reader</code> flag must match the reader name defined in <code>[project.entry-points.\"pynxtools.reader\"]</code> in the pyproject.toml file. The NXDL name passed to <code>--nxdl</code>must be a valid NeXus NXDL/XML file in <code>pynxtools.definitions</code>.</p> <p>Aside from this default structure, there are many more flags that can be passed to the dataconverter call. Here is its API:</p>"},{"location":"how-tos/pynxtools/build-a-plugin.html#dataconverter","title":"dataconverter","text":"<p>This command allows you to use the converter functionality of the dataconverter.</p> <p>Usage:</p> <pre><code>dataconverter [OPTIONS] [FILES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--input-file</code> text Deprecated: Please use the positional file arguments instead. The path to the input data file to read. Repeat for more than one file. default=[] This option is required if no '--params-file' is supplied. <code>[]</code> <code>--reader</code> choice (<code>example</code> | <code>json_map</code> | <code>json_yml</code> | <code>multi</code>) The reader to use. Examples are json_map or readers from a pynxtools plugin. default='json_map' This option is required if no '--params-file' is supplied. <code>json_map</code> <code>--nxdl</code> text The name of the NeXus application definition file to use without the extension nxdl.xml. This option is required if no '--params-file' is supplied. None <code>--output</code> text The path to the output NeXus file to be generated. default='output.nxs' <code>output.nxs</code> <code>--params-file</code> filename Allows to pass a .yaml file with all the parameters the converter supports. None <code>--ignore-undocumented</code> boolean Ignore all undocumented fields during validation. <code>False</code> <code>--fail</code> boolean Fail conversion and don't create an output file if the validation fails. <code>False</code> <code>--skip-verify</code> boolean Skips the verification routine during conversion. <code>False</code> <code>--mapping</code> text Takes a .mapping.json file and converts data from given input files. None <code>-c</code>, <code>--config</code> file A json config file for the reader None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html","title":"Using Python to create NeXus files","text":"<p>In general, we recommend using <code>pynxtools</code> to create NeXus files, which has the inherent advantage that the resulting NeXus file gets automatically validated against the NeXus application definition during conversion.</p> <p>However, in some cases, it might be simpler to create the NeXus NeXus file (.nxs) directly using Python. For static data structures (i.e., always the same type of standard measurement) or one-time examples (small data publications), this may provide a feasible solution. For large scaled automated file processing, storage, and validation, we strongly recommend using <code>pynxtools</code> and its measurement method specific plugins.</p> <p>This How-To is intended as easy access to FAIR data structures via NeXus. It will demonstrate how NeXus file can be created in Python using <code>h5py</code>.</p> <p>You can find all of the data on Zenodo:</p> <p>Download from Zenodo</p> <p>Specifically, the Python script for creating a NeXus file can be downloaded here:</p> <p>Download h5py_nexus_file_creation.py</p> <p>We will discuss its content below and guide you through step-by-step in creating your NeXus file by hand.</p>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#create-a-nexus-file-through-python-and-h5py","title":"Create a NeXus file through Python and h5py","text":"<p>You start by installing <code>h5py</code> via <code>pip</code>:</p> <pre><code>pip install h5py\n</code></pre> <p>Next, we create the Python file and fill it with a minimal structure.</p> <pre><code># Import h5py, to write an hdf5 file\nimport h5py\n\n# create a h5py file in writing mode with given name \"NXopt_minimal_example\", file extension \"nxs\"\nf = h5py.File(\"NXopt_minimal_example.nxs\", \"w\")\n\n# there are only 3 fundamental objects: &gt;group&lt;, &gt;attribute&lt; and &gt;field&lt;.\n\n\n# create a &gt;group&lt; called \"entry\"\nf.create_group('/entry')\n\n# assign the &gt;group&lt; called \"entry\" an &gt;attribute&lt;\n# The attribute is \"NX_class\"(a NeXus class) with the value of this class is \"NXentry\"\nf['/entry'].attrs['NX_class'] = 'NXentry'\n\n# create &gt;field&lt; called \"definition\" inside the entry, and assign it the value \"NXoptical_spectroscopy\"\n# This field is important, as it is used in validation process to identify the NeXus definition.\nf['/entry/definition'] = 'NXoptical_spectroscopy'\n</code></pre> <p>This structure is the starting point for our NeXus file. We will go through these functions in the following.</p>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#add-nexus-concepts","title":"Add NeXus concepts","text":"<p>We will create a file according to the NeXus application definition <code>NXoptical_spectroscopy</code>, which provides a generic description for experiments in optical spectroscopy.</p> <p>On the linked documentation NeXus definitions documentation page, you see a tree-like structure of <code>NXoptical_spectroscopy</code> with several tree nodes: Status, Description, Symbols, Groups_cited, Structure. For now, only the part in Structure is of interest. This contains the information which has to be written in the Python code to add fields/groups/attributes to the NeXus file.</p> <p>Use your browser search (CTRL+F) and search for \"required\" to highlight all NeXus concepts which are required. You have to add those to the Python script to extend your created .nxs file. (Which fields/groups/attributes are \"required\" was defined by the respective scientific community, to ensure that the data serves the FAIR principles.)</p> <p>In the following, it will be shown how to add three types of fundamental NeXus objects through the Python script:</p> <ol> <li> <p>Attribute</p> </li> <li> <p>Field</p> </li> <li> <p>Group</p> </li> </ol>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#adding-an-attribute","title":"Adding an attribute","text":"<p>In the tree structure, the first concept which is not created yet, is the <code>@version</code> attribute:</p> <p>@version: (required) NX_CHAR \u2906</p> <ol> <li> <p>It is located in the tree at <code>ENTRY/definition/</code></p> </li> <li> <p>The \"@\" indicates that this is an attribute of the concept \"definition\".</p> </li> <li> <p>The name of the attribute is \"version\".</p> </li> <li> <p>Since it is \"required\", that means this attribute has to be added so that the resulting NeXus file is compliant with the NeXus definition <code>NXoptical\\_spectroscopy</code>.</p> </li> <li> <p><code>NX\\_CHAR</code> indicates the datatype. This should be a string: \"The preferred string representation is UTF-8\" (more information see here)</p> </li> </ol> <p></p> <p>We add an instance of this concept by adding an HDF5 attribute:</p> <pre><code>f['/entry/definition'].attrs['version'] = 'v2024.02'\n</code></pre> <p>This h5py command adds the attribute named \"version\" with the value \"v2024.02\" to the HDF5 dataset called \"/entry/definition\". The same is done for the URL attribute:</p> <pre><code>f['/entry/definition'].attrs['URL'] = 'https://github.com/FAIRmat-NFDI/nexus_definitions/blob/f75a29836431f35d68df6174e3868a0418523397/contributed_definitions/NXoptical_spectroscopy.nxdl.xml'\n</code></pre> <p>For your use case, you may want to use a different version of the NeXus definitions, since these are changed over time. In the following, it is shown where to obtain the correct version and URL.</p> <p>Get the values: version and URL</p> <p>At the time you create the NeXus file, can do the following to find the version and associated URL:</p> <ul> <li> <p>Go to the page of the respectively used NeXus concept, i.e. NXoptical_spectroscopy</p> </li> <li> <p>Scroll down until you find \"NXDL Source:\" and follow this link, i.e. NXoptical_spectroscopy.nxdl.xml</p> </li> </ul> <p>This is the GitHub website, in which the latest (FAIRmat) NeXus definition of NXoptical_spectroscopy is stored in the NeXus definition language file (.nxdl). The information is structured in the xml format.</p> <ul> <li>Now you have to copy the permalink of this file. Go to the top right side of the website. Find the Menu made by 3 dots:</li> </ul> <p></p> <p>Copy the permalink and insert it as value for the \"URL\" attribute (Step 1, Red box in the image)</p> <ul> <li>Go to \"nexus_definitions\" (Step 2, Red box in the image)</li> </ul> <p></p> <p>On the right side, you should see below \"Releases\" the \"tags\" (Red box in the image). Follow this link.</p> <ul> <li>Copy the latest tag, which should look similar to \"v2024.02\". Insert it as value for the \"version\" attribute.</li> </ul> <p>Disclaimer When specifying this version tag, it would be better to include the GitHub commit ID as well. In pynxtools, these are appended automatically. Such a version tag might look like this: <code>v2022.07.post1.dev1278+g1d7000f4</code>.</p> <p>If you have pynxtools installed, you can get the tag by:</p> <pre><code>from pynxtools import get_nexus_version\nget_nexus_version()\n&gt;&gt;&gt; 'v2022.07.post1.dev1284+gf75a2983'\n</code></pre>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#adding-a-field","title":"Adding a field","text":"<p>The next required concept of NXoptical_spectroscopy is \"experiment_type\".</p> <p>experiment_type: (required) NX_CHAR</p> <ol> <li> <p>It is located in the tree at position <code>ENTRY/</code></p> </li> <li> <p>There is no \"@\" in front of \"experiment_type\". So, this may be a group or a field.</p> </li> <li> <p>The name of this group/field is \"experiment_type\".</p> </li> <li> <p>The \"required\" indicates that this group/field has to be added to be in line with the NeXus definition \"NXoptical_spectroscopy\".</p> </li> <li> <p><code>NX\\_CHAR</code> indicates the datatype. This should NXoptical_spectrs be a string (see above).</p> </li> <li> <p>The presence of the datatype <code>NX\\_CHAR</code> indicates that this is a field. It is NOT a group.</p> </li> </ol> <p>Read the documentation at \"\u25b6 Specify the type of the optical experiment. ...\" by extending it via click on the triangle symbol. You should see something like this:</p> <p></p> <p>There, the value of the field has to be one of the shown list, since it is an enumeration (e.g. \"transmission spectroscopy\"). Note that this is requires an exact match to one of the enumerated items (case and whitespace sensitive).</p> <p>Therefore, the Python script has to be extended by:</p> <pre><code>f['/entry/experiment_type'] = 'transmission spectroscopy'\n</code></pre>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#adding-a-group","title":"Adding a group","text":"<p>The first required group in NXoptical_spectroscopy on the <code>ENTRY/</code> level is \"INSTRUMENT: (required) NXinstrument \u2906\"</p> <ol> <li> <p>It is located in the tree at position: NXentry/</p> </li> <li> <p>There is no \"@\" in front of \"INSTRUMENT\" and because the <code>NXinstrument</code> is a NeXus group, this has to be implemented as an HDF5 group in the Python script.</p> </li> <li> <p>The \"required\" indicates that this group has to be added to be in line with the NeXus definition \"NXoptical_spectroscopy\".</p> </li> <li> <p>As this is a group, other groups, fields, or attributes may be assigned to it.</p> </li> <li> <p>The uppercase notation of \"INSTRUMENT\" means:</p> <ol> <li> <p>You can give INSTRUMENT almost any name, such as \"abc\" or \"Raman_setup\" (see \"regex\" or regular expression).</p> </li> <li> <p>You can create as many groups with the class <code>NXinstrument</code> as you want. Their names have to be different.</p> </li> <li> <p>For more information, see the NeXus rules</p> </li> </ol> </li> </ol> <p>The Python code to implement the <code>NXinstrument</code> group as an HDF5 group named with the name \"experiment_setup_1\"  is:</p> <pre><code>f.create_group('/entry/experiment_setup_1')\nf['/entry/experiment_setup_1'].attrs['NX_class'] = 'NXinstrument'\n</code></pre> <p>The first line creates the group with the name \"experiment_setup_1\".</p> <p>The second line assigns this group the attribute with the name \"NX_class\" and its value \"NXinstrument\".</p>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#finishing-the-nexus-file","title":"Finishing the NeXus file","text":"<p>Afterwards, we repeat the process for all required NeXus groups/fields/attributes defined in NXoptical_spectroscopy.</p> <p>The next required entries are located inside the NXinstrument class:</p> <ol> <li> <p>beam_TYPE: (required) NXbeam \u2906</p> </li> <li> <p>detector_TYPE: (required) NXdetector \u2906</p> </li> </ol> <p>Both are groups. \"beam_TYPE\" could be named: \"beam_abc\" or \"beam_Raman_setup\". Use the knowledge above to extend the Python script to create those NeXus file entries.</p> <p>Note that you can also add instances for recommended or optional concepts to the file by using the same Python functionality as above. The difference to the required concept is that they have to be present in order for the file to comply with the application definitions, whereas recommended/optional files can, but don't need to be present.</p>"},{"location":"how-tos/pynxtools/create-nexus-files-by-python.html#whats-next","title":"What's next?","text":"<ul> <li>Once you have a finished NeXus file, you may continue by validating the NeXus file.</li> <li>If you find yourself in the situation that you need to run such Python code routinely to convert your data, we strongly recommend creating your own reader or plugin in the <code>pynxtools</code> ecosystem. You can find a how-to guide to get you started here.</li> </ul>"},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html","title":"Notes on cnxvalidate installation","text":"<p>This lists some notes for installation of nxvalidate on Ubuntu and Windows. For windows, the installation of the XML2 library was not successful. This should be possible, but could not reproduced yet.</p>"},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html#cnxvalidate-installation-on-ubuntu-2204","title":"cnxvalidate installation on Ubuntu 22.04","text":"<p>These commands install nxvaldiate on a fresh Ubuntu 22.04 system (tested with Linux running from USB stick).</p> <pre><code>sudo apt-get update\nsudo apt-get install git\nsudo apt-get install build-essential\nsudo add-apt-repository universe\nsudo apt-get install libhdf5-serial-dev\nsudo apt-get -y install pkg-config\nsudo apt upgrade -y\nsudo apt-get -y install cmake\nsudo apt-get install libxml2-dev\n\nmkdir nexusvalidate\ncd nexusvalidate\ngit clone https://github.com/nexusformat/cnxvalidate.git\ncd cnxvalidate/\nmkdir build\ncd build/\ncmake ../\nmake\n</code></pre>"},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html#cnxvalidate-installation-on-windows","title":"cnxvalidate installation on Windows:","text":""},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html#-cmake","title":"-- CMAKE","text":"<p>https://cmake.org/download/</p> <p>--&gt; cmake-3.30.2-windows-x86_64.msi</p> <p>Install with .msi</p>"},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html#-hdf5","title":"-- HDF5","text":"<p>Download hdf5-1.14.4-2-win-vs2022_cl.zip** from **https://www.hdfgroup.org/downloads/hdf5/</p> <p>unzip the .zip file</p> <p>put the file into the folder</p> <pre><code>C:\\hdf5\n</code></pre> <p>(can be named differently, but no spaces are allowed for this path)</p> <pre><code>set PATH=%PATH%;C:\\your\\path\\here\\\n</code></pre>"},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html#-libiconv","title":"-- libiconv","text":"<p>https://github.com/vovythevov/libiconv-cmake</p> <pre><code>git clone\n</code></pre> <p>cd to downloaded directory</p> <pre><code>mkdir build\ncd build\ncmake ..\n</code></pre>"},{"location":"how-tos/pynxtools/installation_notes_nxvalidate.html#-xml2","title":"-- XML2","text":"<p>??? Unsolved...</p> <p>Please create GitHub issue here if you could solve this.</p>"},{"location":"how-tos/pynxtools/run-tests-in-parallel.html","title":"Running <code>pynxtools</code> tests in parallel","text":"<p>The <code>pytest</code> framework allows tests to run in sequential and parallel using third-party plugins such as <code>pytest-xdist</code>. In our <code>pytest</code> setup for <code>pynxtools</code>, we use <code>pytest-xdist</code> to execute tests in parallel. To handle shared resources among multiple tests, tests are grouped using the <code>@pytest.mark.xdist_group</code> fixture. This prevents classic race conditions by ensuring that tests sharing the same resources are executed sequentially.</p>"},{"location":"how-tos/pynxtools/run-tests-in-parallel.html#running-tests-sequentially","title":"Running Tests Sequentially","text":"<p>In a local setup, tests can be run sequentially using the following command:</p> <pre><code>pytest tests\n</code></pre> <p>This will execute all tests in a sequential manner. For more details, refer to the official documentation:</p> <ul> <li>How to invoke pytest</li> </ul>"},{"location":"how-tos/pynxtools/run-tests-in-parallel.html#running-tests-in-parallel","title":"Running Tests in Parallel","text":"<p>The <code>pytest-xdist</code> plugin can be used to speed up test execution by distributing tests among available workers. To prevent race conditions, tests that share the same resources are grouped using the <code>@pytest.mark.xdist_group(name=\"group_name\")</code> fixture. These grouped tests must be run with the <code>--dist loadgroup</code> flag. For example:</p> <pre><code>pytest tests -n auto --dist loadgroup\n</code></pre> <p>Here:</p> <ul> <li>The <code>-n auto</code> flag tells <code>pytest</code> to automatically distribute tests among all available workers.</li> <li>The <code>--dist loadgroup</code> flag ensures that tests marked with the same @pytest.mark.xdist_group(name=\"...\") are executed serially.</li> </ul> <p>This setup allows for efficient parallel test execution while maintaining the integrity of tests that depend on shared resources.</p>"},{"location":"how-tos/pynxtools/testing-validation-tools.html","title":"The shows the example of testing NeXus files with validation methods","text":"<p>There are different methods, which can be used for file validation.</p> <ul> <li>pynxtools (verify_nexus, read_nexus)</li> <li>nxvalidate</li> <li>punx</li> </ul> <p>Here some examples are shown for the respective methods, by using a pynxtools-ellips generated NeXus file. This generated file already contained some level of validation, as a generated and filled template for this NeXus application definition was used.</p>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#1-example-from-pynxtools-read_nexus-function","title":"1. Example from pynxtools read_nexus function","text":"<p><code>read_nexus -f SiO2onSi.ellips.nxs &gt; read_nexus_output_file.txt</code> <pre><code>NXellipsometry.nxdl.xml:/ENTRY/data_collection/data_software\nNXprogram.nxdl.xml:\nDEBUG: @url - IS NOT IN SCHEMA\n####################################################\nNXellipsometry.nxdl.xml:/ENTRY/definition\nNXoptical_spectroscopy.nxdl.xml:/ENTRY/definition\nNXentry.nxdl.xml:/definition\nDEBUG: @url - IS NOT IN SCHEMA\n####################################################\nDEBUG: ===== GROUP (//entry/instrument/software_RC2 [NXellipsometry::/NXentry/NXinstrument/software_RC2]): &lt;HDF5 group \"/entry/instrument/software_RC2\" (1 members)&gt;\nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\nDEBUG: ===== FIELD (//entry/instrument/software_RC2/program): &lt;HDF5 dataset \"program\": shape (), type \"|O\"&gt;\nDEBUG: value: b'CompleteEASE' \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\nDEBUG: ===== ATTRS (//entry/instrument/software_RC2/program@url)\nDEBUG: value: https://www.jawoollam.com/ellipsometry-software/completeease \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\nDEBUG: ===== ATTRS (//entry/instrument/software_RC2/program@version)\nDEBUG: value: 6.37 \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\n</code></pre> Total 6 Errors 1. @url. Changing to @URL could fix this maybe. 2. Software_RC2 not detected as NXprogram. This is indeed not assigned.</p>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#2-example-from-pynxtools-verify_nexus-function","title":"2. Example from pynxtools verify_nexus function","text":"<p><code>verify_nexus SiO2onSi.ellips.nxs</code></p> <p><pre><code>WARNING: Field /entry/data_collection/Delta_50deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_50deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_60deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_60deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_70deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_70deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_50deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_50deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_60deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_60deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_70deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_70deg_errors/@units written without documentation.\nWARNING: Missing attribute: \"/ENTRY/DATA/@axes\"\nWARNING: Missing attribute: \"/ENTRY/DATA/@signal\"\nInvalid: The entry `entry` in file `SiO2onSi.ellips.nxs` is NOT a valid file according to the `NXellipsometry` application definition.\n</code></pre> Total 14 Errors Total 3 Errors - without documentation 1. Psi+Delta with Unit+Errors written without doc. 2. Data @axes + @signal. May not find NXdata? Attributes are present in .nxs file. 3. entry not valid in NXellips.</p>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#3-example-from-nxvalidate","title":"3. Example from nxvalidate","text":"<p><code>`PATH_TO_NX_VALIDATE_EXE/nxvalidate -l PATH_TO_FAIRMAT_NEXUS_DEF/nexus_definitions/ PATH_TO_NEXUS_FILE/SiO2onSi.ellips.nxs</code> <pre><code>definition=NXellipsometry.nxdl.xml message=\"Data type mismatch, expected NX_BOOLEAN, got H5T_ENUM {      H5T_STD_I8LE;      \"FALSE\"            0;      \"TRUE\"             1;   }\" nxdlPath=/NXentry/NXinstrument/NXlens_opt/data_correction sev=error dataPath=/entry/instrument/focussing_probes/data_correction dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXinstrument/NXbeam sev=error dataPath=/entry/instrument dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXinstrument/NXdetector sev=error dataPath=/entry/instrument dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Data type mismatch, expected NX_BOOLEAN, got H5T_ENUM {      H5T_STD_I8LE;      \"FALSE\"            0;      \"TRUE\"             1;   }\" nxdlPath=/NXentry/NXsample/backside_roughness sev=error dataPath=/entry/sample/backside_roughness dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required units attribute missing\" nxdlPath=/NXentry/NXdata/measured_data sev=error dataPath=/entry/data_collection/measured_data dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Data type mismatch, expected NX_BOOLEAN, got H5T_STRING {      STRSIZE H5T_VARIABLE;      STRPAD H5T_STR_NULLTERM;      CSET H5T_CSET_UTF8;      CTYPE H5T_C_S1;   }\" nxdlPath=/NXentry/NXidentifier/is_persistent sev=error dataPath=/entry/experiment_identifier/is_persistent dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXdata sev=error dataPath=/entry dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required units attribute missing\" nxdlPath=/NXentry/NXprocess/depolarization sev=error dataPath=/entry/derived_parameters/depolarization dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \n9 errors and 85 warnings found when validating /home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs\n</code></pre> Total 8 or 9 Errors 1. Datatype mismatch for Bools: \"H5T_STRING\" or \"H5T_ENUM\" instead of \"NX_BOOLEAN\". In NXlens_opt, backside_roughness and is_persistent. 2. NXbeam + NXdetector: Has a problem with \"  exists: [min, 1, max, infty]\" 3. \"/NXentry/NXdata/measured_data\". Units are missing (unit should be NX_ANY). 4. It does not find the NXdata (in this file it is at /entry/data_collection/). 5. Depolarization is not assigned the unit NX_unitless.</p>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#nxvalidate-errors","title":"nxvalidate Errors:","text":"<ol> <li> <p>\"Data type mismatch, expected NX_BOOLEAN\" --&gt; \"NeXus interprets NX_BOOLEAN differently than h5py. NeXus uses an integer of 1 byte for NX_BOOLEAN. This is an int8 or uint8.\" --&gt; https://github.com/nexusformat/cnxvalidate/issues/34</p> </li> <li> <p>Required group missing for \"NXbeam\" and \"NXdetector\". Problem with NeXus requirement as given in the .yaml file by: \"exists: [min, 1, max, infty]\"?</p> </li> <li> <p>\"Required units attribute missing\" for entry/data_collection/measured_data --&gt; ? unclear. Units are assigned in NeXus file.</p> </li> <li> <p>\"Required group missing\" for /entry ---&gt; ? unclear.</p> </li> </ol>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#nxvalidate-warnings","title":"nxvalidate Warnings:","text":"<p>I think warnings can be evoked by: (-t in front of the NeXus file):</p> <pre><code>~/FAIRmat/WorkshopNeXusValid02/nxvalidate/cnxvalidate/build$ ./nxvalidate -l /home/ron/FAIRmat/WorkshopNeXusValid02/nxvalidate/nexus_definitions/ -t SiO2onSi.ellips.nxs\n</code></pre> <p>Most of the warnings are not critical at all. Not sure if this is helpful at all:</p> <p>here are some examples of the \"messages\" of the warnings:</p> <ol> <li> <p>\"Optional group missing\"</p> </li> <li> <p>\"Optional field missing\"</p> </li> <li> <p>\"Optional attribute units missing\"</p> </li> <li> <p>\"Validating field\"</p> </li> <li> <p>\"Validating group\"</p> </li> <li> <p>\"Additional base class dataset name found\"</p> </li> <li> <p>\"Additional base class dataset address found\"</p> </li> <li> <p>\"Unknown dataset wavelength_spectrum found\"</p> </li> <li> <p>\"Additional base class group notes of type NXnote found\"</p> </li> <li> <p>\"Additional base class group environment_sample of type NXenvironment found\"</p> </li> </ol>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#4-example-from-punx","title":"4. Example from punx","text":"<p><code>punx validate SiO2onSi.ellips.nxs</code> Not possible, as only the NIAC NeXus definition can right now be used as reference. Unclear if the <code>punx install</code> functionality is working or still developed.</p>"},{"location":"how-tos/pynxtools/testing-validation-tools.html#summary","title":"Summary","text":"Error Message origin Error in .nxs file? Error in validation tool? unit + error without doc verify_nexus ? ? no @signal @axes for NXdata verify_nexus no yes entry not valid in NXellips verify_nexus ? ? @url error read_nexus no yes Software_RC2 no NXprogram read_nexus yes no Bool Data types nxvalidate ? ? exists: [min, 1, max, infty] nxvalidate no yes Unit missing for measured_data nxvalidate yes no NXdata not present nxvalidate no yes No unit for depolarization nxvalidate yes no"},{"location":"how-tos/pynxtools/testing-validation-tools.html#note","title":"NOTE","text":"<p>Only the nxvalidate method seems to point out completely missing required concepts.</p> <p>I tested this with an empty NeXus file, in which only the \"definition\" was given (NXellipsometry and NXraman).</p>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html","title":"How to use the built-in MultiFormatReader","text":"<p>While building on the <code>BaseReader</code> allows for the most flexibility, in most cases it is desirable to implement a reader that can read in multiple file formats and then populate the template based on the read data. For this purpose, <code>pynxtools</code> has the <code>MultiFormatReader</code>, which can be readily extended for your own data. In this how-to guide, we will focus on an implementation using a concrete example. If you are also interested in the general structure of the <code>MultiFormatReader</code>, you can find more information here.</p>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#getting-started","title":"Getting started","text":"<p>You can find all of the data and the developed Python scripts here:</p> <p>Download</p> <p>Here, we will implement a reader called <code>MyDataReader</code> that builds on the <code>MultiFormatReader</code>. <code>MyDataReader</code> is an example for a reader that can read HDF5 data from a specific technology-partner data set, as well as additional metadata from am electronic lab notebook (in YAML format).</p> <p>For demonstration purposes, we will work with a very simple mock application definition:</p> NXsimple.nxdl.xml<pre><code>&lt;definition xmlns=\"http://definition.nexusformat.org/nxdl/3.1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" category=\"application\" type=\"group\" name=\"NXsimple\" extends=\"NXobject\" xsi:schemaLocation=\"http://definition.nexusformat.org/nxdl/3.1 ../nxdl.xsd\"&gt;\n    &lt;doc&gt;\n         Mock application definition.\n    &lt;/doc&gt;\n    &lt;group type=\"NXentry\"&gt;\n        &lt;field name=\"definition\"&gt;\n            &lt;attribute name=\"version\"/&gt;\n            &lt;enumeration&gt;\n                &lt;item value=\"NXsimple\"/&gt;\n            &lt;/enumeration&gt;\n        &lt;/field&gt;\n        &lt;field name=\"title\"/&gt;\n        &lt;group type=\"NXuser\" recommended=\"true\"&gt;\n            &lt;field name=\"name\"&gt;\n                &lt;doc&gt;\n                     Name of the user.\n                &lt;/doc&gt;\n            &lt;/field&gt;\n            &lt;field name=\"address\" recommended=\"true\"&gt;\n                &lt;doc&gt;\n                     Name of the affiliation of the user.\n                &lt;/doc&gt;\n            &lt;/field&gt;\n        &lt;/group&gt;\n        &lt;group type=\"NXinstrument\"&gt;\n            &lt;doc&gt;\n                 Description of the instrument and its individual parts.\n            &lt;/doc&gt;\n            &lt;attribute name=\"version\"&gt;\n                &lt;doc&gt;\n                     Version of the instrument.\n                &lt;/doc&gt;\n            &lt;/attribute&gt;\n            &lt;group type=\"NXdetector\" optional=\"true\"&gt;\n                &lt;field name=\"count_time\" type=\"NX_NUMBER\" units=\"NX_TIME\" recommended=\"true\"&gt;\n                    &lt;doc&gt;\n                         Elapsed actual counting time\n                    &lt;/doc&gt;\n                &lt;/field&gt;\n            &lt;/group&gt;\n        &lt;/group&gt;\n        &lt;group name=\"sample\" type=\"NXsample\"&gt;\n            &lt;field name=\"name\"/&gt;\n            &lt;field name=\"physical_form\" recommended=\"true\"/&gt;\n            &lt;field name=\"temperature\" type=\"NX_FLOAT\" recommended=\"true\" units=\"NX_TEMPERATURE\"/&gt;\n        &lt;/group&gt;\n        &lt;group name=\"data\" type=\"NXdata\"&gt;\n            &lt;doc&gt;\n                 The default NXdata group containing a view on the measured data.\n            &lt;/doc&gt;\n        &lt;/group&gt;\n    &lt;/group&gt;\n&lt;/definition&gt;\n</code></pre> <p>The application definitions requires a user, some sample information, some instrument metadata, and the measured data to be written. Some groups, fields, and attributes are strictly required (the default), others are just recommended or optional.</p> <p>Note that in order to be recognized as a valid application definition, this file should be copied to the <code>applications</code> folder within the <code>definitions</code> submodule at <code>pynxtools.definitions</code>.</p> <p>We first start by implementing the class and its <code>__init__</code> call:</p> reader.py<pre><code>\"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\nfrom typing import Any\n\nfrom pynxtools.dataconverter.readers.base.reader import ParseJsonCallbacks, MultiFormatReader\n\nclass MyDataReader(MultiFormatReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    supported_nxdls = [\n        \"NXsimple\"\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.extensions = {\n            \".yml\": self.handle_eln_file,\n            \".yaml\": self.handle_eln_file,\n            \".json\": self.set_config_file,\n            \".hdf5\": self.handle_eln_file,\n            \".h5\": self.handle_eln_file,\n        }\n\nREADER = MyDataReader\n</code></pre> <p>Note that here we are adding handlers for three types of data file extensions:</p> <ol> <li><code>\".hdf5\"</code>, <code>\".h5\"</code>: This will be used to parse in the (meta)data from the instrument's HDF5 file.</li> <li><code>\".yml\"</code>, <code>\".yaml\"</code>: This will be used to parse in the (meta)data from the ELN file.</li> <li><code>\".json\"</code>: This will be used to read in the config file, which is used to map from the (meta)data concepts from the instrument and ELN data to the concepts in the NXDL file.</li> </ol>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#reading-in-the-instruments-data-and-metadata","title":"Reading in the instrument's data and metadata","text":"<p>First, we will have a look at the HDF5 file. This mock HDF5 file was generated with <code>h5py</code> using a simple script:</p> <p>Download create_mock_data.py</p> <p></p> <p>Here, we see that we have a <code>data</code> group with x and y values, as well as some additional metadata for the instrument.</p> <p>Here is one way to implement the method to read in the data:</p> reader.py<pre><code>import h5py\n\ndef handle_hdf5_file(filepath):\n    def recursively_read_group(group, path=\"\"):\n        result = {}\n        for key, item in group.items():\n            new_path = f\"{path}/{key}\" if path else key\n            if isinstance(item, h5py.Group):\n                # Recursively read subgroups\n                result.update(recursively_read_group(item, new_path))\n            elif isinstance(item, h5py.Dataset):\n                # Read datasets\n                result[new_path] = item[()]\n        return result\n\n    # Open the HDF5 file and read its contents\n    with h5py.File(filepath, \"r\") as hdf:\n        self.hdf5_data = recursively_read_group(hdf)\n\n    return {}\n</code></pre> <p>Note that here we are returning an empty dictionary because we don't want to fill the template just yet, but only read in the HDF5 data for now. We will use the config file later to fill the template with the read-in data. Note that it is also possible to return a dictionary here to update the template directly.</p> <p><code>self.hdf5_data</code> will look like this:</p> <pre><code>{\n    \"data/x_values\": array([-10.        ,  -9.7979798 ,  -9.5959596 , ...,  10.        ]),\n    \"data/y_values\": array([3.72665317e-06, 6.14389891e-06, 1.00262383e-05, ..., 3.72665317e-06]),\n    \"data/x_units\": \"eV\",\n    \"data/y_units\": \"counts_per_second\",\n    \"metadata/instrument/version\": 1.0,\n    \"metadata/instrument/detector/name\": \"my_gaussian_detector\",\n    \"metadata/instrument/detector/count_time\": 1.2,\n    \"metadata/instrument/detector/count_time_units\": s\",\n}\n</code></pre>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#reading-in-eln-data","title":"Reading in ELN data","text":"<p>As we can see in the application definition <code>NXsimple</code> above, there are some concepts defined for which there is no equivalent metadata in the HDF5 file. We are therefore using a YAML ELN file to add additional metadata. The ELN file <code>eln_data.yaml</code> looks like this:</p> eln_data.yaml<pre><code>title: My experiment\nuser:\n  name: John Doe\n  address: 123 Science Rd, Data City, DC\nsample:\n  name: my_sample\n  physical_form: powder\n  temperature:\n    value: 300\n    unit: K\n</code></pre> <p>It contains metadata about the user and the sample that was measured.</p> <p>We now need to write a function to read in this ELN data. Luckily, there exists already a solution within <code>pynxtools</code>, using the <code>parse_yaml</code> function:</p> reader.py<pre><code>from pynxtools.dataconverter.readers.utils import parse_yml\n\nCONVERT_DICT = {\n    \"unit\": \"@units\",\n    \"version\": \"@version\",\n    \"user\": \"USER[user]\",\n    \"instrument\": \"INSTRUMENT[instrument]\",\n    \"detector\": \"DETECTOR[detector]\",\n    \"sample\": \"SAMPLE[sample]\",\n}\n\ndef handle_eln_file(self, file_path: str) -&gt; dict[str, Any]:\n    self.eln_data = parse_yml(\n        file_path,\n        convert_dict=CONVERT_DICT,\n        parent_key=\"/ENTRY[entry]\",\n    )\n\n    return {}\n</code></pre> <p>When this method is called, <code>self.eln_data</code> will look like this:</p> <pre><code>{\n    \"/ENTRY[entry]/title\": \"My experiment\",\n    \"/ENTRY[entry]/USER[user]/name\": \"John Doe\",\n    \"/ENTRY[entry]/USER[user]/address\": \"123 Science Rd, Data City, DC\",\n    \"/ENTRY[entry]/SAMPLE[sample]/name\": \"my_sample\",\n    \"/ENTRY[entry]/SAMPLE[sample]/physical_form\": \"powder\",\n    \"/ENTRY[entry]/SAMPLE[sample]/temperature\": 300,\n    \"/ENTRY[entry]/SAMPLE[sample]/temperature/@units\": \"K\"\n}\n</code></pre> <p>Note that here we are using <code>parent_key=\"/ENTRY[entry]\"</code> as well as a <code>CONVERT_DICT</code>, meaning that each key in <code>self.eln_data</code> will start with <code>\"/ENTRY[entry]\"</code> and some of the paths will be converted to match the template notation. This will be important later.</p>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#parsing-the-config-file","title":"Parsing the config file","text":"<p>Next up, we can make use of the config file, which is a JSON file that tells the reader how to map the concepts from the HDF5 and ELN files in order to populate the template designed to match <code>NXsimple</code>. The choices made in the config file define how semantics from the source (data file) and target (NeXus application definition) side are mapped. Essentially, the config file should contain all keys that are present in the NXDL. In our case, the config file looks like this:</p> config_file.json<pre><code>{\n  \"/ENTRY/title\": \"@eln\", \n  \"/ENTRY/USER[user]\": {\n    \"name\":\"@eln\",\n    \"address\":\"@eln:/ENTRY/USER[user]/address\",\n  }, \n  \"/ENTRY/INSTRUMENT[instrument]\": {\n    \"@version\":\"@attrs:metadata/instrument/version\",\n    \"DETECTOR[detector]\":{\n      \"count_time\":\"@attrs:metadata/instrument/detector/count_time\",\n      \"count_time/@units\":\"@attrs:metadata/instrument/detector/count_time_units\"\n    }\n  },\n  \"/ENTRY/SAMPLE[sample]\": {\n    \"name\":\"@eln\",\n    \"physical_form\":\"@eln\",\n    \"temperature\":\"@eln\",\n    \"temperature/@units\":\"@eln\"\n  },\n  \"/ENTRY/data\": {\n    \"@axes\":[\"x_values\"],\n    \"@signal\": \"data\",\n    \"data\": \"@data:y_values\",\n    \"data/@units\": \"@attrs:data/y_units\",   \n    \"x_values/@units\": \"@attrs:data/x_units\",\n    \"x_values/@units\": \"@data:x_values\"\n  }\n}\n</code></pre> <p>Note that here we are using <code>@</code>-prefixes which are used to fill the template from the different data sources. We discuss this below in more detail.</p> <p>We also implement a method for setting the config file in the reader:</p> reader.py<pre><code>def set_config_file(self, file_path: str) -&gt; dict[str, Any]:\n    if self.config_file is not None:\n        logger.info(\n            f\"Config file already set. Replaced by the new file {file_path}.\"\n        )\n    self.config_file = file_path\n\n    return {}\n</code></pre>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#filling-the-template-from-the-read-in-data","title":"Filling the template from the read-in data","text":"<p>Finally, after reading in all of the data and metadata as well as designing the config file, we can start filling the template. For this, we must implement functions that are called using the reader's callbacks.</p> <p>We will start with the <code>@attrs</code> prefix, associated with the <code>attrs_callback</code>. We must implement the <code>get_attr</code> method:</p> reader.py<pre><code>def get_attr(self, key: str, path: str) -&gt; Any:\n    \"\"\"\n    Get the metadata that was stored in the main file.\n    \"\"\"\n    if self.hdf5_data is None:\n        return None\n\n    return self.hdf5_data.get(path)\n</code></pre> <p>This method (and all similar callbacks methods) have two inputs:</p> <ol> <li><code>key</code>, which is a key in the config file. Note that here, the generic <code>\"/ENTRY/\"</code> gets replaced by <code>f\"/ENTRY[{entry_name}]/\"</code>, where <code>entry_name</code> is the one of the entries of the <code>self.get_entry_names</code> method.</li> <li><code>path</code>, which is the part of the config value that comes after the <code>@attrs:</code> prefix. For example, for the config value <code>\"@attrs:my-metadata\"</code>, the extracted path is <code>my-metadata</code>.</li> </ol> <p>For the <code>get_attr</code> method, we are making use of the <code>path</code>. For example, for the config value <code>\"@attrs:metadata/instrument/version\"</code>, the extracted path is <code>metadata/instrument/version</code>, which is also one of the keys of the <code>self.hdf5_data</code> dictionary.</p> <p>For the ELN data, we must implement the <code>get_eln_data</code> function that gets called from the <code>eln_callback</code> when using the <code>@eln</code> prefix:</p> reader.py<pre><code>def get_eln_data(self, key: str, path: str) -&gt; Any:\n        \"\"\"Returns data from the given eln path.\"\"\"\n        if self.eln_data is None:\n            return None\n\n        return self.eln_data.get(key)\n</code></pre> <p>Here, we are making use of the fact that we have used <code>CONVERT_DICT</code> in the <code>parse_yml</code> function above. Thus, the keys of the <code>self.eln_data</code> dictionary are exactly the same as those in the config file (for example, the config key <code>\"/ENTRY[entry]/USER[user]/address\"</code> also exists in <code>self.eln_data</code>). Therefore, we can just get this data using the <code>key</code> coming from the config file.</p> <p>Finally, we also need to address the <code>@data</code> prefix, which gets used in the <code>data_callback</code> to populate the NXdata group in the template. Note that here we use the same <code>@data</code> prefix to fill the <code>x_values</code> as well as the <code>data</code> (from <code>y_values</code>) fields. We achieve this by using the path that follows <code>@data:</code> in the config file:</p> reader.py<pre><code>def get_data(self, key: str, path: str) -&gt; Any:\n    \"\"\"Returns measurement data from the given hdf5 path.\"\"\"\n    if path.endswith((\"x_values\", \"y_values\")):\n        return self.hdf5_data.get(f\"data/{path}\")\n    else:\n        logger.warning(f\"No axis name corresponding to the path {path}.\")\n</code></pre>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#bringing-it-all-together","title":"Bringing it all together","text":"<p>Et voil\u00e0! That's all we need to read in our data and populate the <code>NXsimple</code> template. Our final reader looks like this:</p> reader.py<pre><code>import logging\nfrom typing import Any\nimport h5py\n\nfrom pynxtools.dataconverter.readers.multi.reader import MultiFormatReader\nfrom pynxtools.dataconverter.readers.utils import parse_yml\n\nlogger = logging.getLogger(\"pynxtools\")\n\nCONVERT_DICT = {\n    \"unit\": \"@units\",\n    \"version\": \"@version\",\n    \"user\": \"USER[user]\",\n    \"instrument\": \"INSTRUMENT[instrument]\",\n    \"detector\": \"DETECTOR[detector]\",\n    \"sample\": \"SAMPLE[sample]\",\n}\n\n\nclass MyDataReader(MultiFormatReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    supported_nxdls = [\n        \"NXsimple\"\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.extensions = {\n            \".yml\": self.handle_eln_file,\n            \".yaml\": self.handle_eln_file,\n           \".json\": self.set_config_file,\n            \".hdf5\": self.handle_hdf5_file,\n            \".h5\": self.handle_hdf5_file,\n        }\n\n    def set_config_file(self, file_path: str) -&gt; dict[str, Any]:\n        if self.config_file is not None:\n            logger.info(\n                f\"Config file already set. Replaced by the new file {file_path}.\"\n            )\n        self.config_file = file_path\n        return {}\n\n    def handle_hdf5_file(self, filepath) -&gt; dict[str, Any]:\n        def recursively_read_group(group, path=\"\"):\n            result = {}\n            for key, item in group.items():\n                new_path = f\"{path}/{key}\" if path else key\n                if isinstance(item, h5py.Group):\n                    # Recursively read subgroups\n                    result.update(recursively_read_group(item, new_path))\n                elif isinstance(item, h5py.Dataset):\n                    # Read datasets\n                    result[new_path] = item[()]\n            return result\n\n        # Open the HDF5 file and read its contents\n        with h5py.File(filepath, \"r\") as hdf:\n            self.hdf5_data = recursively_read_group(hdf)\n\n        return {}\n\n    def handle_eln_file(self, file_path: str) -&gt; dict[str, Any]:\n        self.eln_data = parse_yml(\n            file_path,\n            convert_dict=CONVERT_DICT,\n            parent_key=\"/ENTRY[entry]\",\n        )\n\n        return {}\n\n    def get_attr(self, key: str, path: str) -&gt; Any:\n        \"\"\"\n        Get the metadata that was stored in the main file.\n        \"\"\"\n        if self.hdf5_data is None:\n            return None\n\n        return self.hdf5_data.get(path)\n\n    def get_eln_data(self, key: str, path: str) -&gt; Any:\n        \"\"\"Returns data from the given eln path.\"\"\"\n        if self.eln_data is None:\n            return None\n\n        return self.eln_data.get(key)\n\n    def get_data(self, key: str, path: str) -&gt; Any:\n        \"\"\"Returns measurement data from the given hdf5 path.\"\"\"\n        if path.endswith((\"x_values\", \"y_values\")):\n            return self.hdf5_data.get(f\"data/{path}\")\n        else:\n            logger.warning(f\"No axis name corresponding to the path {path}.\")  \n\nREADER = MyDataReader\n</code></pre>"},{"location":"how-tos/pynxtools/use-multi-format-reader.html#using-the-reader","title":"Using the reader","text":"<p>We can call our reader using the following command</p> <pre><code>dataconverter mock_data.h5 eln_data.yaml -c config_file --reader mydatareader --nxdl NXsimple  --output output.nxs\n</code></pre> <p>The final <code>output.nxs</code> file gets automatically validated against <code>NXsimple</code>, so we can be sure that it is compliant with that application definition. Here is a look at our final NeXus file:</p> <p></p>"},{"location":"how-tos/pynxtools/using-pynxtools-test-framework.html","title":"Test functionality for <code>pynxtools</code> plugins","text":"<p><code>pynxtools</code> contains a sub-module called <code>testing</code> which should be utilized to write automated tests for <code>pynxtools</code> reader plugins. This enables comprehensive tests of the plugin's functionality without needing detailed knowledge of the internal architecture of <code>pynxtools</code>, the technical details of the raw data files, or the plugin\u2019s internal design.</p> <p>Note</p> <p>It is assumed that the plugin has the same structure internally as the existing <code>pynxtools</code> plugins.</p>"},{"location":"how-tos/pynxtools/using-pynxtools-test-framework.html#why-we-need-a-test-framework","title":"Why we need a test framework","text":"<p>To test integration of a plugin with the <code>pynxtools</code> core system, we need to:</p> <ol> <li>Test the plugin's integration with <code>pynxtools</code> from the plugin's CI/CD.</li> <li>Test in the <code>pynxtools</code> CI/CD if the plugin can be integrated with <code>pynxtools</code> properly.</li> </ol>"},{"location":"how-tos/pynxtools/using-pynxtools-test-framework.html#how-to-write-an-integration-test-for-a-reader-plugin-with-pynxtoolstesting","title":"How to write an integration test for a reader plugin with <code>pynxtools.testing</code>","text":"<p>It is very simple to write a test to verify the plugin integration with <code>pynxtools</code> within the plugin's tests directory. The developer can place the test where they want, but they need to use the provided test interface from <code>pynxtools.testing</code>. An example test for a demo plugin <code>pynxtools-FOO</code> (which contains a reader called <code>foo</code> for an application definition <code>NXfoo</code>) is given below:</p> test_plugin.py<pre><code>import os\n\nimport pytest\nfrom pynxtools.testing.nexus_conversion import ReaderTest\n\n# e.g. module_dir = /pynxtools-foo/tests\nmodule_dir = os.path.dirname(os.path.abspath(__file__))\n\n\n@pytest.mark.parametrize(\n    \"nxdl,reader_name,files_or_dir\",\n    [\n        (\"NXfoo\", \"foo\", f\"{module_dir}/../tests/data/test_data_dir_1\"),\n        (\"NXfoo\", \"foo\", f\"{module_dir}/../tests/data/test_data_dir_2\")\n    ],\n)\ndef test_foo_reader(nxdl, reader_name, files_or_dir, tmp_path, caplog):\n    \"\"\"Test for the FooReader or foo reader plugin.\n\n    Parameters\n    ----------\n    nxdl : str\n        Name of the NXDL application definition that is to be tested by\n        this reader plugin (e.g. NXfoo), without the file ending .nxdl.xml.\n    reader_name : str\n        Name of the class of the reader (e.g. \"foo\")\n    files_or_dir : class\n        Name of the class of the reader.\n    tmp_path : pytest.fixture\n        Pytest fixture variable, used to create temporary file and clean up the generated files\n        after test.\n    caplog : pytest.fixture\n        Pytest fixture variable, used to capture the log messages during the test.\n    \"\"\"\n    # test plugin reader\n    test = ReaderTest(nxdl, reader_name, files_or_dir, tmp_path, caplog)\n    test.convert_to_nexus()\n    # test.convert_to_nexus(caplog_level=\"ERROR\", ignore_undocumented=True)\n    # Use `ignore_undocumented` to skip undocumented fields\n    # caplog_level can be \"ERROR\" or \"WARNING\"\n    test.check_reproducibility_of_nexus()\n    # Here, you can also pass `ignore_lines` (a list) or `ignore_sections` (a dict)\n    # if you want to ignore certain lines or lines within a section in the comparison\n    # of the log files of the reference -nxs file and the one created in the test.\n</code></pre> <p>Alongside the test data in <code>tests/data</code>, it is also possible to add other types of test data inside the test directory of the plugin.</p> <p>You can also pass additional parameters to <code>test.convert_to_nexus</code>:</p> <ul> <li> <p><code>caplog_level</code> (str): This parameter determines the level at which the caplog is set during testing. This can be either \"ERROR\" (by default) or \"WARNING\". If it is \"WARNING\", the test will also fail if any warnings are reported by the reader.</p> </li> <li> <p><code>ignore_undocumented</code> (boolean): If true, the test skips the verification of undocumented keys. Otherwise, a warning message for undocumented keys is logged.</p> </li> </ul>"},{"location":"how-tos/pynxtools/using-pynxtools-test-framework.html#how-to-write-an-integration-test-for-a-nomad-example-in-a-reader-plugin","title":"How to write an integration test for a NOMAD example in a reader plugin","text":"<p>It is also possible to ship NOMAD Example Uploads directly with the reader plugin. As an example, <code>pynxtools-mpes</code> comes with its own NOMAD example (see here) using the <code>ExampleUploadEntryPoint</code> of NOMAD (see here for more documentation).</p> <p>The <code>testing</code> sub-package of <code>pynxtools</code> provides two functionalities for testing the <code>ExampleUploadEntryPoint</code> defined in a <code>pynxtools</code> plugin:</p> <ol> <li>Test that the <code>ExampleUploadEntryPoint</code> instance can be properly loaded.</li> <li>Test that the schemas and files in the example folder(s) can be parsed by NOMAD.</li> </ol> <p>We will write a test for a <code>pynxtools_foo_example_entrypoint</code> defined in the pyproject.toml file of a demo <code>pynxtools-FOO</code> repository. Here the actual example data resides in the folder <code>src/pynxtools_foo/nomad/examples</code> and the plugin package is called <code>pynxtools_foo</code>:</p> pyproject.toml<pre><code>[project.entry-points.'nomad.plugin']\npynxtools_foo_example = \"pynxtools_foo.nomad.entrypoints:pynxtools_foo_example_entrypoint\"\n</code></pre> src/pynxtools_foo/nomad/nomad_example_entrypoint.py<pre><code>from nomad.config.models.plugins import ExampleUploadEntryPoint\n\npynxtools_foo_example_entrypoint = ExampleUploadEntryPoint(\n    title=\"My example upload\",\n    description=\"This is an example upload for the pynxtools-FOO package.\",\n    plugin_package=\"pynxtools_foo\",\n    resources=[\"nomad/examples/*\"],\n)\n</code></pre> <p>A test for the <code>pynxtools_foo_example_entrypoint</code> could look like this:</p> test_nomad_examples.py<pre><code>import nomad\n\nfrom pynxtools.testing.nomad_example import (\n    get_file_parameter,\n    parse_nomad_examples,\n    example_upload_entry_point_valid,\n)\n\nfrom pynxtools_foo.nomad.entrypoints import pynxtools_foo_example_entrypoint\n\nEXAMPLE_PATH = os.path.join(\n    os.path.dirname(__file__),\n    \"..\",\n    \"src\",\n    \"pynxtools_foo\",\n    \"nomad\",\n    \"examples\",\n)\n\n@pytest.mark.parametrize(\n    \"mainfile\",\n    get_file_parameter(EXAMPLE_PATH),\n)\ndef test_parse_nomad_examples(mainfile):\n    \"\"\"Test if NOMAD examples work.\"\"\"\n    archive_dict = parse_nomad_examples(mainfile)\n    # Here, you can also implement more logic if you know the contents of the `archive_dict`.\n\n\n@pytest.mark.parametrize(\n    (\"entrypoint\", \"example_path\"),\n    [\n        pytest.param(\n            pynxtools_foo_example_entrypoint,\n            EXAMPLE_PATH,\n            id=\"pynxtools_foo_example\",\n        ),\n    ],\n)\ndef test_example_upload_entry_point_valid(entrypoint, example_path):\n    \"\"\"Test if NOMAD ExampleUploadEntryPoint works.\"\"\"\n    example_upload_entry_point_valid(\n        entrypoint=entrypoint,\n        example_path=example_path,\n    )\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html","title":"Validation of NeXus files","text":"<p>Note: This is a how-to guide for using different tools to validate NeXus files. If you want to learn more about how validation is done in <code>pynxtools</code>, please visit the explanation page.</p> <p>In this how-to guide, we will learn how to use different software tools to validate existing NeXus files. Specifically, we want to use tools to validate NeXus files against a given set of NeXus definitions. This can be the official version of the NeXus definitions or a different version used for local development. Here, we will work with two different versions of the definitions.</p> <ol> <li> <p>Definitions standardized by the NeXus International Advisory Committee (NIAC)</p> </li> <li> <p>FAIRmat NeXus proposal</p> </li> </ol>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#validation-of-a-nxs-file","title":"Validation of a .nxs file","text":"<p>The validity of NeXus files is fundamental to ensure FAIR data. Without specific requirements, it is not possible to understand the data. What type of experiment? What Laser Wavelength? Which voltage? What data is represented in a table? What is the unit of a value? Which ISO norm does this refer to? Where was this measured? Which year was this measured?</p> <p>The NeXus application definitions define the minimum set of terms that must be reported for a given experiment (i.e., the required terms that you must add to the NeXus file in order to be compliant with that application definition). Application definitions may also define terms that are optional in the NeXus data file. The requirements are set by the community via workshops or at conferences.</p> <p>Oftentimes, there will be errors in a generated NeXus file: Typos, missing required concepts, missing attributes, using the incorrect datatype or format (e.g., array instead of list, float instead of integer, etc.). Therefore, a validation is required, to ensure that the data you want to share is FAIR.</p> <p>NeXus files are considered valid if they comply with the respective NeXus application definition.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#validation-software","title":"Validation software","text":"<p>There are several tools which can be used for validation of NeXus files. All are different and have individual advantages or disadvantages:</p> <ol> <li> <p>pynxtools - our own software tool</p> </li> <li> <p>cnxvalidate</p> </li> <li> <p>punx</p> </li> </ol> A note on operating systems <p>Most of these tools were developed using Linux as operating system. If you are on Windows, some of them may not work or you will need additional installation steps than those documented. If you are used to Windows, consider setting up a Linux operating system to eliminate problems in the installation process and ensure compatibility.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#pynxtools","title":"pynxtools","text":"<p>pynxtools = Python Nexus Tools</p> <p>&gt; learn more about validation in pynxtools &lt;</p> <p>This is a python package which is developed by the FAIRmat consortium.</p> <p>As a python package, this can be used on Linux and Windows systems.</p> <p>The package can be installed via pip. Therefore you need to have installed:</p> <ol> <li> <p>python</p> </li> <li> <p>pip</p> </li> </ol> <p>For validation purposes, we will use the \"read_nexus\" and \"verify_nexus\" command line tools from <code>pynxtools</code>.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#pynxtools-verify_nexus","title":"pynxtools - verify_nexus","text":"<p>This tool is currently in development. It enables a command like:</p> <pre><code>verify_nexus C:\\nexusvalidation\\Raman.nxs\n</code></pre> <p>The output warning looks like this:</p> <pre><code>...\nWARNING: Field /entry/instrument/beam_incident/wavelength/@units written without documentation.\n...\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#installation-of-verify_nexus","title":"Installation of verify_nexus","text":"<p>The <code>verify_nexus</code> function is currently under development (July 2025). Therefore, you have to install pynxtools from its feature branch until this function is published.</p> <p>You can install the development version of <code>pynxtools</code> using this feature branch:</p> uvpip <pre><code>uv pip install git+https://github.com/FAIRmat-NFDI/pynxtools@hdf-based-validation\n</code></pre> <pre><code>pip install git+https://github.com/FAIRmat-NFDI/pynxtools@hdf-based-validation\n</code></pre> <p>This installs a command line tool called <code>verify_nexus</code>. You can call its help function:</p> <pre><code>verify_nexus --help\n</code></pre> <p>with this output:</p> <pre><code>Usage: verify_nexus [OPTIONS] FILE\n\n  Verifies a nexus file\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> Development version installation <p>If this installation procedure above does not work, you can use the development installation by using git:</p> <pre><code>python -m venv .py39\nsource .py39/bin/activate\ngit clone https://github.com/FAIRmat-NFDI/pynxtools.git\ncd pynxtools/\ngit checkout hdf-based-validation\ngit submodule sync \u2013recursive\ngit submodule update --init --recursive --jobs=4\nuv pip install --upgrade pip\nuv pip install -e .\nuv pip install -e \".[dev]\u201c\nverify_nexus --help\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#using-verify_nexus","title":"Using <code>verify_nexus</code>","text":"<p>We will use the <code>verify_nexus</code> using an example file containing data in the <code>NXraman</code> format:</p> <p>Download Raman.nxs file</p> <p>Invoke <code>verify_nexus</code> with the command:</p> <pre><code>verify_nexus Raman.nxs\n</code></pre> <p>The respective output is:</p> <pre><code>WARNING: Field /entry/data/spectrum_data_x/@units written without documentation.\nWARNING: Field /entry/data/spectrum_data_x_Raman/@units written without documentation.\nWARNING: Field /entry/data/spectrum_data_y/@units written without documentation.\nWARNING: Field /entry/instrument/beam_incident/wavelength/@units written without documentation.\nWARNING: Field /entry/instrument/detector_DU970BV/number_of_cycles/@units written without documentation.\nInvalid: The entry `entry` in file `Raman.nxs` is NOT a valid file according to the `NXraman` application definition.\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#pynxtools-read_nexus","title":"<code>pynxtools</code> - <code>read_nexus</code>","text":"<p>While <code>verify_nexus</code> is used as a tool for validating a NeXus file, <code>read_nexus</code> is an annotator tools. It outputs a debug log for a given NeXus file by annotating the data and metadata entries with the definitions from the respective NeXus base classes and application definitions to which the file refers to. This can be helpful to extract documentation and understand the concept defined in the NeXus application definition. The command used is:</p> <pre><code>read_nexus -f NXopt_minimal_example.nxs\n</code></pre> <p>The output looks like this, if the respective entry is found:</p> <pre><code>DEBUG: ===== FIELD (//entry/experiment_type): &lt;HDF5 dataset \"experiment_type\": shape (), type \"|O\"&gt;\nDEBUG: value: b'transmission spectroscopy' \nDEBUG: classpath: ['NXentry', 'NX_CHAR']\nDEBUG: classes:\nNXoptical_spectroscopy.nxdl.xml:/ENTRY/experiment_type\nDEBUG: &lt;&lt;REQUIRED&gt;&gt;\nDEBUG: enumeration (NXoptical_spectroscopy.nxdl.xml:/ENTRY/experiment_type):\nDEBUG: -&gt; photoluminescence\nDEBUG: -&gt; transmission spectroscopy\nDEBUG: -&gt; reflection spectroscopy\nDEBUG: -&gt; other\nDEBUG: documentation (NXoptical_spectroscopy.nxdl.xml:/ENTRY/experiment_type):\nDEBUG: \n                 Specify the type of the optical experiment.\n\n                 Chose other if none of these methods are suitable. You may specify\n                 fundamental characteristics or properties in the experimental sub-type.\n\n                 For Raman spectroscopy or ellipsometry use the respective specializations\n                 of NXoptical_spectroscopy.\n</code></pre> <p>or like this, if the respective entry is not found in the definition:</p> <pre><code>DEBUG: ===== ATTRS (//entry/instrument/software_RC2/program@url)\nDEBUG: value: https://www.jawoollam.com/ellipsometry-software/completeease \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\nDEBUG:\n</code></pre> <p>The first example was for for <code>experiment_type</code> entry in the <code>NXoptical_spectroscopy</code> definition.</p> <p>The second example was for the <code>software_TYPE</code> attribute <code>@URL</code> entry in the <code>NXoptical_spectroscopy</code> definition. Here the problem was that \"url\" was used instead of \"URL\".</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#using-read_nexus","title":"Using <code>read_nexus</code>","text":"<p>We will demonstrate the usage of <code>read_nexus</code> using the Raman.nxs file from above.</p> <p>To trigger the annotator tool, use:</p> <pre><code>read_nexus -f Raman.nxs\n</code></pre> <p>The output will look like this:</p> <pre><code>===== FIELD (//entry/data/spectrum_data_y): &lt;HDF5 dataset \"spectrum_data_y\": shape (1600,), type \"&lt;f8\"&gt;\nDEBUG: ===== FIELD (//entry/data/spectrum_data_y): &lt;HDF5 dataset \"spectrum_data_y\": shape (1600,), type \"&lt;f8\"&gt;\nvalue: [ 288.5499878  289.         288.4500122 ... 1875.        1889.349976 ...\nDEBUG: value: [ 288.5499878  289.         288.4500122 ... 1875.        1889.349976 ...\nDataset referenced as NXdata SIGNAL\nDEBUG: Dataset referenced as NXdata SIGNAL\n===== ATTRS (//entry/data/spectrum_data_y@long_name)\nDEBUG: ===== ATTRS (//entry/data/spectrum_data_y@long_name)\nvalue: Raman Intensity \nDEBUG: value: Raman Intensity \nDataset referenced as NXdata SIGNAL\nDEBUG: Dataset referenced as NXdata SIGNAL\n===== ATTRS (//entry/data/spectrum_data_y@units)\nDEBUG: ===== ATTRS (//entry/data/spectrum_data_y@units)\nvalue: counts \nDEBUG: value: counts \n\nDEBUG: \nFor Axis #0, 1 axes have been identified: [&lt;HDF5 dataset \"spectrum_data_x_Raman\": shape (1600,), type \"&lt;f8\"&gt;]\nDEBUG: For Axis #0, 1 axes have been identified: [&lt;HDF5 dataset \"spectrum_data_x_Raman\": shape (1600,), type \"&lt;f8\"&gt;]\n</code></pre> <p>Search for fields which are not found in the NeXus definition by searching for the line: \"DEBUG: NOT IN SCHEMA\". Recheck the used NeXus definition to eliminate the problem. Be careful with upper and lower case notation and correct spelling.</p> <p>Keep in mind that the output provides quite some information. This is useful for software development, but may be a bit too much for validation purposes.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#cnxvalidate","title":"cnxvalidate","text":"<p>This package is written in C. It is allows a command line evocation like:</p> <pre><code>nxvalidate -l appdefdir datafile\n</code></pre> <ol> <li> <p><code>nxvalidate</code>: calls the software function</p> </li> <li> <p><code>\\-l appdefdir</code>: points to the location of the NeXus definitions you want to use. This is a path to a folder called \"definitions\".</p> </li> <li> <p><code>datafile</code>: This is the path to the .nxs file which should be checked.</p> </li> </ol> <p>This output shows warnings like:</p> <pre><code>definition=NXoptical_spectroscopy.nxdl.xml message=\"Required attribute URL missing\" nxdlPath=/NXentry/definition sev=error dataPath=/entry/definition dataFile=NXopt_minimal_example.nxs\n</code></pre> <p>and indicates the entry of the .nxs file, which is incorrect and what the respective problem is. It also points to the NeXus definition (.nxdl.xml file), in which this conflict was found.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#installation","title":"Installation","text":"A note on operating systems <p>You can find more information about installing nxvalidate here. Note that installation on Windows can be tricky because cmake can sometimes not find the libxml2 library. Though, if you solve this, this maybe work on windows. Therefore, we recommend to use Linux.</p> <p>The software has to be built from source. This is eased significantly by using another software called <code>cmake</code>.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#install-cmake-github-hdf5-xml2-library","title":"Install cmake, github, HDF5 &amp; xml2 library","text":"<p>Open the terminal and install all parts required to install cnxvalidate via cmake:</p> <pre><code>sudo apt-get update\nsudo apt-get install git\nsudo apt-get install build-essential\nsudo add-apt-repository universe\nsudo apt-get install libhdf5-serial-dev\nsudo apt-get -y install pkg-config     \nsudo apt upgrade -y\nsudo apt-get -y install cmake\nsudo apt-get install libxml2-dev\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#directory-location","title":"Directory location","text":"<p>Create a folder named \"nexusvalidation\" via terminal or file manager.</p> <p>The folder is located at <code>/home/USER/nexusvalidation</code></p> <p>Enter this directory by:</p> <pre><code>cd /home/USER/nexusvalidation\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#closing-the-github-repository","title":"Closing the Github repository","text":"<p>The software is available in the Github Repository of cnxvalidate:</p> <p>Clone the GitHub repository:</p> <pre><code>git clone https://github.com/nexusformat/cnxvalidate.git\n</code></pre> <p>Now you have a new folder at <code>~/nexusvalidation/cnxvalidate</code></p> <p>go into this folder via the command</p> <pre><code>cd cnxvalidate\n</code></pre> <p>Make a new directory called \"build\" and enter it:</p> <pre><code>mkdir build\n</code></pre> <p>Use cmake, to compile/build the software - this puts together all pieces of software, especially external parts such as xml2 and hdf5 library.</p> <pre><code>cmake .\n</code></pre> <p>install cnxvalidate after it was successfully build</p> <pre><code>cd build\nmake\n</code></pre> <p>Now the above mentioned commands should be available. The program/executable is located at:</p> <pre><code>/home/USER/nexusvalidation/cnxvalidate/build/nxvalidate\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#using-cnxvalidate","title":"Using cnxvalidate","text":"<p>Now you can start to validate your created NeXus file. But before the validation, we need to get a set of NeXus definitions, which we want to use as reference. This is done again by using git:</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#getting-nexus-definitions","title":"Getting NeXus definitions","text":"<p>Go to the folder <code>nexusvalidation</code></p> <pre><code>cd /home/USER/nexusvalidation\n</code></pre> <p>Download a set of NeXus definitions. Choose only one:</p> <p>For FAIRmat NeXus definitions, clone the repository:</p> <pre><code>git clone https://github.com/FAIRmat-NFDI/nexus_definitions.git definitions/\n</code></pre> <p>For the NIAC NeXus definitions:</p> <pre><code>git clone https://github.com/nexusformat/definitions.git\n</code></pre> <p>Now you have a folder called \"definitions\" in the \"nexusvalidation\" folder. The path to this definitions folder is used as option for <code>cnxvalidate</code>, to tell the program which NeXus definitions shall be used.</p> <p>The respective path would be:</p> <pre><code>/home/USER/nexusvalidation/definitions\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#choose-your-nexus-file","title":"Choose your NeXus file","text":"<p>Put one of created NeXus file (or this this file) into the \"nexusvalidation\" folder (filemanager/explorer).</p> <p>The file should now be located at (assumed the file name is \"NXopt_minimal_example.nxs\")</p> <pre><code>/home/USER/nexusvalidation/NXopt_minimal_example.nxs\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#validating-the-nexus-file","title":"Validating the NeXus file","text":"<p>Now you can use <code>cnxvalidate</code> with the executable called <code>nxvalidate</code> to validate the NeXus file called <code>datafile\u00b4(using the set of NeXus definitions in</code>appdefdir`:</p> <pre><code>nxvalidate -l appdefdir datafile\n</code></pre> <p>All names are \"paths\" to the definition, application or file. Use the \"full path\", if you are not experienced, but relative paths work as well.</p> <p>For the provided example, the suitable command looks like:</p> <pre><code>/home/USER/nexusvalidation/cnxvalidate/build/nxvalidate -l /home/USER/nexusvalidation/definitions /home/USER/nexusvalidation/NXopt_minimal_example.nxs\n</code></pre> <p>The <code>-l</code> option tells the program at which path the local definitions are located.</p> <p>For the file above, the output should look like this:</p> <pre><code>USER@XXX:/home/USER/nexusvalidation/cnxvalidate/build/nxvalidate -l /home/USER/nexusvalidation/definitions /home/USER/nexusvalidation/NXopt_minimal_example.nxs\ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required attribute version missing\" nxdlPath=/NXentry/definition sev=error dataPath=/entry/definition dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required attribute URL missing\" nxdlPath=/NXentry/definition sev=error dataPath=/entry/definition dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required field missing\" nxdlPath=/NXentry/experiment_type sev=error dataPath=/entry/experiment_type dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXinstrument sev=error dataPath=/entry dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXsample sev=error dataPath=/entry dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXdata sev=error dataPath=/entry dataFile=NXopt_minimal_example.nxs \n9 errors and 11 warnings found when validating NXopt_minimal_example.nxs\n</code></pre> <p>The errors tell you now which things are missing (message=\"Required group missing\"), if there is a field missing (message=\"Required field missing\"), or if an attribute is missing (message=\"Required attribute URL missing\" - here for example the attribute named URL)</p> <p>Now adjust the file creation, and add the respective fields to make your NeXus file compliant with the NeXus definitions. This way, you can ensure that your data is FAIR, which is then ready for sharing and publication.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#punx-python-utilities-for-nexus-hdf5-files","title":"punx - Python Utilities for NeXus HDF5 files","text":"<ul> <li>Official punx docs</li> </ul> <p>This is Python package, and can therefore be used on Linux and Windows systems.</p> <p>After installation, you can evoke the validation from the command line:</p> <pre><code>punx validate [-h] [--report REPORT] infile\n</code></pre> <ul> <li><code>validate</code> tells the program that we want to validate a file</li> <li><code>[-h]</code> tells the program to show the help message</li> <li><code>[--report REPORT]</code> tells the program what findings should be reported. This is done by replacing REPORT with any of <code>{COMMENT,ERROR,NOTE,OK,TODO,UNUSED,WARN}</code>.</li> </ul>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#installation_1","title":"Installation","text":"<p>The package can be installed via pip:</p> uvpip <pre><code>uv pip install punx\n</code></pre> <pre><code>pip install punx\n</code></pre> <p>This software is based on other powerful software packages or libraries, therefore some other packages have to be installed as well:</p> uvpip <pre><code>uv pip install h5py\nuv pip install lxml\nuv pip install numpy\nuv pip install PyQt5\nuv pip install requests\nuv pip install pyRestTable\n</code></pre> <pre><code>pip install h5py\npip install lxml\npip install numpy\npip install PyQt5\npip install requests\npip install pyRestTable\n</code></pre> <p>Then you should be able to test the package by:</p> <pre><code>punx demo\n</code></pre> <p>The output should look like this:</p> <pre><code>C:\\&gt;punx demo\n\n!!! WARNING: this program is not ready for distribution.\n\n\nconsole&gt; punx validate C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5\ndata file: C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5\nNeXus definitions: main, dated 2024-01-02 03:04:05, sha=xxxx21fxcef02xfbaa6x04e182e3d67dace7ef1b\n\nfindings\n============================ ======== ==================================== ==========================================================\naddress                      status   test                                 comments\n============================ ======== ==================================== ==========================================================\n/                            TODO     NeXus base class                     NXroot: more validations needed\n/                            OK       known NXDL                           NXroot: recognized NXDL specification\n/                            OK       NeXus base class                     NXroot: known NeXus base class\n/                            OK       NeXus default plot                   found by v3: /Scan/data/counts\n/                            OPTIONAL NXDL group in data file              not found:  in //entry\n/Scan                        TODO     NeXus base class                     NXentry: more validations needed\n/Scan                        OK       group in base class                  not defined: NXroot/Scan\n/Scan                        OK       known NXDL                           NXentry: recognized NXDL specification\n/Scan                        OK       NeXus base class                     NXentry: known NeXus base class\n/Scan                        OK       NXDL group in data file              found:  in /Scan/data\n/Scan                        NOTE     validItemName                        relaxed pattern: [a-zA-Z0-9_]([a-zA-Z0-9_.]*[a-zA-Z0-9_])?\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/collection_description\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/collection_identifier\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/collection_time\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/definition\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/definition_local\n...\n...\n...\n/Scan/data@signal            OK       known attribute                      known: NXdata@signal\n/Scan/data@signal            OK       value of @signal                     found: /Scan/data/counts\n/Scan/data@signal            OK       NeXus default plot v3, NXdata@signal correct default plot setup in /NXentry/NXdata\n/Scan/data@two_theta_indices TODO     attribute value                      implement\n/Scan/data@two_theta_indices OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data@two_theta_indices OK       known attribute                      unknown: NXdata@two_theta_indices\n/Scan/data/counts            OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data/counts            OK       field in base class                  not defined: NXdata/counts\n/Scan/data/counts@units      TODO     attribute value                      implement\n/Scan/data/counts@units      OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data/two_theta         OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data/two_theta         OK       field in base class                  not defined: NXdata/two_theta\n/Scan/data/two_theta@units   TODO     attribute value                      implement\n/Scan/data/two_theta@units   OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n============================ ======== ==================================== ==========================================================\n\n\nsummary statistics\n======== ===== =========================================================== =========\nstatus   count description                                                 (value)\n======== ===== =========================================================== =========\nOK       35    meets NeXus specification                                   100\nNOTE     1     does not meet NeXus specification, but acceptable           75\nWARN     0     does not meet NeXus specification, not generally acceptable 25\nERROR    0     violates NeXus specification                                -10000000\nTODO     7     validation not implemented yet                              0\nUNUSED   0     optional NeXus item not used in data file                   0\nCOMMENT  0     comment from the punx source code                           0\nOPTIONAL 40    allowed by NeXus specification, not identified              99\n         --\nTOTAL    83\n======== ===== =========================================================== =========\n\n&lt;finding&gt;=99.144737 of 76 items reviewed\nNeXus definitions version: main\n\nconsole&gt; punx tree C:\\Users\\rh83hixu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5\nC:\\Users\\rh83hixu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5 : NeXus data file\n  Scan:NXentry\n    @NX_class = \"NXentry\"\n    data:NXdata\n      @NX_class = \"NXdata\"\n      @axes = \"two_theta\"\n      @signal = \"counts\"\n      @two_theta_indices = [0]\n      counts:NX_INT32[31] = [1037, 1318, 1704, '...', 1321]\n        @units = \"counts\"\n      two_theta:NX_FLOAT64[31] = [17.92608, 17.92591, 17.92575, '...', 17.92108]\n        @units = \"degrees\"\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#using-punx","title":"Using punx","text":"<p>We will test <code>punx</code> using this file:</p> <p>Download SiO2onSi.ellips.nxs</p> <p>You can start the <code>punx</code> validation using</p> <pre><code>punx validate C:\\nexusvalidation\\SiO2onSi.ellips.nxs\n</code></pre> <p>The output tables \"findings\" and \"summary statistics\" can be used to find error present in the NeXus file.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#select-a-set-of-nexus-definition","title":"Select a set of NeXus definition","text":"<p>The program selects the NeXus definitions (set of nxdl.xml files) by itself. As of July 2025, only the official definitions from the NIAC repository are available.</p> <p>You may update the repository for the latest version via:</p> <pre><code>punx install\n</code></pre>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#running-the-validation","title":"Running the validation","text":"<p>The NeXus respective definitions are found here.</p> <p>Search on the right side under \"quick search\" for \"NXopt\":</p> <p>NXopt NeXus definition</p> <p>This python code creates the respective Python file with all required fields:</p> <p>NXopt_minimal_example_NIAC_NeXus_Def.nxs</p> <p>Here is the Python code:</p> <p>Download h5py_nexus_file_creation_NIAC_NeXus_Def.py.</p> <p>The command:</p> <pre><code>punx validate --report ERROR C:\\nexusvalidation\\NXopt_minimal_example_NIAC_NeXus_Def.nxs\n</code></pre> <p>then gives this output:</p> <pre><code>findings\n======= ====== ========== ======================================\naddress status test       comments                              \n======= ====== ========== ======================================\n/entry  ERROR  known NXDL NXopt: unrecognized NXDL specification\n======= ====== ========== ======================================\n\n\nsummary statistics\n======== ===== =========================================================== =========\nstatus   count description                                                 (value)  \n======== ===== =========================================================== =========\nOK       148   meets NeXus specification                                   100      \nNOTE     0     does not meet NeXus specification, but acceptable           75       \nWARN     0     does not meet NeXus specification, not generally acceptable 25       \nERROR    1     violates NeXus specification                                -10000000\nTODO     16    validation not implemented yet                              0        \nUNUSED   0     optional NeXus item not used in data file                   0        \nCOMMENT  0     comment from the punx source code                           0        \nOPTIONAL 213   allowed by NeXus specification, not identified              99       \n         --                                                                         \nTOTAL    378                                                                        \n======== ===== =========================================================== =========\n</code></pre> <p>The last error message:</p> <pre><code>======= ====== ========== ======================================\n/entry  ERROR  known NXDL NXopt: unrecognized NXDL specification\n======= ====== ========== ======================================\n</code></pre> <p>can be ignored and is a bug right now. If this is the only Error message, then your NeXus file is compliant with the NeXus definitions and you can share and publish your data.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#further-notes","title":"Further notes","text":"<ol> <li>More details for installation</li> <li>Other punx commands</li> <li>Github project</li> </ol>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#recommended-workflow","title":"Recommended workflow","text":"<p>As the <code>verify_nexus</code> method from <code>pynxtools</code> is right now in development, not all situations are covered right now. Therefore, the most reliable method right now is a combination of Human Manual Validation + Software solutions.</p>"},{"location":"how-tos/pynxtools/validate-nexus-file.html#pynxtools-reader-plugins","title":"Pynxtools Reader Plugins","text":"<p>For a specifically structured set of data, a reader plugin can be written, which uses the meta data and a pre-structured meta data fil, to create a NeXus file. Each reader depends on the given experimental technique/setup and therefore has to be written individually. Take a look at all FAIRmat-supported plugins.</p>"},{"location":"learn/nexus/multiple-appdefs.html","title":"The concept of multiple application definitions","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p> <p>This tutorial showcases how to employ multiple application definitions in NeXus for creating a file that conforms to various definitions simultaneously.</p> <p>Prerequisites</p> <p>Familiarity with the basics of NeXus and its application definitions is required. For an introduction to NeXus, please refer to the basic documentation.</p> <p>In a laboratory setting, the data we collect can vary significantly depending on the experiment's specific setup. Consider, for instance, an experiment characterized using the <code>NXexperiment</code> application definition. Suppose we want to enhance this experiment by incorporating energy resolution details. A straightforward approach might involve creating a specialized sub-application definition, like <code>NXexperiment_energy_resolved</code>, to include metadata about the experiment's energy resolution.</p> <p>While this method is effective for initial expansions of the metadata, it becomes cumbersome when trying to merge multiple enhancements into a single application definition. Imagine we wish to integrate additional elements that provide time resolution data for our experiment.  We need to create three sub application definitions to reflect all combinations: <code>NXexperiment_time_resolved</code>, <code>NXexperiment_energy_resolved</code> and <code>NXexperiment_energy_time_resolved</code>. For three experimental facets we already need 7 sub application definitions. An additional problem is that we have to repeat the whole procedure for all experiments we like to add the specific traits to. So if we have three different parent application definitions we already need to create 9 sub application definitions just to add energy and time resolution.</p> <p>The solution for this problem is to specify multiple application definitions while writing a NeXus file to follow different traits of the experiment. This allows us to simply create <code>NXtime_resolved</code> and <code>NXenergy_resolved</code> and combine it with any experiment we want to use it with. This comes, however, with a few drawbacks. One of them is that it is currently not possible to write a file which wants to use two different application definitions which have conflicting fields. While this is generally possible in the framework of NeXus, since every application definition creates their own namespace, this is not supported when the paths are reduced to entry path notation.</p> <p>ToDo:</p> <ul> <li>Make an example of NXexperiment, NXtime_resolved and NXenergy_resolved and show how it is combined into the instance path.</li> <li>Also show this for a conflict. Compare concept path (no problem) to instance path (colliding).</li> <li>Write a part how it is described in the file that it follows two application definitions <code>/entry/definitions</code> as array containing both application definitions.</li> <li>Explain that this is no problem with the expanded concept path notation but fails when we only use the instance path.</li> <li>Explain the reader concept: One reader for one application definition, then pynxtools will figure out how to combine them (this is domain knowledge for the FAIRmat reader -&gt; will be different when a read/write tool is written somewhere else).</li> </ul>"},{"location":"learn/nexus/nexus-primer.html","title":"A primer on NeXus","text":"<p>NeXus is a common data exchange format initially developed for neutron, X-ray, and muon experiments. Within FAIRmat we extensively extended the format to cover a range of experiments with major support for APM, ARPES, XPS, and optical spectroscopy, but we also give advice and guidance for developing standards for other formats as well.</p>"},{"location":"learn/nexus/nexus-primer.html#what-is-nexus","title":"What is NeXus?","text":"<p>Sometimes, NeXus is seen as writing data to some form of file in HDF5 format. While this is partly true, NeXus is independent of the actual storage format, but is typically written into an HDF5 file.</p> <p>But what is NeXus then? It is the conceptual layer above the file structure. It is a contract on which data has to be present and how to name them in a given dataset. Hence, the use of NeXus helps to make data FAIR. It especially covers the interoperability and reproducibility part of research data.</p> <p>NeXus path notations</p> <p>There are several methods for referencing concepts or data paths within NeXus:</p> <ul> <li> <p>Concept Path Notation: This notation describes the hierarchical structure of NeXus concepts using class names. For example, <code>NXexperiment:/NXentry/NXinstrument/NXdetector</code> indicates the creation of a new NXdetector class within the NXexperiment concept. This path typically forms automatically when an application definition extends a base class's fields.</p> </li> <li> <p>Instance Path Notation: It represents the actual location of a field or group in a NeXus data instance (e.g., an HDF5 file). An example is <code>my_file.nxs:/entry/instrument/detector</code>.</p> </li> <li> <p>Combined Notation: In pynxtools, we sometimes use templates and configuration files to match data instances from other sources to the terms defined in NeXus application definitions and base classes. We represent these NeXus concepts using a mixed notation, where uppercase indicates a selectable (part of the) name and lowercase a fixed name. Examples include <code>NXexperiment:ENTRY[my_experiment.nxs:entry]/INSTRUMENT[instrument]/DETECTOR[detector]</code> and <code>NXexperiment:ENTRY[my_experiment.nxs:entry]/my_INSTRUMENT[my_instrument]/DETECTOR[detector]</code>. In this notation, we combine concept (outside the square brackets) and instance paths (inside the square brackets). The leftmost entries may include the NeXus class or file reference.</p> </li> </ul>"},{"location":"learn/nexus/nexus-primer.html#nexus-as-a-tool-for-fair-data","title":"NeXus as a tool for FAIR data","text":"<p>If you want to build data according to the FAIR principles, you can think of NeXus fulfilling the interoperability and reproducibility part. As NeXus defines commonly used standards for describing experiments in materials science, any data that is written according to the NeXus standard can be compared to any other such data. NeXus application definitions, which exactly define which data is required to describe a given experiments, help to reproduce experiments.</p> <p>If integrated into a research data management (RDM) platform, the findable and accessible part of FAIR can also be fulfilled. We integrate NeXus into the RDM we are developing in FAIRmat: NOMAD. Experimental data following an NeXus application definition can easily be uploaded and is recognized by NOMAD's search system. If you want to learn more about uploading NeXus data to NOMAD, please refer to the NeXus to NOMAD tutorial of this documentation. Since NeXus follows a rigorously defined structure, NOMAD can enabling semantic searches, making it easy to find and access NeXus data.</p>"},{"location":"learn/nexus/nexus-rules.html","title":"Rules for storing data in NeXus","text":"<p>There are several rules which apply for storing single data items in NeXus. There exists a summary in the NeXus documentation outlining most of these rules. However, to guide data providers even further, we have compiled here additional information and explanations.</p>"},{"location":"learn/nexus/nexus-rules.html#name-resolution","title":"Name resolution","text":"<p>In general, the names of NeXus group and field items are validated according to the boundaries outlined in the Rules for Storing Data Items in NeXus Files, section \"NXDL group and field names\":</p> <ul> <li> <p>Recommended names</p> <ul> <li>lower case words separated by underscores and, if needed, with a trailing number</li> </ul> </li> <li> <p>Allowed names</p> <ul> <li>any combination of upper and lower case letter, numbers, underscores and periods, except that periods cannot be at the start or end of the string</li> <li>This statement is equivalent to matching  this regular expression (named <code>validItemName</code> in the nxdl.xsd XML Schema file):</li> </ul> <pre><code>^[a-zA-Z0-9_]([a-zA-Z0-9_.]*[a-zA-Z0-9_])?$\n</code></pre> </li> <li> <p>Invalid names:</p> <ul> <li>any name not matching this <code>validItemName</code> regular expression</li> </ul> </li> </ul> <p>Note that this explicitly also means that it is not allowed to have whitespace (including \" \") in NeXus names.</p> <p>A speciality of NeXus is the possibility to define concept names that are different to the names of the actual data instances. In NeXus base classes and application definitions, there are three options for defining how instances must be named to match to the name of a given concept. This matching is based on a combination of the <code>name</code> and the <code>nameType</code> attributes of the concept.</p> <p>Concept and instance names</p> <p>In NeXus, we must distinguish carefully between names of concepts and the names given to the actual instance of that concept.</p> <ul> <li>Concept Name: This is the name given to a NeXus concept, i.e., on the data modelling level in the NeXus definitions.</li> <li>Instance Name: This is the actual name for a NeXus data instance of the concept (e.g., in an HDF5 file).</li> </ul> <p>There are three different options for the <code>nameType</code> XML attribute:</p> <ul> <li><code>specified</code></li> <li><code>any</code></li> <li><code>partial</code></li> </ul> <p>If <code>nameType=specified</code>, that means that any instance must have the exact same (fixed) name as the concept. As an example, if there is a field called <code>my_field</code> with <code>nameType=specified</code> in an application definition, the only allowed name in a file would be <code>my_field</code>. Note that this is also true for concept names containing uppercase letters. \"specified\" is the default <code>nameType</code>, i.e., if no <code>nameType</code> is given, it is assumed that any instance name must match the concept name directly</p> <p>In addition, there is also the option to allow for selectable names. This is achieved by <code>nameType=any</code> or <code>nameType=partial</code>.</p> <p>If the <code>nameType</code> is any, that means that the concept name can be matched by any instance name, as long as it matches the regular expression above. As an example. As an example, if a field in an application definition is called <code>FIELD</code> and has <code>nameType=any</code>, <code>field</code>, <code>field0</code>, <code>any_other_name</code> would be allowed names, while <code>any other name</code> would not be allowed.</p> <p>There is also the possibility to fix a subpart of the name using <code>nameType=partial</code>. In this case, it important which characters in the concept name are lowercase and which are uppercase. Those characters that are uppercase may be replaced by any other string, as long as the final instance name is still valid according to the regex above. For example, there might be a <code>userID</code> group. In this case, allowed names include any name that start with <code>user</code>, e.g., <code>user0</code>, <code>user_abcde</code>,  Note that here it is also allowed to write <code>user</code>, i.e., replacing the uppercase part of the name with an empty string.</p> <p>The validation of names is performed by namefitting, i.e., fitting the name that is used by the data provider to the name given in the base class / application definitions.</p> <p>A python implementation of this process can be found in this function. This function returns twice the length for an exact match, otherwise the number of matching characters (case insensitive) or zero, if <code>name_any</code> is set to True, is returned. This is also the function that is used in the validation implemented in <code>pynxtools</code>.</p>"},{"location":"learn/nexus/nexus-rules.html#special-rules-for-names-and-namefitting","title":"Special rules for names and namefitting","text":"<p>Aside from these general rules, there are a number of special rules for NeXus names that need to be considered:</p> <ul> <li> <p>There is a set of UPPERCASE reserved words (like <code>BLUESKY_</code>, <code>DECTRIS_</code>, <code>IDF_</code>, etc.) that are reserved for certain projects and communities. These are prefixes (typically written as uppercase + underscore) that cannot be overwritten by namefitting. For the full list, see Rules for Storing Data Items in NeXus Files, section \"Reserved prefixes\".</p> </li> <li> <p>There is also a set of reserved suffixes that are used to give additional information for a group or field. For the full list, see Rules for Storing Data Items in NeXus Files, section \"Reserved suffixes\".</p> </li> <li> <p>Additionally to namefitting, data annotation can use further information. For example, in case of NXdata, the axes listed among the <code>@axes</code> shall fit to any instances of <code>AXISNAME</code> and data objects listed in <code>@signal</code> or <code>@auxiliary_signals</code> shall fit to instances of <code>DATA</code>. Such rules are typically given in the base classes (e.g., see here for NXdata). Any tool that makes use of the base classes should implement these special rules in its validation procedure. As an example, pynxtools has a special function for handling NXdata.</p> </li> </ul>"},{"location":"learn/nexus/nexus-rules.html#concept-name-inheritance","title":"Concept name inheritance","text":"<p>Note that NeXus also supports inheritance of concepts. The same rules as for instance names on the data level apply here for the inherited concept names. That is, the name of a concept must match in concept name and <code>nameType</code> to inherit from another concept. As an example, if we define a field with name <code>userID</code> and <code>nameType=\"partial\"</code> in a base class and then use this base class in an application definition, the concept <code>user</code> and <code>nameType=\"specified\"</code> would inherit its property. Contrarily, the concept <code>my_user</code> would not inherit from <code>userID</code>.</p>"},{"location":"learn/pynxtools/dataconverter-and-readers.html","title":"Data conversion in pynxtools","text":"<p>One of the main motivations for pynxtools is to develop a tool for combining various instrument output formats and electronic lab notebook (ELN) into a file according to NeXus application definitions. </p> <p>The <code>dataconverter</code> API in pynxtools provides exactly that: it converts experimental as well as simulation data, together with the results from analysis of such data, to NeXus files based on any provided NXDL schemas. Here, we are using HDF5 as the serialization format.</p> <p>The dataconverter currently has essentially three functionalities:</p> <ol> <li>Read in experimental data using <code>readers</code></li> <li>Validate the data and metadata against a NeXus application definition of choice (i.e., check that the output data matches all existence, shape, and format constraints of application definition)</li> <li>Write a valid NeXus/HDF5 file</li> </ol> <p>A set of readers has been developed which the converter calls to read in a set of experiment/method-specific file(s) and for a specific set of application definitions (NXDL XML file). These data files can be in a proprietary format, or of a certain format used in the respective scientific community, or text files. Only in combination, these files hold all the required pieces of information which the application definition demands and which are thus required to make a NeXus/HDF5 file compliant. Users can store additional pieces of information in an NeXus/HDF5 file. In this case readers will issue a warning that these data are not properly documented from the perspective of NeXus.</p> <p>There exists two different subsets of readers:</p> <ol> <li>Built-in readers, which are implemented directly in pynxtools and are typically used either as superclasses for new reader implementations or for generic reading purposes not directly related to any specific technique.</li> <li>Reader plugins for `pynxtools, which are used for reading data of specific experimental techniques and are typically available as their own Python packages.</li> </ol>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#matching-to-nexus-application-definitions","title":"Matching to NeXus application definitions","text":"<p>The purpose of the dataconverter is to create NeXus/HDF5 files with content that matches a specific NeXus application definition. Such application definitions are useful for collecting a set of pieces of information about a specific experiment in a given scientific field. The pieces of information are numerical and categorical (meta)data. The application definition is used to provide these data in a format that serves a data delivery contract: The HDF5 file, or so-called NeXus file, delivers all those pieces of information which the application definition specifies. Required and optional pieces of information are distinguished. NeXus classes can recommend the inclusion of certain pieces of information. Recommended data are essentially optional. The idea is that flagging these data as recommended motivates users to collect these, but does not require to write dummy or nonsense data if the recommended data is not available.</p>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#getting-started","title":"Getting started","text":"<p>You should start by installing <code>pynxtools</code> and (if needed) one or more of its supported plugins.</p> <ul> <li>Installation</li> </ul>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#usage","title":"Usage","text":"<p>See here for the documentation of the <code>dataconverter</code> API.</p>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#use-with-multiple-input-files","title":"Use with multiple input files","text":"<pre><code>dataconverter metadata data.raw otherfile --nxdl nxdl --reader &lt;reader-name&gt;\n</code></pre>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#merge-partial-nexus-files-into-one","title":"Merge partial NeXus files into one","text":"<pre><code>dataconverter --nxdl nxdl partial1.nxs partial2.nxs\n</code></pre>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#map-an-hdf5-filejson-file","title":"Map an HDF5 file/JSON file","text":"<pre><code>dataconverter --nxdl nxdl any_data.hdf5 --mapping my_custom_map.mapping.json\n</code></pre> <p>You can find actual examples with data files at <code>examples/json_map</code>.</p>"},{"location":"learn/pynxtools/dataconverter-and-readers.html#example-data-for-testing-and-development-purposes","title":"Example data for testing and development purposes","text":"<p>Before using your own data we strongly encourage you to download a set of open-source test data for testing the pynxtools readers and reader  plugins. For this purpose, pynxtools and its plugins come with <code>examples</code> and <code>test</code> directories including reader-specific examples. These examples can be used for downloading test data and use specific readers as a standalone converter to translate given data into a NeXus/HDF5 file.</p> <p>Once you have practiced with these tools how to convert these examples, feel free to use the tools for converting your own data. You should feel invited to contact the respective corresponding author(s) of each reader if you run into issues with the reader or feel there is a necessity to include additional data into the NeXus file for your respective application.</p> <p>We are looking forward to learning from your experience and learn from your use cases. You can find the contact persons here or in the respective documentation of each reader (plugin).</p>"},{"location":"learn/pynxtools/multi-format-reader.html","title":"The MultiFormatReader as a reader superclass","text":"<p>There are three options for building a new <code>pynxtools</code> reader:</p> <ol> <li>build the reader from scratch</li> <li>inherit and extend the <code>BaseReader</code></li> <li>inherit and extend the <code>MultiFormatReader</code></li> </ol> <p>While option 1 is generally not recommended, inheriting and extending the <code>BaseReader</code> has traditionally been the default solution for all existing pynxtools readers and reader plugins. The <code>BaseReader</code>, which is an abstract base class, has an essentially empty <code>read</code> function and is  thus only helpful for implementing the correct input/output design of the <code>read</code> function of any reader which is implemented off of it.</p> <p>While building on the <code>BaseReader</code> allows for the most flexibility, in most cases it is desirable to implement a reader that can read in multiple file formats and then populate the NeXus file based on the read data, in compliance with a NeXus application definition. For this purpose, <code>pynxtools</code> has the <code>MultiFormatReader</code>, which can be readily extended for any new data.</p> <p>Here, we will explain the inner workings of the <code>MultiFormatReader</code>. Note that there is also a how-to guide on how to implement a new reader off of the <code>MultiFormatReader</code> using a concrete example. In case you simply want to use the <code>MultiFormatReader</code> without understanding its inner logic, we recommend you start there.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#the-basic-structure","title":"The basic structure","text":"<p>For extending the <code>MultiFormatReader</code>, the following basic structure must be implemented:</p> multi/reader.py<pre><code>\"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\nfrom typing import Any\n\nfrom pynxtools.dataconverter.readers.base.reader import MultiFormatReader\n\nclass MyDataReader(MultiFormatReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.extensions = {\n            \".yml\": self.handle_eln_file,\n            \".yaml\": self.handle_eln_file,\n            \".json\": self.set_config_file,\n            # Here, one must add functions for handling any other file extension(s)\n        }\n# This has to be set to allow the convert script to use this reader. Set it to \"MyDataReader\".\nREADER = MyDataReader\n</code></pre> <p>In order to understand the capabilities of the <code>MultiFormatReader</code> and which methods need to be implemented when extending it, we will have a look at its <code>read</code> method:</p> multi/reader.py<pre><code>def read(\n    self,\n    template: dict = None,\n    file_paths: tuple[str] = None,\n    objects: Optional[tuple[Any]] = None,\n    **kwargs,\n) -&gt; dict:\n    self.kwargs = kwargs\n    self.config_file = self.kwargs.get(\"config_file\", self.config_file)\n    self.overwrite_keys = self.kwargs.get(\"overwrite_keys\", self.overwrite_keys)   \n</code></pre>"},{"location":"learn/pynxtools/multi-format-reader.html#template-initialization-and-processing-order","title":"Template initialization and processing order","text":"<p>An empty <code>Template</code> object is initialized that later gets filled from the data files later.</p> multi/reader.py<pre><code>    template = Template(overwrite_keys=self.overwrite_keys)\n\n    def get_processing_order(path: str) -&gt; tuple[int, Union[str, int]]:\n        \"\"\"\n        Returns the processing order of the file.\n        \"\"\"\n        ext = os.path.splitext(path)[1]\n        if self.processing_order is None or ext not in self.processing_order:\n            return (1, ext)\n        return (0, self.processing_order.index(ext))\n\n    sorted_paths = sorted(file_paths, key=get_processing_order)\n</code></pre> <p>If the reader has a <code>self.processing_order</code>, the input files get sorted in this order. If <code>self.overwrite_keys</code> is True, later files get precedent. For example, if <code>self.processing_order = [\".yaml\", \".hdf5\"]</code>, any values coming from HDF5 files would overwrite values from the YAML files.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#reading-of-input-files","title":"Reading of input files","text":"multi/reader.py<pre><code>    for file_path in sorted_paths:\n        extension = os.path.splitext(file_path)[1].lower()\n        if extension not in self.extensions:\n            logger.warning(\n                f\"File {file_path} has an unsupported extension, ignoring file.\"\n            )\n            continue\n        if not os.path.exists(file_path):\n            logger.warning(f\"File {file_path} does not exist, ignoring entry.\")\n            continue\n\n        template.update(self.extensions.get(extension, lambda _: {})(file_path))\n</code></pre> <p>This parts reads in the data from all data files. The <code>MultiFormatReader</code> has an <code>extensions</code> property, which is a dictionary that for each file extension calls a function that reads in data from files with that extension. If the reader shall handle e.g. an HDF5 file, a method for handling this type of file should be added, i.e., <code>self.extensions[\".hdf5\"] = self.handle_hdf5</code>. Note that these methods should also implement any logic depending on the provided data, i.e., it may not be sufficient to rely on the filename suffix, but the reader may also need to check for different file versions, binary signature, mimetype, etc.</p> <p>Any of these methods should take as input only the file path, e.g.</p> multi/reader.py<pre><code>def handle_eln_file(self, file_path: str) -&gt; dict[str, Any]\n</code></pre> <p>These methods must return a dictionary. One possibility is to return a dictionary that directly fills the template (see the <code>template.update</code> call above) with the data from the file. Another option is to return an empty dictionary (i.e., not fill the template at this stage) and only later fill the template from a config file (see below).</p> <p>Note that for several input formats, standardized parser functions already exist within the <code>MultiFormatReader</code>. For example, YAML files can be parsed using the <code>pynxtools.dataconverter.readers.utils.parse_yml</code> function.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#setting-default-values-in-the-template","title":"Setting default values in the template","text":"multi/reader.py<pre><code>    template.update(self.setup_template())\n</code></pre> <p>Next, the <code>setup_template</code> method can be implemented, which is used to populate the template with initial data that does not come from the files themselves. This may be used to set fixed information, e.g., about the reader. As an example, <code>NXentry/program_name</code> (which is defined as the name of program used to generate the NeXus file) scan be set to <code>pynxtools-plugin</code> by making <code>setup_template</code> return a dictionary of the form</p> <pre><code>{\n  \"/ENTRY[my_entry]/program_name\": \"pynxtools-plugin\",\n  \"/ENTRY[my_entry]/program_name/@version\": \"v0.1.0\"\n}\n</code></pre>"},{"location":"learn/pynxtools/multi-format-reader.html#handling-objects","title":"Handling objects","text":"multi/reader.py<pre><code>    if objects is not None:\n        template.update(self.handle_objects(objects))\n</code></pre> <p>Aside from data files, it is also possible to directly pass any Python objects to the <code>read</code> function (e.g., a numpy array with measurement data). In order to exploit this, the <code>handle_objects</code> method must implemented, which should return a dictionary that populates the template.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#parsing-the-config-file","title":"Parsing the config file","text":"multi/reader.py<pre><code>    if self.config_file is not None:\n        self.config_dict = parse_flatten_json(\n            self.config_file, create_link_dict=False\n        )\n</code></pre> <p>Next up, we can make use of the config file, which is a JSON file that tells the reader which input data to use to populate the template. In other words, the config.json is used for ontology mapping between the input file paths and the NeXus application definition. Essentially, the config file should contain all keys that are present in the NXDL. A subset of a typical config file may look like this:</p> <pre><code>{\n  \"/ENTRY/title\": \"@attrs:metadata/title\", \n  \"/ENTRY/USER[user]\": {\n    \"name\": \"my_name\",\n  }, \n  \"/ENTRY/INSTRUMENT[instrument]\": {\n    \"name\":\"@eln\",\n    \"temperature_sensor\": {\n      \"value\": \"@attrs:metadata/temp\",\n      \"value/@units\": \"K\"\n    }\n  },\n  \"/ENTRY/SAMPLE[sample]\": {\n    \"temperature_env\": {\n      \"temperature_sensor\": \"@link:/entry/instrument/temperature_sensor\"\n    }\n  },  \n  \"/ENTRY/data\": {\n    \"@axes\": \"@data:dims\",\n    \"AXISNAME_indices[@*_indices]\": \"@data:*.index\",\n    \"@signal\": \"data\",\n    \"data\": \"@data:mydata\",\n  }\n}\n</code></pre> <p>Here, the <code>parse_flatten_json</code> method is used that allows us to write the config dict in the structured manner above and internally flattens it (so that it has a similar structure as the Template).</p> <p>In the config file, one can</p> <ol> <li>hard-code values (like the unit <code>\"K\"</code> in <code>\"/ENTRY/INSTRUMENT[instrument]/temperature_sensor/value/@units\"</code>) or</li> <li>tell the reader where to search for data using the <code>@</code>-prefixes. For more on these prefixes, see below.</li> </ol> <p>Note that in order to use a <code>link_callback</code> (see below), <code>create_link_dict</code> must be set to <code>False</code>, which means that at this stage, config values of the form <code>\"@link:\"/path/to/source/data\"</code> get NOT yet converted to <code>{\"link\": \"/path/to/source/data\"}</code>.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#data-post-processing","title":"Data post processing","text":"multi/reader.py<pre><code>   self.post_process()\n</code></pre> <p>In case there is the need for any post-processing on the data and/or config dictionary after they have been read, the <code>post_process</code> method can be implemented. For example, this can be helpful if there are multiple entities of a given NX_CLASS (for example, multiple detectors) on the same level and the config dict shall be set up to fill the template with all of these entities.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#filling-the-template-from-the-read-in-data","title":"Filling the template from the read-in data","text":"multi/reader.py<pre><code>    if self.config_dict:\n        suppress_warning = kwargs.pop(\"suppress_warning\", False)\n        template.update(\n            fill_from_config(\n                self.config_dict,\n                self.get_entry_names(),\n                self.callbacks,\n                suppress_warning=suppress_warning,\n            )\n        )\n\n    return template\n</code></pre> <p>As a last step, the template is being filled from the config dict using the data. If there is more than one entry, the <code>get_entry_names</code> method must be implemented, which shall return a list of all entry names. The <code>fill_from_config</code> method iterates through all of the them and replaces the generic <code>/ENTRY/</code> in the config file by keys of the form <code>/ENTRY[my-entry]/</code> to fill the template.</p> <p>Here, we are using callbacks, which are used to bring in data based on <code>@</code>-prefixes in the config file. These are defined in the reader's <code>__init__</code> call using the <code>pynxtools.dataconverter.readers.multi.ParseJsonCallbacks</code> class:</p> multi/reader.py<pre><code>self.callbacks = ParseJsonCallbacks(\n    attrs_callback=self.get_attr,\n    data_callback=self.get_data,\n    eln_callback=self.get_eln_data,\n    dims=self.get_data_dims,\n)\n</code></pre> <p>The <code>ParseJsonCallbacks</code> class has an attribute called <code>special_key_map</code> that makes use of these callbacks to populate the template based on the starting prefix of the config dict value:</p> multi/reader.py<pre><code>self.special_key_map = {\n    \"@attrs\": attrs_callback if attrs_callback is not None else self.identity,\n    \"@link\": link_callback if link_callback is not None else self.link_callback,\n    \"@data\": data_callback if data_callback is not None else self.identity,\n    \"@eln\": eln_callback if eln_callback is not None else self.identity,\n}\n</code></pre> <p>That means, if the config file has an entry <code>{\"/ENTRY/title\": \"@attrs:metadata/title\"}</code>, the <code>get_attr</code> method of the reader gets called and should return an attribute from the given path, i.e., in this case from <code>metadata/title</code>.</p> <p>By default, the MultiFormatReader supports the following special prefixes:</p> <ul> <li><code>@attrs</code>: To get metadata from the read-in experiment file(s). You need to implement the <code>get_attr</code> method in the reader.</li> <li><code>@data</code>: To get measurement data from the read-in experiment file(s). You need to implement the <code>get_data</code> method in the reader.</li> <li><code>@eln</code>: To get metadata from additional ELN files. You need to implement the <code>get_eln_data</code> method in the reader.</li> <li><code>@link</code>: To implement a link between two entities in the NeXus file. By default, the link callback returns a dict of the form {\"link\": value.replace(\"/entry/\", f\"/{self.entry_name}/\")}, i.e., a generic <code>/entry/</code> get replaced by the actual <code>entry_name</code>.</li> </ul> <p>The distinction between data and metadata is somewhat arbitrary here. The reason to have both of these prefixes is to have different methods to access different parts of the read-in data. For example, <code>@attrs</code> may just access key-value pairs of a read-in dictionary, whereas <code>@data</code> can handle different object types, e.g. xarrays. The implementation in the reader decides how to distinguish data and metadata and what each of the callbacks shall do.</p> <p>In addition, the reader can also implement the <code>get_data_dims</code> method, which is used to return a list of the data dimensions (see below for more details).</p> <p>All of <code>get_attr</code>, <code>get_data</code>, and <code>get_eln_data</code>  (as well as any similar method that might be implemented) should have the same call signature:</p> <pre><code>def get_data(self, key: str, path: str) -&gt; Any:\n</code></pre> <p>Here, <code>key</code> is the config dict key (e.g., <code>\"/ENTRY[my-entry]/data/data\"</code>) and path is the path that comes after the prefix in the config file. In the example config file above, <code>path</code> would be <code>mydata</code>. With these two inputs, the reader should be able to return the correct data for this template key.</p>"},{"location":"learn/pynxtools/multi-format-reader.html#special-rules","title":"Special rules","text":"<ul> <li> <p>Lists as config value: It is possible to write a list of possible configurations of the sort   <pre><code>\"/ENTRY/title\":\"['@attrs:my_title', '@eln', 'no title']\"\n</code></pre>   The value must be a string which can be parsed as a list, with each item being a string itself. This allows to provide different options depending if the data exists for a given callback. For each list item , it is checked if a value can be returned and if so, the value is written. In this example, the converter would check (in order) the <code>@attrs</code> (with path <code>\"my_title\"</code>) and <code>@eln</code> (with path <code>\"\"</code>) tokens and write the respective value if it exists. If not, it defaults to \"no title\".   This concept can be particularly useful if the same config file is used for multiple measurement configurations, where for some setup, the same metadata may or may not be available.</p> <p>Note that if this notation is used, it may be helpful to pass the <code>suppress_warning</code> keyword as <code>True</code> to the read function. Otherwise, there will be a warning for every non-existent value.</p> </li> <li> <p>Wildcard notation: There exists a wildcard notation (using <code>*</code>)   <pre><code>\"/ENTRY/data/AXISNAME[*]\": \"@data:*.data\",\n</code></pre>   that allows filling multiple fields of the same type from a list of dimensions. This can be particularly helpful for writing <code>DATA</code> and <code>AXISNAME</code> fields that are all stored under similar paths in the read-in data.   For this, the <code>get_data_dims</code> method needs to be implemented. For a given path, it should return a list of all data axes available to replace the wildcard.</p> <p>The same wildcard notation can also be used within a name to repeat entries with different names (e.g., field_*{my, name, etc} is converted into three keys with * replaced by my, name, etc, respectively). As an example, for multiple lenses and their voltage readouts, one could write:   <pre><code>\"ELECTROMAGNETIC_LENS[lens_*{A,B,Foc}]\": {\n  \"name\": \"*\",\n  \"voltage\": \"@attrs:metadata/file/Lens:*:V\",\n  \"voltage/@units\": \"V\"\n},\n</code></pre>   which would write <code>NXelectromagnetic_lens</code> instances named <code>lens_A</code>, <code>lens_B</code>, and <code>lens_Foc</code>.</p> </li> <li> <p>Required fields in optional groups: There will sometimes be the situation that there is an optional NeXus group in an application definition, that (if implemented) requires some sub-element. As an example, for the instrument's energy resolution, the only value expected to come from a data source is the <code>resolution</code>, whereas other fields are hardcoded.   <pre><code>\"ENTRY/INSTRUMENT[instrument]/energy_resolution\": {\n  \"resolution\": \"@attrs:metadata/instrument/electronanalyzer/energy_resolution\",\n  \"resolution/@units\": \"meV\",\n  \"physical_quantity\": \"energy\"\n}\n</code></pre>   Now, if there is no data for <code>@attrs:metadata/instrument/electronanalyzer/energy_resolution</code> available in a dataset, this will be skipped by the reader, and not available, yet the other entries are present. During validation, this means that the required field <code>resolution</code> of the optional group <code>energy_resolution</code> is not present, and thus a warning or error would be raised:   <pre><code>LookupError: The data entry, /ENTRY[entry]/INSTRUMENT[instrument]/ELECTRONANALYZER[electronanalyzer]/energy_resolution/physical_quantity, has an optional parent, /ENTRY[entry]/INSTRUMENT[instrument]/ELECTRONANALYZER[electronanalyzer]/energy_resolution, with required children set. Either provide no children for /ENTRY[entry]/INSTRUMENT[instrument]/ELECTRONANALYZER[electronanalyzer]/energy_resolution or provide all required ones.\n</code></pre></p> <p>To circumvent this problem, there exists a notation using the <code>\"!\"</code> prefix. If you write <pre><code>\"ENTRY/INSTRUMENT[instrument]/energy_resolution/resolution\": \"!@attrs:metadata/instrument/electronanalyzer/energy_resolution\"\n</code></pre> the whole parent group <code>/ENTRY/INSTRUMENT[instrument]/energy_resolution</code> will not be written in case that there is no value for <code>@attrs:metadata/instrument/electronanalyzer/energy_resolution\"</code>, thus preventing the aforementioned error.</p> </li> </ul>"},{"location":"learn/pynxtools/nexus-validation.html","title":"Validation of NeXus file","text":"<p>This page is intended to give more information about the validation tools that are part of <code>pynxtools</code>. Please also have a look at our comprehensive how-to guide on NeXus validation.</p> <p>One of the main advantages of using pynxtools is that it comes with its own validation tools. That is, it can be used to validate that a given NeXus/HDF5 file is compliant with a NeXus application definition.</p>"},{"location":"learn/pynxtools/nexus-validation.html#as-part-of-the-dataconverter","title":"As part of the dataconverter","text":"<p>During data conversion, before writing the HDF5 file, the data is first checked against the provided application definition.</p>"},{"location":"learn/pynxtools/nexus-validation.html#read_nexus-nexus-file-reader-and-debugger","title":"read_nexus: NeXus file reader and debugger","text":"<p>This utility outputs a debug log for a given NeXus file by annotating the data and metadata entries with the schema definitions from the respective NeXus base classes and application definitions to which the file refers to. See here for the API documentation.</p> <p>The following example dataset can be used to test the <code>read_nexus</code> module: src/pynxtools/data/201805_WSe2_arpes.nxs. This is an angular-resolved photoelectron spectroscopy (ARPES) dataset that is formatted according to the NXarpes application definition of NeXus.</p> <p>Using a different set of NeXus definitions</p> <p>The environment variable \"NEXUS_DEF_PATH\" can be set to a directory which contains the NeXus definitions as NXDL XML files. If this environment variable is not defined, the module will use the definitions in its bundle (see <code>src/pynxtools/definitions</code>)._</p> <p>The environment variable can be set as follows: <pre><code>export 'NEXUS_DEF_PATH'=&lt;folder_path_that_contains_nexus_defs&gt;\n</code></pre></p> <p>A note to Windows users</p> <p>If you run <code>read_nexus</code> from <code>git bash</code>, you need to set the environmental variable <code>MSYS_NO_PATHCONV</code> to avoid the path translation in Windows Git MSys. The easiest way is to prefix the <code>read_nexus</code> call with <code>MSYS_NO_PATHCONV=1</code>:</p> <pre><code>MSYS_NO_PATHCONV=1 read_nexus -c /NXarpes/ENTRY/INSTRUMENT/analyzer\n</code></pre> <p>This workaround was tested with Windows 11, but should very likely also work with Windows 10 and lower.</p>"},{"location":"learn/pynxtools/nexus-validation.html#other-approaches-not-part-of-pynxtools","title":"Other approaches (not part of pynxtools)","text":"<p>Aside from the tools we developed within FAIRmat, the official NeXus website lists additional programs for the validation of NeXus files:</p> <ol> <li>cnxvalidate: NeXus validation tool written in C</li> <li>punx: Python Utilities for NeXus HDF5 files</li> <li>nexpy/nxvalidate: A python API for validating NeXus file</li> </ol> <p>We will not discuss the details of these programs here, but you can find some information about the in the how-to guide linked above.</p>"},{"location":"reference/built-in-readers.html","title":"Built-in <code>pynxtools</code> readers","text":"<p>There exists a number of readers directly in <code>pynxtools</code>. These are typically used either as superclasses for new reader implementations or for generic reading purposes not directly related to any specific technique.</p>"},{"location":"reference/built-in-readers.html#the-basereader","title":"The BaseReader","text":"<p>This is the most simple reader, which is an abstract base class, on top of which a new reader implementation can build. It has an essentially empty read function and is thus only helpful for implementing the correct input/output design of the <code>read</code> function of any reader that is inheriting from this base reader.</p>"},{"location":"reference/built-in-readers.html#the-multiformatreader","title":"The MultiFormatReader","text":"<p>Another reader that can act as the basis for any reader implementation is the <code>MultiFormatReader</code>, which can be used to implement a reader that can read in multiple file formats and then populate the NeXus file using the read data. Note that this reader has a lot of already built-in functionality, which is extensively described here. There is also a how-to guide on how to implement a new reader off of the <code>MultiFormatReader</code> using a concrete example.</p>"},{"location":"reference/built-in-readers.html#the-jsonmapreader","title":"The JsonMapReader","text":"<p>This reader is designed to allow users of <code>pynxtools</code> to convert their existing data with the help of a map file. The map file tells the reader which concept and instance data to pick from the data files and how to convert these to NeXus files. The following formats are supported as input files:</p> <ul> <li>HDF5</li> <li>JSON</li> <li>Python Dict Objects pickled with pickle. These can contain xarray.DataArray objects as well as regular Python types and Numpy types. Note that while it is supported, we strongly recommend note to use pickle due to its known security concerns.</li> </ul> <p>It accepts any XML file that follows the NXDL schema definition language file as long as your mapping file contains all the required fields. Please use the <code>--generate-template</code> function of the <code>dataconverter</code> to create a <code>.mapping.json</code> file:</p> <pre><code>user@box:~$ dataconverter --nxdl NXmynxdl --generate-template &gt; mynxdl.mapping.json\n</code></pre>"},{"location":"reference/built-in-readers.html#the-mappingjson-file","title":"The mapping.json file","text":"<p>This file is designed to let you fill in the requirements of a NeXus Application Definition without writing any code. If you already have data in the formats listed above, you just need to use this mapping file to help the dataconverter pick your data correctly.</p> <p>The mapping files will always be based on the template the dataconverter generates. See above on how to generate a mapping file. The right hand side values of the template keys are what you can modify. These keys are called NeXus template paths, because they combine the actual path that will be used in the HDF5 hierarchy with additional NeXus datatype hints to guide the dataconverter to add NX_class annotations.</p> <p>Here are the three different ways you can fill the right hand side of the template keys:</p> <ul> <li>Write the nested path in your datafile. This is indicated by a leading <code>/</code> before the word <code>entry</code> to make <code>/entry/data/current_295C</code> below. Example:</li> </ul> <pre><code>  \"/ENTRY[entry]/DATA[data]/current_295C\": \"/entry/data/current_295C\",\n  \"/ENTRY[entry]/NXODD_name/posint_value\": \"/a_level_down/another_level_down/posint_value\",\n</code></pre> <p>Here, <code>\"/entry/data/current_295C\"</code> is the path in the original HDF5 file, while the key shown here is the template path (see above).</p> <ul> <li>Write the values directly in the mapping file for missing data from your data file.</li> </ul> <pre><code>  \"/ENTRY[entry]/PROCESS[process]/program\": \"Bluesky\",\n  \"/ENTRY[entry]/PROCESS[process]/program/@version\": \"1.6.7\"\n</code></pre> <ul> <li>Write JSON objects with a link key. This follows the same link mechanism that the dataconverter implements. In the context of this reader, you can only use external links to your data files. In the example below, <code>current.nxs</code> is an already existing HDF5 file that we link to in our new NeXus file without copying over the data. The format is as follows: <code>\"link\": \"&lt;filename&gt;:&lt;path_in_file&gt;\"</code> Note: This only works for HDF5 files currently.</li> </ul> <pre><code>  \"/ENTRY[entry]/DATA[data]/current_295C\": {\"link\": \"current.nxs:/entry/data/current_295C\"},\n  \"/ENTRY[entry]/DATA[data]/current_300C\": {\"link\": \"current.nxs:/entry/data/current_300C\"},\n</code></pre>"},{"location":"reference/built-in-readers.html#examples","title":"Examples","text":""},{"location":"reference/built-in-readers.html#basic-mappings","title":"Basic mappings","text":"<p>There are some example files you can use:</p> <p>data.mapping.json</p> <p>data.json</p> <pre><code>user@box:~$ dataconverter --nxdl NXtest data.json --mapping data.mapping.json\n</code></pre>"},{"location":"reference/built-in-readers.html#example-with-hdf5-files","title":"Example with HDF5 files","text":"<p>You can find example data files for using the mapping with HDF5 files at <code>examples/json_map</code>.</p> <p>The example can be run by calling</p> <pre><code>user@box:~$ dataconverter --nxdl nxdl any_data.hdf5 --mapping my_custom_map.mapping.json\n</code></pre>"},{"location":"reference/built-in-readers.html#the-yamljsonreader","title":"The YamlJsonReader","text":"<p>Work in progress</p>"},{"location":"reference/built-in-readers.html#installation","title":"Installation","text":"<p>Each of the built-in readers are shipped/installed with the main <code>pynxtools</code> package. Hence, these readers are available after installation:</p> <ul> <li>Installation</li> </ul>"},{"location":"reference/cli-api.html","title":"API for command line tools","text":"<p><code>pynxtools</code> supports a number of command line applications. This page provides documentation for their current API.</p>"},{"location":"reference/cli-api.html#data-conversion","title":"Data conversion","text":"<p>Note that simply calling <code>dataconverter</code> defaults to <code>dataconverter convert</code>.</p>"},{"location":"reference/cli-api.html#dataconverter","title":"dataconverter","text":"<p>Usage:</p> <pre><code>dataconverter [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>convert: This command allows you to use the converter functionality of the dataconverter.</li> <li>generate-template: Generates and prints a template to use for your nxdl.</li> <li>get-readers: Prints a list of all installed readers.</li> </ul>"},{"location":"reference/cli-api.html#dataconverter-convert","title":"dataconverter convert","text":"<p>This command allows you to use the converter functionality of the dataconverter.</p> <p>Usage:</p> <pre><code>dataconverter convert [OPTIONS] [FILES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--input-file</code> text Deprecated: Please use the positional file arguments instead. The path to the input data file to read. Repeat for more than one file. default=[] This option is required if no '--params-file' is supplied. <code>[]</code> <code>--reader</code> choice (<code>example</code> | <code>json_map</code> | <code>json_yml</code> | <code>multi</code>) The reader to use. Examples are json_map or readers from a pynxtools plugin. default='json_map' This option is required if no '--params-file' is supplied. <code>json_map</code> <code>--nxdl</code> text The name of the NeXus application definition file to use without the extension nxdl.xml. This option is required if no '--params-file' is supplied. None <code>--output</code> text The path to the output NeXus file to be generated. default='output.nxs' <code>output.nxs</code> <code>--params-file</code> filename Allows to pass a .yaml file with all the parameters the converter supports. None <code>--ignore-undocumented</code> boolean Ignore all undocumented fields during validation. <code>False</code> <code>--fail</code> boolean Fail conversion and don't create an output file if the validation fails. <code>False</code> <code>--skip-verify</code> boolean Skips the verification routine during conversion. <code>False</code> <code>--mapping</code> text Takes a .mapping.json file and converts data from given input files. None <code>-c</code>, <code>--config</code> file A json config file for the reader None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli-api.html#dataconverter-generate-template","title":"dataconverter generate-template","text":"<p>Generates and prints a template to use for your nxdl.</p> <p>Usage:</p> <pre><code>dataconverter generate-template [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--nxdl</code> text The name of the NeXus application definition file to use without extension. For example: NXmpes _required <code>--required</code> boolean Use this flag to only get the required template. <code>False</code> <code>--pythonic</code> boolean Prints a valid Python dictionary instead of JSON <code>False</code> <code>--output</code> path Writes the output into the filepath provided. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli-api.html#dataconverter-get-readers","title":"dataconverter get-readers","text":"<p>Prints a list of all installed readers.</p> <p>Usage:</p> <pre><code>dataconverter get-readers [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli-api.html#nexus-file-validation","title":"NeXus file validation","text":""},{"location":"reference/cli-api.html#read_nexus","title":"read_nexus","text":"<p>Functionality to extract documentation and concept definition information about the individual parts of a NeXus/HDF5 file.</p> <p>Usage:</p> <pre><code>read_nexus [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>-f</code>, <code>--nexus-file</code> text NeXus file with extension .nxs. None <code>-d</code>, <code>--documentation</code> text Definition path in nexus output (.nxs) file. Returns debug log relevant with that definition path. Example input: /entry/data/delays None <code>-c</code>, <code>--concept</code> text Concept path from application definition file (.nxdl.xml). Finds out all the available concept definition (IS-A relation) for a given concept path. Example input: /NXarpes/ENTRY/INSTRUMENT/analyser None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>NOTE: Only one option from (<code>-d</code> and <code>-c</code>) is acceptable.</p>"},{"location":"reference/cli-api.html#eln-generation","title":"ELN generation","text":""},{"location":"reference/cli-api.html#generate_eln","title":"generate_eln","text":"<p>Helper tool for generating ELN files in YAML format.</p> <p>Usage:</p> <pre><code>generate_eln [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--nxdl</code> text Name of NeXus definition without extension (.nxdl.xml). _required <code>--skip-top-levels</code> integer To skip the level of parent hierarchy level. For example, by default the part Entry[ENTRY] from /Entry[ENTRY]/Instrument[INSTRUMENT]/... will be skiped. <code>0</code> <code>--output-file</code> text Name of file that is needed to generated output file. None <code>--eln-type</code> choice (<code>reader</code> | <code>schema</code>) Choose a type of ELN output (reader or schema). <code>eln</code> <code>--optionality</code> choice (<code>required</code> | <code>recommended</code> | <code>optional</code>) Level of requiredness to generate. If any of ('required', 'recommended', 'optional', only those concepts matching this requiredness level are created. <code>required</code> <code>--filter-file</code> text JSON configuration file to filter NeXus concepts (based on the presence of the '@eln' keyword). This is a positive filter, i.e., all concepts in the filter file will be included in the ELN. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/definitions.html","title":"NeXus definitions","text":"<p>We link two references here. The first links to the official definitions by the NIAC and the second one links to latest FAIRmat definitions.</p> <ul> <li>Official NIAC definitions</li> <li>Latest FAIRmat definitions</li> </ul> <p>The FAIRmat definitions are regularly contributed to NIAC (around every 6 months), but generally reflect a state which is still under development and may contain new or improved application definitions or base classes. Consider it as the public review stage of these application definitions. However, there might be some parts which are still under discussion and will be subject to change.</p> <p>Note: To connect NeXus concepts with semantic web tools, efforts are underway to represent them using the W3C Web Ontology Language (OWL). See the NeXusOntology for more details.</p>"},{"location":"reference/plugins.html","title":"FAIRmat-supported <code>pynxtools</code> plugins","text":"<p>There are a number of plugins available for <code>pynxtools</code> that are maintained within FAIRmat. These are extensions of <code>pynxtools</code> used for reading data of specific experimental techniques and/or file formats.</p>"},{"location":"reference/plugins.html#photoemission-spectroscopy","title":"Photoemission spectroscopy","text":"Repository Description Docs PyPI pynxtools-mpes Reader plugin for multi-dimensional photoelectron spectroscopy (MPES) data. \ud83d\udce6 pynxtools-xps Reader plugin for X-ray photoelectron spectroscopy (XPS) data from various vendors/sources. \ud83d\udcda \ud83d\udce6"},{"location":"reference/plugins.html#electron-microscopy","title":"Electron microscopy","text":"Repository Description Docs PyPI pynxtools-em Reader plugin for electron microscopy (EM) data from various vendors/sources. \ud83d\udcda \ud83d\udce6"},{"location":"reference/plugins.html#atom-probe-microscopytomography","title":"Atom probe microscopy/tomography","text":"Repository Description Docs PyPI pynxtools-apm Reader plugin for atom probe microscopy (APM) as well as related field ion microscopy (FIM) data. \ud83d\udcda \ud83d\udce6"},{"location":"reference/plugins.html#optical-spectroscopy","title":"Optical spectroscopy","text":"Repository Description Docs PyPI pynxtools-ellips Reader plugin for ellipsometry data. \ud83d\udcda \ud83d\udce6 pynxtools-raman Reader plugin for Raman data. \ud83d\udce6"},{"location":"reference/plugins.html#scanning-probe-microscopy","title":"Scanning probe microscopy","text":"Repository Description Docs PyPI pynxtools-spm Reader plugin for scanning probe microscopy (SPM). \ud83d\udcda \ud83d\udce6"},{"location":"reference/plugins.html#x-ray-diffraction","title":"X-ray diffraction","text":"Repository Description Docs PyPI pynxtools-xrd pynxtools reader plugin for X-ray diffraction data. \ud83d\udce6"},{"location":"reference/plugins.html#others","title":"Others","text":"Repository Description Docs PyPI pynxtools-igor A general reader plugin for Igor Pro Binary Wave data. \ud83d\udcda \ud83d\udce6"},{"location":"reference/plugins.html#installation","title":"Installation","text":"<p>You can install each of the plugins together with <code>pynxtools</code> by passing the name of the plugin as an extra to the pip install call. For example, for the <code>pynxtools-mpes</code> plugin:</p> uvpip <pre><code>uv pip install pynxtools[mpes]\n</code></pre> <pre><code>pip install pynxtools[mpes]\n</code></pre> <p>In addition, you can also install all of the pynxtools reader plugins which are maintained by FAIRmat by passing the <code>[convert]</code> extra to the pip install call:</p> uvpip <pre><code>uv pip install pynxtools[convert]\n</code></pre> <pre><code>pip install pynxtools[convert]\n</code></pre>"},{"location":"tutorial/contributing.html","title":"Development guide","text":"<p>This tutorial will guide you through on how to set up a working environment for developing <code>pynxtools</code>.</p>"},{"location":"tutorial/contributing.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<ul> <li>You should read our guide on getting started.</li> <li>You should read the installation tutorial.</li> </ul>"},{"location":"tutorial/contributing.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will know</p> <ul> <li>how to setup your environment for developing <code>pynxtools</code></li> <li>how to make changes to the software</li> <li>how to test the software</li> <li>how to contribute on GitHub</li> <li>how to use pynxtools as a NOMAD plugin</li> </ul>"},{"location":"tutorial/contributing.html#contributing","title":"Contributing","text":"Structure of the <code>pynxtools</code> repository <p>The software tools are located inside <code>src/pynxtools</code>. They are shipped with unit tests located in <code>tests</code>. Some examples from the scientific community are provided in <code>examples</code>. They guide you through the process of converting instrument data into the NeXus standard and visualizing the files' content.</p>"},{"location":"tutorial/contributing.html#setup","title":"Setup","text":"<p>It is recommended to use python 3.11 with a dedicated virtual environment for this package. Learn how to manage python versions and virtual environments. We recommend using <code>uv</code>, an extremely fast manager Python package and project manager. In this tutorial, you will find paralleled descriptions, using either <code>uv</code> or a more classical approach using <code>venv</code> and <code>pip</code>.</p> <p>Start by creating a virtual environment:</p> uvvenv <p><code>uv</code> is capable of creating a virtual environment and install the required Python version at the same time.</p> <pre><code>uv venv --python 3.11\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>python -m venv .venv\n</code></pre> <p>That command creates a new virtual environment in a directory called .venv.</p>"},{"location":"tutorial/contributing.html#development-installation","title":"Development installation","text":"<p>We start by cloning the repository:</p> <pre><code>git clone https://github.com/FAIRmat-NFDI/pynxtools.git \\\\\n    --branch master \\\\\n    --recursive pynxtools\ncd pynxtools\ngit submodule sync --recursive\ngit submodule update --init --recursive --jobs=4\n</code></pre> <p>Note that we are using the NeXus definitions as a Git submodule. The last two lines initiate the submodule and upgrade it to match the first used in pynxtools.</p> <p>Next, we install the package in editable mode (together with its dependencies):</p> uvpip <pre><code>uv pip install -e \".[dev]\"\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>pip install --upgrade pip\npip install -e \".[dev]\"\n</code></pre>"},{"location":"tutorial/contributing.html#linting-and-formatting","title":"Linting and formatting","text":"<p>We are using ruff and mypy for linting, formatting, and type checking. It is recommended to use the pre-commit hook available for ruff which formats the code and checks the linting before actually making an actual Git commit.</p> <p>Install the precommit by running</p> <pre><code>pre-commit install\n</code></pre> <p>from the root of this repository.</p>"},{"location":"tutorial/contributing.html#testing","title":"Testing","text":"<p>There exist unit tests for the software written in pytest which can be used as follows:</p> <pre><code>pytest -sv tests\n</code></pre>"},{"location":"tutorial/contributing.html#editing-the-documentation","title":"Editing the documentation","text":"<p>We are using `mkdocs for the documentation. If you edit the documentation, you can build it locally. For this, you need to install an additional set of dependencies:</p> uvpip <pre><code>uv pip install -e \".[docs]\"\n</code></pre> <pre><code>pip install -e \".[docs]\"\n</code></pre> <p>You can then serve the documentation locally by running</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"tutorial/contributing.html#running-the-examples","title":"Running the examples","text":"<p>A number of examples exist which document how the tools can be used. For a standalone usage, convenient Jupyter notebooks are available for some of the tools. To use these notebooks, Jupyter and related tools have to be installed in the development environment as follows:</p> uvpip <pre><code>uv pip install jupyter\nuv pip install jupyterlab\nuv pip install jupyterlab_h5web\n</code></pre> <pre><code>pip install jupyter\npip install jupyterlab\npip install jupyterlab_h5web\n</code></pre>"},{"location":"tutorial/contributing.html#contributing-to-the-package-on-github","title":"Contributing to the package on Github","text":"<p>Once you are happy with the changes, please commit them on a separate branch and create a pull request on GitHub. We run a number of GitHub actions that check the correct linting, run the tests in an isolated environment, and build the documentation. Once these pass and a peer review of the code has occurred, your code will be accepted.</p>"},{"location":"tutorial/contributing.html#developing-pynxtools-as-a-nomad-plugin","title":"Developing pynxtools as a NOMAD plugin","text":"<p>If you plan to contribute to the NOMAD plugin functionality of <code>pynxtools</code>, it often makes sense to use the NOMAD development environment called <code>nomad-distro-dev</code>. You can learn more in the NOMAD documentation.</p>"},{"location":"tutorial/contributing.html#troubleshooting","title":"Troubleshooting","text":"<p>If you face any issues with the tool or when setting up the development environment, please create a new Github Issue.</p>"},{"location":"tutorial/converting-data-to-nexus.html","title":"Converting your research data to NeXus","text":""},{"location":"tutorial/converting-data-to-nexus.html#who-is-this-tutorial-for","title":"Who is this tutorial for?","text":"<p>The document is for people who want to standardize their research data by converting their research data into a NeXus standardized format. We cover the basic principles and common principles of NeXus, here. For a more detailed description on the general principles of NeXus we recommend reading our learning page for NeXus or the official NeXus user manual.</p>"},{"location":"tutorial/converting-data-to-nexus.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<ul> <li>You should have a basic understanding of NeXus: see our primer on NeXus.</li> <li>You should have a basic understanding of FAIR data.</li> <li>You should have installed <code>pynxtools</code>: Installation tutorial.</li> </ul>"},{"location":"tutorial/converting-data-to-nexus.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will have</p> <ul> <li>a basic understanding how to use the NeXus data converter from the <code>pynxtools</code> package</li> </ul>"},{"location":"tutorial/converting-data-to-nexus.html#setup","title":"Setup","text":"<p><code>pynxtools</code> has a number of readers that support reading and converting multiple file formats. A generic reader is the JSON Map Reader. In addition, we provide multiple reader plugins for different experimental techniques.</p> <p>We will use the XPS reader plugin with a SpecsLabProdigy file (file extension: <code>.sle</code>) as an example.</p>"},{"location":"tutorial/converting-data-to-nexus.html#steps","title":"Steps","text":"<ol> <li> <p>Download the example files from here:</p> <p>Download example files</p> </li> <li> <p>Extract the zip and copy the files in your current working directory. You can find the working directory by typing the following in your terminal:</p> <pre><code>pwd\n</code></pre> </li> <li> <p>Install pynxtools with the XPS reader plugin:</p> uvpip <pre><code>uv pip install pynxtools[xps]\n</code></pre> <pre><code>pip install pynxtools[xps]\n</code></pre> </li> <li> <p>Verify you can run the <code>dataconverter</code> in a terminal window. Open a terminal with the Python environment where you installed <code>pynxtools</code>. Then type the following:</p> <pre><code>dataconverter --help\n</code></pre> </li> </ol>"},{"location":"tutorial/converting-data-to-nexus.html#converting-the-example-files","title":"Converting the example files","text":"<p>Once you have your files copied into the working directory, your directory structure should look like this:</p> <pre><code>\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 EX439_S718_Au.sle\n\u251c\u2500\u2500 eln_data_sle.yaml\n\u2514\u2500\u2500 params.yaml\n</code></pre> <p>The <code>eln_data_sle.yaml</code> YAML file is another data file containing additional information (e.g., information about the experimenter) that is not provided in the main data file.</p> <p>Next, you will run the conversion routine from your Python environment:</p> <pre><code>dataconverter --params-file params.yaml\n</code></pre> <p>Here we use a <code>params.yaml</code> parameter file to configure the converter.  This will create a file called <code>Au_25_mbar_O2_no_align.nxs</code> in your current directory.</p> <p>Congrats! You now have a FAIR NeXus file!</p> <p>You can try out other examples from pynxtools.</p>"},{"location":"tutorial/installation.html","title":"Installation guide","text":"<p>The document is the entry point for anybody that is new to the NeXus data format and to FAIRmat/NOMAD. It serves as a guide to getting started with the <code>pynxtools</code> software.</p>"},{"location":"tutorial/installation.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<p>However, to get started, it does not hurt to  the following explanations:</p> <ul> <li>You should have read our guide on getting started</li> </ul>"},{"location":"tutorial/installation.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will know</p> <ul> <li>how to install <code>pynxtools</code></li> <li>how to configure your <code>pynxtools</code> installation</li> <li>how to install <code>pynxtools</code> together with NOMAD</li> </ul>"},{"location":"tutorial/installation.html#setup","title":"Setup","text":"<p>It is recommended to use python 3.11 with a dedicated virtual environment for this package. Learn how to manage python versions and virtual environments.</p> <p>There are many alternatives to managing virtual environments and package dependencies (requirements). We recommend using <code>uv</code>, an extremely fast manager Python package and project manager. In this tutorial, you will find paralleled descriptions, using either <code>uv</code> or a more classical approach using <code>venv</code> and <code>pip</code>.</p> <p>Start by creating a virtual environment:</p> uvvenv <p><code>uv</code> is capable of creating a virtual environment and install the required Python version at the same time.</p> <pre><code>uv venv --python 3.11\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>python -m venv .venv\n</code></pre> <p>That command creates a new virtual environment in a directory called <code>.venv</code>.</p>"},{"location":"tutorial/installation.html#installation","title":"Installation","text":"<p>Install the latest stable version of this package from PyPI with</p> uvpip <pre><code>uv pip install pynxtools\n</code></pre> <pre><code>pip install pynxtools\n</code></pre> <p>You can also install the latest development version with</p> uvpip <pre><code>uv pip install git+https://github.com/FAIRmat-NFDI/pynxtools.git\n</code></pre> <pre><code>pip install git+https://github.com/FAIRmat-NFDI/pynxtools.git\n</code></pre>"},{"location":"tutorial/installation.html#configuring-your-pynxtools-installation","title":"Configuring your <code>pynxtools</code> installation","text":"<p><code>pynxtools</code> comes with a list of built-in readers that can be used after after pip installation. In addition, <code>pynxtools</code> supports a plugin mechanism for adding file readers for different experimental techniques. The different FAIRmat-supported plugins can be installed together with <code>pynxtools</code> by passing the name of the plugin as an extra to the install call. For example, for the <code>pynxtools-mpes</code> plugin, you can run:</p> uvpip <pre><code>uv pip install pynxtools[mpes]\n</code></pre> <pre><code>pip install pynxtools[mpes]\n</code></pre> <p>In addition, you can also install all of the pynxtools reader plugins which are maintained by FAIRmat by passing the <code>[convert]</code> extra to the install call:</p> uvpip <pre><code>uv pip install pynxtools[convert]\n</code></pre> <pre><code>pip install pynxtools[convert]\n</code></pre> <p>Note that in this case, the latest version of the plugin(s) from PyPI are installed.</p>"},{"location":"tutorial/installation.html#how-to-install-pynxtools-with-nomad","title":"How to install <code>pynxtools</code> with NOMAD","text":"<p>To use <code>pynxtools</code> with NOMAD, simply install it in the same environment as the <code>nomad-lab</code> package. NOMAD will recognize <code>pynxtools</code> as a plugin automatically and offer automatic parsing of <code>.nxs</code> files. In addition, NOMAD will install a schema for NeXus application definitions.</p>"},{"location":"tutorial/installation.html#start-using-pynxtools","title":"Start using <code>pynxtools</code>","text":"<p>That's it! You can now use <code>pynxtools</code> and the plugins that you have installed!</p>"},{"location":"tutorial/nexus-to-nomad.html","title":"Uploading NeXus data to NOMAD","text":"<p>Great choice! NOMAD makes it easier than ever to work with your research data. At this point you probably have an idea of what FAIR data is. Even if you don't, it doesn't matter. NOMAD provides a simple graphical interface that let's you collect and have your data ready for publication.</p> <p>In this tutorial, we will go through how one can upload their NeXus files to NOMAD.</p> <p>NOMAD, as a FAIR data platform, supports NeXus and allows users to upload their NeXus (<code>.nxs</code>) files directly. These files get interpreted and added to your NOMAD account with complete control on how you would like to present and publish them alongside your research.</p>"},{"location":"tutorial/nexus-to-nomad.html#create-an-account","title":"Create an account","text":"<p>The very first thing you need to do is get a NOMAD account. If you don't have one you can register here.</p> <ol> <li>Navigate to nomad-lab.eu</li> <li>Click on <code>Login / Register</code> on the top right corner.</li> </ol> <p></p>"},{"location":"tutorial/nexus-to-nomad.html#create-an-upload","title":"Create an Upload","text":"<p>NOMAD allows you to have a draft working space called an upload. This allows you to test and prepare how your data will look in NOMAD before you publish it.</p> <p>Go to <code>Publish -&gt; Uploads</code></p> <p></p> <p></p> <p>Click <code>Create a new upload</code></p> <p></p>"},{"location":"tutorial/nexus-to-nomad.html#upload-your-nexus-file","title":"Upload your NeXus file","text":"<p>Now we can upload your FAIR NeXus file and let NOMAD interpret it for us.</p> <p>Click the <code>Drop files here...</code> button and choose your NeXus file from your device. </p> <p>Once NOMAD has interpreted your data, this is what your screen will look like.</p> <p></p>"},{"location":"tutorial/nexus-to-nomad.html#browsing-your-nexus-data","title":"Browsing your NeXus data","text":"<p>You can find the NOMAD interpretation of your data under entries. If you click on this arrow, you will be able to see an Overview of your NeXus file.</p> <p></p> <p></p> <p>On the Overview page you will be presented with <code>H5Web</code> that let's you browse the data in your <code>NeXus</code> file directly.</p> <p></p> <p></p> <p>NOMAD also interprets and normalizes this data to make it interoperable with other corners of materials research. To browse this normalized data you can browse the <code>DATA</code> tab. Here you see all the information NOMAD has picked up and made available for search and comparison with synthesis, experimental, and computational materials data.</p> <p></p> <p>Feel free to explore more!</p>"},{"location":"tutorial/nexus-to-nomad.html#learn-more","title":"Learn more","text":"<p>Learn more about uploading and publishing experimental data in NOMAD:</p> <ul> <li>NOMAD tutorial on uploading NeXus data</li> </ul>"}]}