{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"FAIRmat NeXus documentation","text":"<p>Within FAIRmat, we are extending the NeXus data format standard to support the FAIR data principles for experimental data in materials science (covering solid-state physics and the chemical physics of solids, as well as materials engineering). This is the documentation for both our contribution to the NeXus standard and for our tools for data conversion and verification.</p> <p><code>pynxtools</code>, the main tool under development, provides a data converter that maps experimental data and metadata to the NeXus format, performing parsing, normalization, visualization, and ontology matching. It combines various instrument output formats and electronic lab notebook (ELN) formats to an HDF5 file according to NeXus application definitions. In addition, <code>pynxtools</code> can be used to validate and verify NeXus files.</p> <p><code>pynxtools</code> offers scientists a convenient way to use the NeXus format and solves the challenge of unstructured and non-standardized data in experimental materials science. We consider this package useful for meeting the following FAIR principle as defined in FAIR Principles: Interpretations and Implementation Considerations: F2-4, I2-I3, and R1.</p> <p>FAIRmat's contribution to the existing NeXus standard, together with the tools provided through <code>pynxtools</code>, enable scientists and research groups working with data, as well as helping communities implement standardized FAIR research data.</p> <p>Additionally, the software is used as a plugin in the research data management system NOMAD for making experimental data searchable and publishable. NOMAD is developed by the FAIRmat consortium, as a part of the German National Research Data Infrastructure (NFDI).</p> Project and community <p>The work is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 460197019 (FAIRmat).</p>"},{"location":"index.html#tutorial","title":"Tutorial","text":"<p>A series of tutorials giving you an overview on how to store or convert your data to NeXus-compliant files.</p> <ul> <li>Converting your data to NeXus</li> <li>Uploading NeXus data to NOMAD</li> </ul>"},{"location":"index.html#how-to-guides","title":"How-to guides","text":"<p>How-to guides provide step-by-step instructions for a wide range of tasks.</p> <ul> <li>Build your own pynxtools plugin</li> <li>Implement a reader based on the MultiFormatReader</li> <li>Validation of NeXus files</li> <li>Creation of NeXus files in python via hard-coding</li> <li>Using pynxtools test framework for plugins</li> <li>Using pynxtools tests in parallel</li> </ul> <p>The following How-to guides are still under development:</p> <ul> <li>Writing an application definition</li> <li>Storing data in multiple application definitions</li> <li>Representing experimental geometries</li> </ul>"},{"location":"index.html#learn","title":"Learn","text":""},{"location":"index.html#an-introduction-to-nexus-and-its-design-principles","title":"An introduction to NeXus and its design principles","text":"<ul> <li>An introduction to NeXus</li> <li>Rules for storing data in NeXus</li> <li>The concept of multiple application definitions</li> <li>The MultiFormatReader as a reader superclass</li> </ul>"},{"location":"index.html#pynxtools","title":"pynxtools","text":"<ul> <li>Data conversion in <code>pynxtools</code></li> <li>Validation of NeXus files</li> <li>The MultiFormatReader as a reader superclass</li> </ul>"},{"location":"index.html#reference","title":"Reference","text":""},{"location":"index.html#nexus-definitions","title":"NeXus definitions","text":"<p>Here, you find the detailed list of application definitions and base classes and their respective fields.</p> <p>Or go directly to the official NIAC  or latest FAIRmat definitions.</p> <p>Note: To connect NeXus concepts with semantic web tools, efforts are underway to represent them using the W3C Web Ontology Language (OWL). See the NeXusOntology for more details.</p>"},{"location":"index.html#pynxtools_1","title":"pynxtools","text":"<p><code>pynxtools</code> has a number of command line tools that can be used to convert data and verify NeXus files. You can find more information about the API here.</p> <p>Within FAIRmat, we maintain a number of generic built-in pynxtools readers, together with reader plugins for different experimental techniques. Here you can find more information:</p> <ul> <li>Built-in pynxtools readers</li> <li>FAIRmat-supported pynxtools plugins</li> </ul>"},{"location":"how-tos/build-a-plugin.html","title":"Build your own pynxtools plugin","text":"<p>The pynxtools dataconverter is used to convert experimental data to NeXus/HDF5 files based on any provided NXDL schemas. The converter allows extending support to other data formats by allowing extensions called <code>readers</code>.  There exist a set of built-in pynxtools readers as well as pynxtools reader plugins to convert supported data files for some experimental techniques into NeXus-compliant files.</p> <p>Your current data is not supported yet by the built-in pynxtools readers or the officially supported pynxtools plugins?</p> <p>Don't worry, the following how-to will guide you through the steps of writing a reader for your own data.</p>"},{"location":"how-tos/build-a-plugin.html#getting-started","title":"Getting started","text":"<p>You should start by creating a clean repository that implements the following structure (for a plugin called <code>pynxtools-plugin</code>): <pre><code>pynxtools-plugin\n\u251c\u2500\u2500 .github/workflows\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 explanation\n\u2502   \u251c\u2500\u2500 how-tos\n\u2502   \u251c\u2500\u2500 reference\n\u2502   \u251c\u2500\u2500 tutorial\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 pynxtools_plugin\n\u2502       \u251c\u2500\u2500 reader.py\n\u251c\u2500\u2500 tests\n\u2502   \u2514\u2500\u2500 data\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 mkdocs.yaml\n\u251c\u2500\u2500 dev-requirements.txt\n\u2514\u2500\u2500 pyproject.toml\n</code></pre></p> <p>To identify <code>pynxtools-plugin</code> as a plugin for pynxtools, an entry point must be established (in the <code>pyproject.toml</code> file): <pre><code>[project.entry-points.\"pynxtools.reader\"]\nmydatareader = \"pynxtools_plugin.reader:MyDataReader\"\n</code></pre></p> <p>Note that it is also possible that your plugin contains multiple readers. In that case, each reader must have its unique entry point.</p> <p>Here, we will focus mostly on the <code>reader.py</code> file and how to build a reader. For guidelines on how to build the other parts of your plugin, you can have a look here:</p> <ul> <li>Documentation writing guide</li> <li>Plugin testing framework</li> </ul>"},{"location":"how-tos/build-a-plugin.html#writing-a-reader","title":"Writing a Reader","text":"<p>After you have established the main structure, you can start writing your reader. The new reader shall be placed in <code>reader.py</code>.</p> <p>Then implement the reader function:</p> reader.py<pre><code>\"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\nfrom typing import Tuple, Any\n\nfrom pynxtools.dataconverter.readers.base.reader import BaseReader\n\nclass MyDataReader(BaseReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    supported_nxdls = [\n        \"NXmynxdl\" # this needs to be changed during implementation.\n    ]\n\n    def read(\n        self,\n        template: dict = None,\n        file_paths: Tuple[str] = None,\n        objects: Tuple[Any] = None\n    ) -&gt; dict:\n        \"\"\"Reads data from given file and returns a filled template dictionary\"\"\"\n        # Here, you must provide functionality to fill the the template, see below.\n        # Example:\n        # template[\"/entry/instrument/name\"] = \"my_instrument\"\n\n        return template\n\n\n# This has to be set to allow the convert script to use this reader. Set it to \"MyDataReader\".\nREADER = MyDataReader\n</code></pre>"},{"location":"how-tos/build-a-plugin.html#the-reader-template-dictionary","title":"The reader template dictionary","text":"<p>The read function takes a <code>Template</code> dictionary, which is used to map from the measurement (meta)data to the concepts defined in the NeXus application definition. The template contains keys that match the concepts in the provided NXDL file.</p> <p>The returned template dictionary should contain keys that exist in the template as defined below. The values of these keys have to be data objects to populate the output NeXus file. They can be lists, numpy arrays, numpy bytes, numpy floats, numpy ints, ... . Practically you can pass any value that can be handled by the <code>h5py</code> package.</p> <p>Example for a template entry:</p> <pre><code>{\n  \"/entry/instrument/source/type\": \"None\"\n}\n</code></pre> <p>For a given NXDL schema, you can generate an empty template with the command <pre><code>user@box:~$ dataconverter generate-template --nxdl NXmynxdl\n</code></pre></p>"},{"location":"how-tos/build-a-plugin.html#naming-of-groups","title":"Naming of groups","text":"<p>In case the NXDL does not define a <code>name</code> for the group the requested data belongs to, the template dictionary will list it as <code>/NAME_IN_NXDL[name_in_output_nexus]</code>. You can choose any name you prefer instead of the suggested <code>name_in_output_nexus</code> (see here for the naming conventions). This allows the reader function to repeat groups defined in the NXDL to be outputted to the NeXus file.</p> <pre><code>{\n  \"/ENTRY[my_entry]/INSTRUMENT[my_instrument]/SOURCE[my_source]/type\": \"None\"\n}\n</code></pre>"},{"location":"how-tos/build-a-plugin.html#attributes","title":"Attributes","text":"<p>For attributes defined in the NXDL, the reader template dictionary will have the assosciated key with a \"@\" prefix to the attributes name at the end of the path:</p> <pre><code>{\n  \"/entry/instrument/source/@attribute\": \"None\"\n}\n</code></pre>"},{"location":"how-tos/build-a-plugin.html#units","title":"Units","text":"<p>If there is a field defined in the NXDL, the converter expects a filled in /data/@units entry in the template dictionary corresponding to the right /data field unless it is specified as NX_UNITLESS in the NXDL. Otherwise, a warning will be shown.</p> <pre><code>{\n  \"/ENTRY[my_entry]/INSTRUMENT[my_instrument]/SOURCE[my_source]/data\": \"None\",\n  \"/ENTRY[my_entry]/INSTRUMENT[my_instrument]/SOURCE[my_source]/data/@units\": \"Should be set to a string value\"\n}\n</code></pre>"},{"location":"how-tos/build-a-plugin.html#links","title":"Links","text":"<p>You can also define links by setting the value to sub dictionary object with key <code>link</code>:</p> <pre><code>template[\"/entry/instrument/source\"] = {\"link\": \"/path/to/source/data\"}\n</code></pre>"},{"location":"how-tos/build-a-plugin.html#building-off-of-the-basereader","title":"Building off of the BaseReader","text":"<p>When building off the <code>BaseReader</code>, the developer has the most flexibility. Any new reader must implement the <code>read</code> function, which must return a filled template object.</p>"},{"location":"how-tos/build-a-plugin.html#building-off-of-the-multiformatreader","title":"Building off of the MultiFormatReader","text":"<p>While building on the <code>BaseReader</code> allows for the most flexibility, in most cases it is desirable to implement a reader that can read in multiple file formats and then populate the template based on the read data. For this purpose, <code>pynxtools</code> has the <code>MultiFormatReader</code>, which can be readily extended for your own data.</p> <p>You can find an extensive how-to guide to build off the <code>MultiFormatReader</code> here.</p>"},{"location":"how-tos/build-a-plugin.html#calling-the-reader-from-the-command-line","title":"Calling the reader from the command line","text":"<p>The dataconverter can be executed using: <pre><code>user@box:~$ dataconverter --reader mydatareader --nxdl NXmynxdl --output path_to_output.nxs\n</code></pre> Here, the <code>--reader</code> flag must match the reader name defined in <code>[project.entry-points.\"pynxtools.reader\"]</code> in the pyproject.toml file. The NXDL name passed to <code>--nxdl</code>must be a valid NeXus NXDL/XML file in <code>pynxtools.definitions</code>.</p> <p>Aside from this default structure, there are many more flags that can be passed to the dataconverter call. Here is its API:</p>"},{"location":"how-tos/build-a-plugin.html#dataconverter","title":"dataconverter","text":"<p>This command allows you to use the converter functionality of the dataconverter.</p> <p>Usage:</p> <pre><code>dataconverter [OPTIONS] [FILES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--input-file</code> text Deprecated: Please use the positional file arguments instead. The path to the input data file to read. Repeat for more than one file. default=[] This option is required if no '--params-file' is supplied. <code>[]</code> <code>--reader</code> choice (<code>example</code> | <code>json_map</code> | <code>json_yml</code> | <code>multi</code>) The reader to use. Examples are json_map or readers from a pynxtools plugin. default='json_map' This option is required if no '--params-file' is supplied. <code>json_map</code> <code>--nxdl</code> text The name of the NeXus application definition file to use without the extension nxdl.xml. This option is required if no '--params-file' is supplied. None <code>--output</code> text The path to the output NeXus file to be generated. default='output.nxs' <code>output.nxs</code> <code>--params-file</code> filename Allows to pass a .yaml file with all the parameters the converter supports. None <code>--ignore-undocumented</code> boolean Ignore all undocumented fields during validation. <code>False</code> <code>--fail</code> boolean Fail conversion and don't create an output file if the validation fails. <code>False</code> <code>--skip-verify</code> boolean Skips the verification routine during conversion. <code>False</code> <code>--mapping</code> text Takes a .mapping.json file and converts data from given input files. None <code>-c</code>, <code>--config</code> file A json config file for the reader None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"how-tos/create-nexus-files-by-python.html","title":"Use python to create NeXus files","text":"<p>The goal</p> <p>Use python to create a NeXus file (.nxs) by hardcoding via the python package <code>h5py</code>. NeXus files can also be created by our software <code>pynxtools</code> automatically, but ONLY IF a reader for the specific device/instrument/data-structure exists. This How-To is intended as easy access to FAIR data structures via NeXus. For static-datastructures (i.e., always the same type of standard measurement) or one-time examples (small data publications), this may provide a feasible solution. For large scaled automated file processing, storage, and validation, it is advisable to use <code>pynxtools</code> and its measurement method specific plugins</p> <p>You can find the necessary file downloads here.</p>"},{"location":"how-tos/create-nexus-files-by-python.html#make-nexus-file-by-python","title":"Make NeXus file by python","text":"<p>Install <code>h5py</code> via <code>pip</code>: <pre><code>`pip install h5py`\n</code></pre></p> <p>Then you can create a NeXus file by the python script called h5py_nexus_file_creation.py.</p> <pre><code># Import h5py, to write an hdf5 file\nimport h5py\n\n# create a h5py file in writing mode with given name \"NXopt_minimal_example\", file extension \"nxs\"\nf = h5py.File(\"NXopt_minimal_example.nxs\", \"w\")\n\n# there are only 3 fundamental objects: &gt;group&lt;, &gt;attribute&lt; and &gt;datafield&lt;.\n\n\n# create a &gt;group&lt; called \"entry\"\nf.create_group('/entry')\n\n# assign the &gt;group&lt; called \"entry\" an &gt;attribute&lt;\n# The attribute is \"NX_class\"(a NeXus class) with the value of this class is \"NXentry\"\nf['/entry'].attrs['NX_class'] = 'NXentry'\n\n# create &gt;datafield&lt; called \"definition\" inside the entry, and assign it the value \"NXoptical_spectroscopy\"\n# This field is important, as it is used in validation process to identify the NeXus definition.\nf['/entry/definition'] = 'NXoptical_spectroscopy'\n</code></pre> <p>This proves a starting point of the NeXus file. We will go through these functions in the following.</p>"},{"location":"how-tos/create-nexus-files-by-python.html#add-nexus-concepts-by-python","title":"Add NeXus concepts by python","text":"<p>Go to FAIRmat NeXus definitions</p> <p>Scroll down until you see the search box named \"Quick search\".</p> <p>Type \"NXoptical\" and press start the search.</p> <p>You see several search results, select the one with is named \"NXoptical_spectroscopy\".</p> <p>Then you are (ideally) on this page: NXoptical_spectroscopy NeXus definition</p> <p>You see a tree-like structure of the NeXus definition NXoptical_spectrosocopy with several tree nodes: Status, Description, Symbols, Groups_cited, Structure. For now, only the part in Structure is of interest. This contains the information which has to be written in the python code to add fields/groups/attributes to the NeXus file.</p> <p>Use your browser search (CRTL+F) and search for \"required\". Ideally, your browser highlights all concepts which are required. You have to add those to the python script to extend your created .nxs file. (Which fields/groups/attributes are \"required\" was defined by the respective scientific community, to ensure that the data serves the FAIR principles.)</p> <p>In the following, it will be shown how the python script has to be extended for the three fundamental objects:</p> <ol> <li> <p>Attribute</p> </li> <li> <p>Datafield</p> </li> <li> <p>Group</p> </li> </ol>"},{"location":"how-tos/create-nexus-files-by-python.html#adding-an-attribute","title":"Adding an attribute","text":"<p>Search for the first concept/object in the NeXus file which is not created yet. It is:</p> <p>@version: (required) NX_CHAR \u2906</p> <ol> <li> <p>It is located in the tree at position: ENTRY/definition/</p> </li> <li> <p>The \"@\" indicates that this is an attribute of the concept \"definition\".</p> </li> <li> <p>The name of the attribute is \"version\".</p> </li> <li> <p>Since it is \"required\", that means this attribute has to be added so that the resulting NeXus file is compliant with the NeXus definition \"NXoptical_spectroscopy\".</p> </li> <li> <p>The \"NX_CHAR\" indicates the datatype. This should be a string: \"The preferred string representation is UTF-8\" (more information see here)</p> </li> </ol> <p></p> <p>Now the python script has to be extended in the following:</p> <pre><code>f['/entry/definition'].attrs['version'] = 'v2024.02'\n</code></pre> <p>This h5py command adds the attribute named \"version\" with the value \"v2024.02\" to the HDF5 dataset called  \"/entry/definition\". The same is done for the URL attribute:</p> <pre><code>f['/entry/definition'].attrs['URL'] = 'https://github.com/FAIRmat-NFDI/nexus_definitions/blob/f75a29836431f35d68df6174e3868a0418523397/contributed_definitions/NXoptical_spectroscopy.nxdl.xml'\n</code></pre> <p>For your use case, you may want to use a different version of the NeXus definitions, since these are changed over time. In the following, it is shown where to obtain the correct version and URL.</p> <p>Get the values: version and URL</p> <p>At the time, you create the NeXus definition. Go to the page of the respectively used NeXus concept, i.e. NXoptical_spectroscopy</p> <p>Scroll down until you find \"NXDL Source:\" and follow this link, i.e. NXoptical_spectroscopy.nxdl.xml</p> <p>This is the GitHub website, in which the latest (FAIRmat) NeXus definition of NXoptical_spectroscopy is stored in the NeXus definition language file (.nxdl). The information is structured in the xml format.</p> <p>Now you have to copy the permalink of this file. Go to the top right side of the website. Find the Menu made by 3 dots:</p> <p></p> <p>Copy the permalink and insert it as value for the \"URL\" attribute (Step 1, Red box in the image)</p> <p>Go to \"nexus_definitions\" (Step 2, Red box in the image)</p> <p></p> <p>On the right side, you should see below \"Releases\" the \"tags\" (Red box in the image). Follow this link.</p> <p>Copy the latest tag, which should look similar to \"v2024.02\". Insert it as value for the \"version\" attribute.</p> <p>Disclaimer When specifying this version tag, it would be better to include the \"GitHub commit id\" as well. In this way, a pynxtools generated version tag might look like this: <code>v2022.07.post1.dev1278+g1d7000f4</code>. If you have pynxtools installed, you can get the tag by:</p> <pre><code>&gt;&gt;&gt; from pynxtools import get_nexus_version\n&gt;&gt;&gt; get_nexus_version()\n'v2022.07.post1.dev1284+gf75a2983'\n</code></pre>"},{"location":"how-tos/create-nexus-files-by-python.html#adding-a-datafield","title":"Adding a datafield","text":"<p>Two attributes were added to \"ENTRY/definition\", both of which were required. By now, this part of the NeXus file fulfills the requirements of the application definition NXoptical_spectroscopy.</p> <p>The next required concept of NXoptical_spectrsocopy is \"experiment_type\".</p> <p>experiment_type: (required) NX_CHAR</p> <ol> <li> <p>It is located in the tree at position: ENTRY/</p> </li> <li> <p>There is no \"@\" in front of \"experiment_type\". So, this may be a group or a datafield.</p> </li> <li> <p>The name of this group/datafield is \"experiment_type\".</p> </li> <li> <p>The \"required\" indicates that this group/datafield has to be added to be in line with the NeXus definition \"NXoptical_spectroscopy\".</p> </li> <li> <p>The \"NX_CHAR\" indicates the datatype. This should be a string: \"The preferred string representation is UTF-8\" (more information see here).</p> </li> <li> <p>The \"NX_CHAR\" indicates that this is a datafield. It is NOT a group.     A group is a NeXus class. \"NXentry\" is for example a NeXus class, while \"NX_CHAR\" indicates the datatype of the field.     Whether or not the underscore \"_\" is present after NX, indicates therefore if it is a NeXus class or datafield.</p> </li> </ol> <p>Read the documentation at \"\u25b6 Specify the type of the optical experiment. ...\" by extending it via click on the triangle symbol. You should see something like this:</p> <p></p> <p>There, the value of the datafield has to be one of the shown list, since it is an enumeration (e.g. \"transmission spectroscopy\"). Note that this is case sensitive.</p> <p>Therefore, the python script has to be extended by:</p> <pre><code>f['/entry/experiment_type'] = 'transmission spectroscopy'\n</code></pre>"},{"location":"how-tos/create-nexus-files-by-python.html#adding-a-group","title":"Adding a group","text":"<p>The first required group in NXoptical_spectroscopy on the \"ENTRY/\" level is \"INSTRUMENT: (required) NXinstrument \u2906\"</p> <ol> <li> <p>It is located in the tree at position: NXentry/</p> </li> <li> <p>There is no \"@\" in front of \"INSTRUMENT\" and because the \"NXinstrument\" is a NeXus class, this has to be implemented as group in the python script.</p> </li> <li> <p>The \"required\" indicates that this group has to be added to be in line with the NeXus definition \"NXoptical_spectroscopy\".</p> </li> <li> <p>The \"NXinstrument\" indicates that it is a NeXus class (or group in python), as it starts with \"NX\" - without an underscore \"_\". It can also not be found at the data types.</p> </li> <li> <p>As this is a group, attributes or values may be assigned to it.</p> </li> <li> <p>As this is a group, it can contain many datafields or groups.</p> </li> <li> <p>The uppercase notation of \"INSTRUMENT\" means:</p> <ol> <li> <p>You can give INSTRUMENT almost any name, such as \"abc\" or \"Raman_setup\" (see \"regex\" or regular expression).</p> </li> <li> <p>You can create as many groups with the class NXinstrument as you want. Their names have to be different.</p> </li> <li> <p>For more information see the NeXus rules</p> </li> </ol> </li> </ol> <p>The respective python code to implement a NXinstrument class (or equivalently in python group) with the name \"experiment_setup_1\" is:</p> <pre><code>f.create_group('/entry/experiment_setup_1')\nf['/entry/experiment_setup_1'].attrs['NX_class'] = 'NXinstrument'\n</code></pre> <p>The first line creates the group with the name \"experiment_setup_1\".</p> <p>The second line assigns this group the attribute with the name \"NX_class\" and its value \"NXinstrument\".</p>"},{"location":"how-tos/create-nexus-files-by-python.html#finishing-the-nexus-file","title":"Finishing the NeXus file","text":"<p>This has to be done by using the respective NeXus definition website:</p> <p>NXoptical_spectroscopy</p> <p>And by searching for all \"required\" entries. The next required entries are located inside the NXinstrument class:</p> <ol> <li> <p>beam_TYPE: (required) NXbeam \u2906</p> </li> <li> <p>detector_TYPE: (required) NXdetector \u2906</p> </li> </ol> <p>Both are groups. \"beam_TYPE\" could be named: \"beam_abc\" or \"beam_Raman_setup\". Use the knowledge above to extend the python script to create those NeXus file entries.</p> <p>Note for required NeXus concepts</p> <p>Above in the definition of NXoptical_spectroscopy, you as well may found a required entry \"depends_on: (required) NX_CHAR \u2906\". This is at the level of \"ENTRY/reference_frames/beam_ref_frame\". If you don't have the group \"beam_ref_frame\" because this is \"optional\", then you don't need to have this field.</p> <p>Continue by validating the NeXus file</p>"},{"location":"how-tos/create-nexus-files-by-python.html#feedback-and-contact","title":"Feedback and contact","text":"<ol> <li> <p>Best way is to contact the FAIRmat team directly by creating a Github Issue.</p> </li> <li> <p>ron.hildebrandt(at)physik.hu-berlin.de</p> </li> </ol>"},{"location":"how-tos/installation_notes_nxvalidate.html","title":"Installation notes nxvalidate","text":"<p>This lists some notes for installation of nxvalidate on Ubuntu and Windows. For windows, the installation of the XML2 library was not sucessful. This should be possible, but could not reproduced yet.</p>"},{"location":"how-tos/installation_notes_nxvalidate.html#cnxvalidate-installation-on-ubuntu-2204","title":"cnxvalidate installation on Ubuntu 22.04","text":"<p>These commands install nxvaldiate on a fresh Ubuntu 22.04 system (tested with Linux running from USB stick).</p> <pre><code>sudo apt-get update\nsudo apt-get install git\nsudo apt-get install build-essential\nsudo add-apt-repository universe\nsudo apt-get install libhdf5-serial-dev\nsudo apt-get -y install pkg-config\nsudo apt upgrade -y\nsudo apt-get -y install cmake\nsudo apt-get install libxml2-dev\n\nmkdir nexusvalidate\ncd nexusvalidate\ngit clone https://github.com/nexusformat/cnxvalidate.git\ncd cnxvalidate/\nmkdir build\ncd build/\ncmake ../\nmake\n</code></pre>"},{"location":"how-tos/installation_notes_nxvalidate.html#cnxvalidate-installation-on-windows","title":"cnxvalidate installation on windows:","text":""},{"location":"how-tos/installation_notes_nxvalidate.html#-cmake","title":"-- CMAKE","text":"<p>https://cmake.org/download/</p> <p>--&gt; cmake-3.30.2-windows-x86_64.msi</p> <p>Install with .msi</p>"},{"location":"how-tos/installation_notes_nxvalidate.html#-hdf5","title":"-- HDF5","text":"<p>Download hdf5-1.14.4-2-win-vs2022_cl.zip** from **https://www.hdfgroup.org/downloads/hdf5/</p> <p>unzip the .zip file</p> <p>put the file into the folder</p> <pre><code>C:\\hdf5\n</code></pre> <p>(can be named differently, but no spaces are allowed for this path)</p> <pre><code>set PATH=%PATH%;C:\\your\\path\\here\\\n</code></pre>"},{"location":"how-tos/installation_notes_nxvalidate.html#-libiconv","title":"-- libiconv","text":"<p>https://github.com/vovythevov/libiconv-cmake</p> <pre><code>git clone\n</code></pre> <p>cd to downloaded directory</p> <pre><code>mkdir build\ncd build\ncmake ..\n</code></pre>"},{"location":"how-tos/installation_notes_nxvalidate.html#-xml2","title":"-- XML2","text":"<p>??? Unsolved...</p> <p>Please create GitHub issue here if you could solve this.</p>"},{"location":"how-tos/run-tests-in-parallel.html","title":"Running <code>pynxtools</code> Tests in Parallel","text":"<p>The <code>pytest</code> framework allows tests to run in sequential and parallel using third-party plugins such as <code>pytest-xdist</code>. In our <code>pytest</code> setup for <code>pynxtools</code>, we use <code>pytest-xdist</code> to execute tests in parallel. To handle shared resources among multiple tests, tests are grouped using the <code>@pytest.mark.xdist_group</code> fixture. This prevents classic race conditions by ensuring that tests sharing the same resources are executed sequentially.</p>"},{"location":"how-tos/run-tests-in-parallel.html#running-tests-sequentially","title":"Running Tests Sequentially","text":"<p>In a local setup, tests can be run sequentially using the following command:</p> <pre><code>$ python -m pytest tests\n</code></pre> <p>This will execute all tests in a sequential manner. For more details, refer to the official documentation: How to invoke pytest.</p>"},{"location":"how-tos/run-tests-in-parallel.html#running-tests-in-parallel","title":"Running Tests in Parallel","text":"<p>The <code>pytest-xdist</code> plugin can be used to speed up test execution by distributing tests among available workers. To prevent race conditions, tests that share the same resources are grouped using the <code>@pytest.mark.xdist_group(name=\"group_name\")</code> fixture. These grouped tests must be run with the <code>--dist loadgroup</code> flag. For example:</p> <pre><code>$ python -m pytest tests -n auto --dist loadgroup\n</code></pre> <p>Here: - The <code>-n auto</code> flag tells <code>pytest</code> to automatically distribute tests among all available workers. - The <code>--dist loadgroup</code> flag ensures that tests marked with the same @pytest.mark.xdist_group(name=\"...\") are executed serially.</p> <p>This setup allows for efficient parallel test execution while maintaining the integrity of tests that depend on shared resources.</p>"},{"location":"how-tos/testing-validation-tools.html","title":"The shows the example of testing NeXus files with validation methods","text":"<p>There are different methods, which can be used for file validation.</p> <ul> <li>pynxtools (verify_nexus, read_nexus)</li> <li>nxvalidate</li> <li>punx</li> </ul> <p>Here some examples are shown for the respective methods, by using a pynxtools-ellips generated NeXus file. This generated file already contained some level of validation, as a generated and filled template for this NeXus application definition was used.</p>"},{"location":"how-tos/testing-validation-tools.html#1-example-from-pynxtools-read_nexus-function","title":"1. Example from pynxtools read_nexus function","text":"<p><code>read_nexus -f SiO2onSi.ellips.nxs &gt; read_nexus_output_file.txt</code> <pre><code>NXellipsometry.nxdl.xml:/ENTRY/data_collection/data_software\nNXprogram.nxdl.xml:\nDEBUG: @url - IS NOT IN SCHEMA\n####################################################\nNXellipsometry.nxdl.xml:/ENTRY/definition\nNXoptical_spectroscopy.nxdl.xml:/ENTRY/definition\nNXentry.nxdl.xml:/definition\nDEBUG: @url - IS NOT IN SCHEMA\n####################################################\nDEBUG: ===== GROUP (//entry/instrument/software_RC2 [NXellipsometry::/NXentry/NXinstrument/software_RC2]): &lt;HDF5 group \"/entry/instrument/software_RC2\" (1 members)&gt;\nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\nDEBUG: ===== FIELD (//entry/instrument/software_RC2/program): &lt;HDF5 dataset \"program\": shape (), type \"|O\"&gt;\nDEBUG: value: b'CompleteEASE' \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\nDEBUG: ===== ATTRS (//entry/instrument/software_RC2/program@url)\nDEBUG: value: https://www.jawoollam.com/ellipsometry-software/completeease \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\nDEBUG: ===== ATTRS (//entry/instrument/software_RC2/program@version)\nDEBUG: value: 6.37 \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\n####################################################\n</code></pre> Total 6 Errors 1. @url. Changing to @URL could fix this maybe. 2. Software_RC2 not detected as NXprogram. This is indeed not assigned.</p>"},{"location":"how-tos/testing-validation-tools.html#2-example-from-pynxtools-verify_nexus-function","title":"2. Example from pynxtools verify_nexus function","text":"<p><code>verify_nexus SiO2onSi.ellips.nxs</code></p> <p><pre><code>WARNING: Field /entry/data_collection/Delta_50deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_50deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_60deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_60deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_70deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Delta_70deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_50deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_50deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_60deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_60deg_errors/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_70deg/@units written without documentation.\nWARNING: Field /entry/data_collection/Psi_70deg_errors/@units written without documentation.\nWARNING: Missing attribute: \"/ENTRY/DATA/@axes\"\nWARNING: Missing attribute: \"/ENTRY/DATA/@signal\"\nInvalid: The entry `entry` in file `SiO2onSi.ellips.nxs` is NOT a valid file according to the `NXellipsometry` application definition.\n</code></pre> Total 14 Errors Total 3 Errors - without documentation 1. Psi+Delta with Unit+Errors written without doc. 2. Data @axes + @signal. May not find NXdata? Attributes are present in .nxs file. 3. entry not valid in NXellips.</p>"},{"location":"how-tos/testing-validation-tools.html#3-example-from-nxvalidate","title":"3. Example from nxvalidate","text":"<p><code>`PATH_TO_NX_VALIDATE_EXE/nxvalidate -l PATH_TO_FAIRMAT_NEXUS_DEF/nexus_definitions/ PATH_TO_NEXUS_FILE/SiO2onSi.ellips.nxs</code> <pre><code>definition=NXellipsometry.nxdl.xml message=\"Data type mismatch, expected NX_BOOLEAN, got H5T_ENUM {      H5T_STD_I8LE;      \"FALSE\"            0;      \"TRUE\"             1;   }\" nxdlPath=/NXentry/NXinstrument/NXlens_opt/data_correction sev=error dataPath=/entry/instrument/focussing_probes/data_correction dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXinstrument/NXbeam sev=error dataPath=/entry/instrument dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXinstrument/NXdetector sev=error dataPath=/entry/instrument dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Data type mismatch, expected NX_BOOLEAN, got H5T_ENUM {      H5T_STD_I8LE;      \"FALSE\"            0;      \"TRUE\"             1;   }\" nxdlPath=/NXentry/NXsample/backside_roughness sev=error dataPath=/entry/sample/backside_roughness dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required units attribute missing\" nxdlPath=/NXentry/NXdata/measured_data sev=error dataPath=/entry/data_collection/measured_data dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Data type mismatch, expected NX_BOOLEAN, got H5T_STRING {      STRSIZE H5T_VARIABLE;      STRPAD H5T_STR_NULLTERM;      CSET H5T_CSET_UTF8;      CTYPE H5T_C_S1;   }\" nxdlPath=/NXentry/NXidentifier/is_persistent sev=error dataPath=/entry/experiment_identifier/is_persistent dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXdata sev=error dataPath=/entry dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \ndefinition=NXellipsometry.nxdl.xml message=\"Required units attribute missing\" nxdlPath=/NXentry/NXprocess/depolarization sev=error dataPath=/entry/derived_parameters/depolarization dataFile=/home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs \n9 errors and 85 warnings found when validating /home/ron/GitPynxtoolsValidation/nexus_files/SiO2onSi.ellips.nxs\n</code></pre> Total 8 or 9 Errors 1. Datatype mismatch for Bools: \"H5T_STRING\" or \"H5T_ENUM\" instead of \"NX_BOOLEAN\". In NXlens_opt, backside_roughness and is_persistent. 2. NXbeam + NXdetector: Has a problem with \"  exists: [min, 1, max, infty]\" 3. \"/NXentry/NXdata/measured_data\". Units are missing (unit should be NX_ANY). 4. It does not find the NXdata (in this file it is at /entry/data_collection/). 5. Depolarization is not assigned the unit NX_unitless.</p>"},{"location":"how-tos/testing-validation-tools.html#nxvalidate-errors","title":"nxvalidate Errors:","text":"<ol> <li> <p>\"Data type mismatch, expected NX_BOOLEAN\" --&gt; \"NeXus interprets NX_BOOLEAN differently than h5py. NeXus uses an integer of 1 byte for NX_BOOLEAN. This is an int8 or uint8.\" --&gt; https://github.com/nexusformat/cnxvalidate/issues/34</p> </li> <li> <p>Required group missing for \"NXbeam\" and \"NXdetector\". Probem with NeXus requirement as given in the .yaml file by: \"exists: [min, 1, max, infty]\"?</p> </li> <li> <p>\"Required units attribute missing\" for entry/data_collection/measured_data --&gt; ? unclear. Units are assigned in NeXus file.</p> </li> <li> <p>\"Required group missing\" for /entry ---&gt; ? unclear.</p> </li> </ol>"},{"location":"how-tos/testing-validation-tools.html#nxvalidate-warnings","title":"nxvalidate Warnings:","text":"<p>I think warnings can be evoked by: (-t in front of the NeXus file):</p> <pre><code>~/FAIRmat/WorkshopNeXusValid02/nxvalidate/cnxvalidate/build$ ./nxvalidate -l /home/ron/FAIRmat/WorkshopNeXusValid02/nxvalidate/nexus_definitions/ -t SiO2onSi.ellips.nxs\n</code></pre> <p>Most of the warnings are not critical at all. Not sure if this is helpful at all:</p> <p>here are some examples of the \"messages\" of the warnings:</p> <ol> <li> <p>\"Optional group missing\"</p> </li> <li> <p>\"Optional field missing\"</p> </li> <li> <p>\"Optional attribute units missing\"</p> </li> <li> <p>\"Validating field\"</p> </li> <li> <p>\"Validating group\"</p> </li> <li> <p>\"Additional base class dataset name found\"</p> </li> <li> <p>\"Additional base class dataset address found\"</p> </li> <li> <p>\"Unknown dataset wavelength_spectrum found\"</p> </li> <li> <p>\"Additional base class group notes of type NXnote found\"</p> </li> <li> <p>\"Additional base class group environment_sample of type NXenvironment found\"</p> </li> </ol>"},{"location":"how-tos/testing-validation-tools.html#4-example-from-punx","title":"4. Example from punx","text":"<p><code>punx validate SiO2onSi.ellips.nxs</code> Not possible, as only the NIAC NeXus definitoon can right now be used as reference. Unclear if the <code>punx install</code> functionality is working or still developed.</p>"},{"location":"how-tos/testing-validation-tools.html#summary","title":"Summary","text":"Error Message origin Error in .nxs file? Error in validation tool? unit + error without doc verify_nexus ? ? no @signal @axes for NXdata verify_nexus no yes entry not valid in NXellips verify_nexus ? ? @url error read_nexus no yes Software_RC2 no NXprogram read_nexus yes no Bool Data types nxvalidate ? ? exists: [min, 1, max, infty] nxvalidate no yes Unit missing for measured_data nxvalidate yes no NXdata not present nxvalidate no yes No unit for depolarization nxvalidate yes no"},{"location":"how-tos/testing-validation-tools.html#note","title":"NOTE","text":"<p>Only the nxvalidate method seems to point out completely missing required concepts.</p> <p>I tested this with an empty NeXus file, in which only the \"definition\" was given (NXellipsometry and NXraman).</p>"},{"location":"how-tos/transformations.html","title":"Storing experimental geometries","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p>"},{"location":"how-tos/use-multi-format-reader.html","title":"How to use the built-in MultiFormatReader","text":"<p>While building on the <code>BaseReader</code> allows for the most flexibility, in most cases it is desirable to implement a reader that can read in multiple file formats and then populate the template based on the read data. For this purpose, <code>pynxtools</code> has the <code>MultiFormatReader</code>, which can be readily extended for your own data. In this how-to guide, we will focus on an implementation using a concrete example. If you are also interested in the general structure of the <code>MultiFormatReader</code>, you can find more information here.</p>"},{"location":"how-tos/use-multi-format-reader.html#getting-started","title":"Getting started","text":"<p>Note: You can find all of the data and the developed python scripts here.</p> <p>Here, we will implement a reader called <code>MyDataReader</code> that builds on the <code>MultiFormatReader</code>. <code>MyDataReader</code> is an example for a reader that can read HDF5 data from a specific technology-partner data set, as well as additional metadata from am electronic lab notebook (in YAML format).</p> <p>For demonstration purposess, we will work with a very simple mock application definition:</p> NXsimple.nxdl.xml<pre><code>&lt;definition xmlns=\"http://definition.nexusformat.org/nxdl/3.1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" category=\"application\" type=\"group\" name=\"NXsimple\" extends=\"NXobject\" xsi:schemaLocation=\"http://definition.nexusformat.org/nxdl/3.1 ../nxdl.xsd\"&gt;\n    &lt;doc&gt;\n         Mock application definition.\n    &lt;/doc&gt;\n    &lt;group type=\"NXentry\"&gt;\n        &lt;field name=\"definition\"&gt;\n            &lt;attribute name=\"version\"/&gt;\n            &lt;enumeration&gt;\n                &lt;item value=\"NXsimple\"/&gt;\n            &lt;/enumeration&gt;\n        &lt;/field&gt;\n        &lt;field name=\"title\"/&gt;\n        &lt;group type=\"NXuser\" recommended=\"true\"&gt;\n            &lt;field name=\"name\"&gt;\n                &lt;doc&gt;\n                     Name of the user.\n                &lt;/doc&gt;\n            &lt;/field&gt;\n            &lt;field name=\"address\" recommended=\"true\"&gt;\n                &lt;doc&gt;\n                     Name of the affiliation of the user.\n                &lt;/doc&gt;\n            &lt;/field&gt;\n        &lt;/group&gt;\n        &lt;group type=\"NXinstrument\"&gt;\n            &lt;doc&gt;\n                 Description of the instrument and its individual parts.\n            &lt;/doc&gt;\n            &lt;attribute name=\"version\"&gt;\n                &lt;doc&gt;\n                     Version of the instrument.\n                &lt;/doc&gt;\n            &lt;/attribute&gt;\n            &lt;group type=\"NXdetector\"&gt;\n                &lt;field name=\"count_time\" type=\"NX_NUMBER\" units=\"NX_TIME\" recommended=\"true\"&gt;\n                    &lt;doc&gt;\n                         Elapsed actual counting time\n                    &lt;/doc&gt;\n                &lt;/field&gt;\n            &lt;/group&gt;\n        &lt;/group&gt;\n        &lt;group name=\"sample\" type=\"NXsample\"&gt;\n            &lt;field name=\"name\"/&gt;\n            &lt;field name=\"physical_form\" recommended=\"true\"/&gt;\n            &lt;field name=\"temperature\" type=\"NX_FLOAT\" recommended=\"true\" units=\"NX_TEMPERATURE\"/&gt;\n        &lt;/group&gt;\n        &lt;group name=\"data\" type=\"NXdata\"&gt;\n            &lt;doc&gt;\n                 The default NXdata group containing a view on the measured data.\n            &lt;/doc&gt;\n        &lt;/group&gt;\n    &lt;/group&gt;\n&lt;/definition&gt;\n</code></pre> <p>The NXDL requires a user, some sample information, some instrument metadata, and the measured data to be written. Some groups, fields, and attributes are strictly required (the default), others just recommended.</p> <p>Note that in order to be recognized as a valid application definition, this file should be copied to the <code>definitions</code> submodule at <code>pynxtools.definitions</code>.</p> <p>We first start by implementing the class and its <code>__init__</code> call: reader.py<pre><code>\"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\nfrom typing import Tuple, Any\n\nfrom pynxtools.dataconverter.readers.base.reader import ParseJsonCallbacks, MultiFormatReader\n\nclass MyDataReader(MultiFormatReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    supported_nxdls = [\n        \"NXsimple\"\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.extensions = {\n            \".yml\": self.handle_eln_file,\n            \".yaml\": self.handle_eln_file,\n            \".json\": self.set_config_file,\n            \".hdf5\": self.handle_eln_file,\n            \".h5\": self.handle_eln_file,\n        }\n\nREADER = MyDataReader\n</code></pre> Note that here we are adding handlers for three types of data file extensions: 1. <code>\".hdf5\"</code>, <code>\".h5\"</code>: This will be used to parse in the (meta)data from the instrument's HDF5 file. 2. <code>\".yml\"</code>, <code>\".yaml\"</code>: This will be used to parse in the (meta)data from the ELN file. 3. <code>\".json\"</code>: This will be used to read in the config file, which is used to map from the (meta)data concepts from the instrument and ELN data to the concepts in the NXDL file.</p>"},{"location":"how-tos/use-multi-format-reader.html#reading-in-the-instruments-data-and-metadata","title":"Reading in the instrument's data and metadata","text":"<p>First, we will have a look at the HDF5 file. This mock HDF5 file was generated with <code>h5py</code> using a simple script.</p> <p></p> <p>Here, we see that we have a <code>data</code> group with x and y values, as well as some additional metadata for the instrument.</p> <p>Here is one way to implement the method to read in the data: reader.py<pre><code>import h5py\n\ndef handle_hdf5_file(filepath):\n    def recursively_read_group(group, path=\"\"):\n        result = {}\n        for key, item in group.items():\n            new_path = f\"{path}/{key}\" if path else key\n            if isinstance(item, h5py.Group):\n                # Recursively read subgroups\n                result.update(recursively_read_group(item, new_path))\n            elif isinstance(item, h5py.Dataset):\n                # Read datasets\n                result[new_path] = item[()]\n        return result\n\n    # Open the HDF5 file and read its contents\n    with h5py.File(filepath, \"r\") as hdf:\n        self.hdf5_data = recursively_read_group(hdf)\n\n    return {}\n</code></pre> Note that here we are returning an empty dictionary because we don't want to fill the template just yet, but only read in the HDF5 data for now. We will use the config file later to fill the template with the read-in data. Note that it is also possible to return a dictionary here to update the template directly.</p> <p><code>self.hdf5_data</code> will look like this: <pre><code>{\n    \"data/x_values\": array([-10.        ,  -9.7979798 ,  -9.5959596 , ...,  10.        ]),\n    \"data/y_values\": array([3.72665317e-06, 6.14389891e-06, 1.00262383e-05, ..., 3.72665317e-06]),\n    \"data/x_units\": \"eV\",\n    \"data/y_units\": \"counts_per_second\",\n    \"metadata/instrument/version\": 1.0,\n    \"metadata/instrument/detector/name\": \"my_gaussian_detector\",\n    \"metadata/instrument/detector/count_time\": 1.2,\n    \"metadata/instrument/detector/count_time_units\": s\",\n}\n</code></pre></p>"},{"location":"how-tos/use-multi-format-reader.html#reading-in-eln-data","title":"Reading in ELN data","text":"<p>As we can see in the application definition <code>NXsimple</code> above, there are some concepts defined for which there is no equivalent metadata in the HDF5 file. We are therefore using a YAML ELN file to add additional metadata. The ELN file <code>eln_data.yaml</code> looks like this: eln_data.yaml<pre><code>title: My experiment\nuser:\n  name: John Doe\n  address: 123 Science Rd, Data City, DC\nsample:\n  name: my_sample\n  physical_form: powder\n  temperature:\n    value: 300\n    unit: K\n</code></pre></p> <p>It contains metadata about the user and the sample that was measured.</p> <p>We now need to write a function to read in this ELN data. Luckily, there exists already a solution within <code>pynxtools</code>, using the <code>parse_yaml</code> function:</p> <p>reader.py<pre><code>from pynxtools.dataconverter.readers.utils import parse_yml\n\nCONVERT_DICT = {\n    \"unit\": \"@units\",\n    \"version\": \"@version\",\n    \"user\": \"USER[user]\",\n    \"instrument\": \"INSTRUMENT[instrument]\",\n    \"detector\": \"DETECTOR[detector]\",\n    \"sample\": \"SAMPLE[sample]\",\n}\n\ndef handle_eln_file(self, file_path: str) -&gt; Dict[str, Any]:\n    self.eln_data = parse_yml(\n        file_path,\n        convert_dict=CONVERT_DICT,\n        parent_key=\"/ENTRY[entry]\",\n    )\n\n    return {}\n</code></pre> When this method is called, <code>self.eln_data</code> will look like this: <pre><code>{\n    \"/ENTRY[entry]/title\": \"My experiment\",\n    \"/ENTRY[entry]/USER[user]/name\": \"John Doe\",\n    \"/ENTRY[entry]/USER[user]/address\": \"123 Science Rd, Data City, DC\",\n    \"/ENTRY[entry]/SAMPLE[sample]/name\": \"my_sample\",\n    \"/ENTRY[entry]/SAMPLE[sample]/physical_form\": \"powder\",\n    \"/ENTRY[entry]/SAMPLE[sample]/temperature\": 300,\n    \"/ENTRY[entry]/SAMPLE[sample]/temperature/@units\": \"K\"\n}\n</code></pre> Note that here we are using <code>parent_key=\"/ENTRY[entry]\"</code> as well as a <code>CONVERT_DICT</code>, meaning that each key in <code>self.eln_data</code> will start with <code>\"/ENTRY[entry]\"</code> and some of the paths will be converted to match the template notation. This will be important later.</p>"},{"location":"how-tos/use-multi-format-reader.html#parsing-the-config-file","title":"Parsing the config file","text":"<p>Next up, we can make use of the config file, which is a JSON file that tells the reader how to map the concepts from the HDF5 and ELN files in order to populate the template designed to match <code>NXsimple</code>. The choices made in the config file define how semantics from the source (data file) and target (NeXus application definition) side are mapped. Essentially, the config file should contain all keys that are present in the NXDL. In our case, the config file looks like this:</p> <p>config_file.json<pre><code>{\n  \"/ENTRY/title\": \"@eln\", \n  \"/ENTRY/USER[user]\": {\n    \"name\":\"@eln\",\n    \"address\":@eln:\"/ENTRY/USER[user]/address\",\n  }, \n  \"/ENTRY/INSTRUMENT[instrument]\": {\n    \"@version\":\"@attrs:metadata/instrument/version\",\n    \"DETECTOR[detector]\":{\n      \"count_time\":\"@attrs:metadata/instrument/detector/count_time\",\n      \"count_time/@units\":\"@attrs:metadata/instrument/detector/count_time_units\"\n    }\n  },\n  \"/ENTRY/SAMPLE[sample]\": {\n    \"name\":\"@eln\",\n    \"physical_form\":\"@eln\",\n    \"temperature\":\"@eln\",\n    \"temperature/@units\":\"@eln\"\n  },\n  \"/ENTRY/data\": {\n    \"@axes\":[\"x_values\"],\n    \"@signal\": \"data\",\n    \"data\": \"@data:y_values\",\n    \"data/@units\": \"@attrs:data/y_units\",   \n    \"x_values/@units\": \"@attrs:data/x_units\",\n    \"x_values/@units\": \"@data:x_values\"\n  }\n}\n</code></pre> Note that here we are using <code>@</code>-prefixes which are used to fill the template from the different data sources. We dicuss this below in more detail.</p> <p>We also implement a method for setting the config file in the reader: reader.py<pre><code>def set_config_file(self, file_path: str) -&gt; Dict[str, Any]:\n    if self.config_file is not None:\n        logger.info(\n            f\"Config file already set. Replaced by the new file {file_path}.\"\n        )\n    self.config_file = file_path\n\n    return {}\n</code></pre></p>"},{"location":"how-tos/use-multi-format-reader.html#filling-the-template-from-the-read-in-data","title":"Filling the template from the read-in data","text":"<p>Finally, after reading in all of the data and metadata as well as designing the config file, we can start filling the template. For this, we must implement functions that are called using the reader's callbacks.</p> <p>We will start with the <code>@attrs</code> prefix, associated with the <code>attrs_callback</code>. We must implement the <code>get_attr</code> method: reader.py<pre><code>def get_attr(self, key: str, path: str) -&gt; Any:\n    \"\"\"\n    Get the metadata that was stored in the main file.\n    \"\"\"\n    if self.hdf5_data is None:\n        return None\n\n    return self.hdf5_data.get(path)\n</code></pre> This method (and all similar callbacks methods) have two inputs: 1. <code>key</code>, which is a key in the config file. Note that here, the generic <code>\"/ENTRY/\"</code> gets replaced by <code>f\"/ENTRY[{entry_name}]/\"</code>, where <code>entry_name</code> is the one of the entries of the <code>self.get_entry_names</code> method. 2. <code>path</code>, which is the part of the config value that comes after the <code>@attrs:</code> prefix. For example, for the config value <code>\"@attrs:my-metadata\"</code>, the extracted path is <code>my-metadata</code>.</p> <p>For the <code>get_attr</code> method, we are making use of the <code>path</code>. For example, for the config value <code>\"@attrs:metadata/instrument/version\"</code>, the extracted path is <code>metadata/instrument/version</code>, which is also one of the keys of the <code>self.hdf5_data</code> dictionary.</p> <p>For the ELN data, we must implement the <code>get_eln_data</code> function that gets called from the <code>eln_callback</code> when using the <code>@eln</code> prefix: reader.py<pre><code>def get_eln_data(self, key: str, path: str) -&gt; Any:\n        \"\"\"Returns data from the given eln path.\"\"\"\n        if self.eln_data is None:\n            return None\n\n        return self.eln_data.get(key)\n</code></pre> Here, we are making use of the fact that we have used <code>CONVERT_DICT</code> in the <code>parse_yml</code> function above. Thus, the keys of the <code>self.eln_data</code> dictionary are exactly the same as those in the config file (for example, the config key <code>\"/ENTRY[entry]/USER[user]/address\"</code> also exists in <code>self.eln_data</code>). Therefore, we can just get this data using the <code>key</code> coming from the config file. </p> <p>Finally, we also need to address the <code>@data</code> prefix, which gets used in the <code>data_callback</code> to populate the NXdata group in the template. Note that here we use the same <code>@data</code> prefix to fill the <code>x_values</code> as well as the <code>data</code> (from <code>y_values</code>) fields. We achieve this by using the path that follows <code>@data:</code> in the config file: reader.py<pre><code>def get_data(self, key: str, path: str) -&gt; Any:\n    \"\"\"Returns measurement data from the given hdf5 path.\"\"\"\n    if path.endswith((\"x_values\", \"y_values\")):\n        return self.hdf5_data.get(f\"data/{path}\")\n    else:\n        logger.warning(f\"No axis name corresponding to the path {path}.\")\n</code></pre></p>"},{"location":"how-tos/use-multi-format-reader.html#bringing-it-all-together","title":"Bringing it all together","text":"<p>Et voil\u00e0! That's all we need to read in our data and populate the <code>NXsimple</code> template. Our final reader looks like this:</p> reader.py<pre><code>import logging\nfrom typing import Dict, Any\nimport h5py\n\nfrom pynxtools.dataconverter.readers.multi.reader import MultiFormatReader\nfrom pynxtools.dataconverter.readers.utils import parse_yml\n\nlogger = logging.getLogger(\"pynxtools\")\n\nCONVERT_DICT = {\n    \"unit\": \"@units\",\n    \"version\": \"@version\",\n    \"user\": \"USER[user]\",\n    \"instrument\": \"INSTRUMENT[instrument]\",\n    \"detector\": \"DETECTOR[detector]\",\n    \"sample\": \"SAMPLE[sample]\",\n}\n\n\nclass MyDataReader(MultiFormatReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    supported_nxdls = [\n        \"NXsimple\"\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.extensions = {\n            \".yml\": self.handle_eln_file,\n            \".yaml\": self.handle_eln_file,\n           \".json\": self.set_config_file,\n            \".hdf5\": self.handle_hdf5_file,\n            \".h5\": self.handle_hdf5_file,\n        }\n\n    def set_config_file(self, file_path: str) -&gt; Dict[str, Any]:\n        if self.config_file is not None:\n            logger.info(\n                f\"Config file already set. Replaced by the new file {file_path}.\"\n            )\n        self.config_file = file_path\n        return {}\n\n    def handle_hdf5_file(self, filepath) -&gt; Dict[str, Any]:\n        def recursively_read_group(group, path=\"\"):\n            result = {}\n            for key, item in group.items():\n                new_path = f\"{path}/{key}\" if path else key\n                if isinstance(item, h5py.Group):\n                    # Recursively read subgroups\n                    result.update(recursively_read_group(item, new_path))\n                elif isinstance(item, h5py.Dataset):\n                    # Read datasets\n                    result[new_path] = item[()]\n            return result\n\n        # Open the HDF5 file and read its contents\n        with h5py.File(filepath, \"r\") as hdf:\n            self.hdf5_data = recursively_read_group(hdf)\n\n        return {}\n\n    def handle_eln_file(self, file_path: str) -&gt; Dict[str, Any]:\n        self.eln_data = parse_yml(\n            file_path,\n            convert_dict=CONVERT_DICT,\n            parent_key=\"/ENTRY[entry]\",\n        )\n\n        return {}\n\n    def get_attr(self, key: str, path: str) -&gt; Any:\n        \"\"\"\n        Get the metadata that was stored in the main file.\n        \"\"\"\n        if self.hdf5_data is None:\n            return None\n\n        return self.hdf5_data.get(path)\n\n    def get_eln_data(self, key: str, path: str) -&gt; Any:\n        \"\"\"Returns data from the given eln path.\"\"\"\n        if self.eln_data is None:\n            return None\n\n        return self.eln_data.get(key)\n\n    def get_data(self, key: str, path: str) -&gt; Any:\n        \"\"\"Returns measurement data from the given hdf5 path.\"\"\"\n        if path.endswith((\"x_values\", \"y_values\")):\n            return self.hdf5_data.get(f\"data/{path}\")\n        else:\n            logger.warning(f\"No axis name corresponding to the path {path}.\")  \n\nREADER = MyDataReader\n</code></pre>"},{"location":"how-tos/use-multi-format-reader.html#using-the-reader","title":"Using the reader","text":"<p>We can call our reader using the following command</p> <pre><code>user@box:~$ dataconverter mock_data.h5 eln_data.yaml -c config_file --reader mydatareader --nxdl NXsimple  --output output.nxs\n</code></pre> <p>The final <code>output.nxs</code> file gets automatically validated against <code>NXsimple</code>, so we can be sure that it is compliant with that application definition. Here is a look at our final NeXus file:</p> <p></p>"},{"location":"how-tos/using-multiple-appdefs.html","title":"Storing data following multiple appdefs","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p>"},{"location":"how-tos/using-pynxtools-test-framework.html","title":"Generalized Test Functionality for <code>pynxtools</code> plugins","text":"<p>The <code>pynxtools</code> sub-package <code>testing</code> is to be utilized to write automated tests for pynxtools reader plugins without requiring in-depth knowledge of the pynxtools internal architecture. The tool supports generalised a general test for all reader plugins, irrespective of the technical details of the raw data files and the internal design of the plugin (note: it is assumed that the plugin was built from the plugin template or has the same structure internally).</p>"},{"location":"how-tos/using-pynxtools-test-framework.html#why-it-is-needed","title":"Why it is needed","text":"<p>To test integration of a plugin with the <code>pynxtools</code> core system, we need to: 1. Test the plugin's integration with <code>pynxtools</code> from the plugin's CI/CD. 2. Test in the pynxtools's CI/CD if the plugin has been integrated with <code>pynxtools</code> properly.</p>"},{"location":"how-tos/using-pynxtools-test-framework.html#how-to-write-an-integration-test-for-a-reader-plugin-with-pynxtoolstesting","title":"How to write an integration test for a reader plugin with <code>pynxtools.testing</code>","text":"<p>It is very simple to write a test to verify the plugin integration with <code>pynxtools</code> within the plugin's tests directory. The developer can place the test where they want, but they need to use the provided test interface from <code>pynxtools</code>. An example test for <code>pynxtools-FOO</code> (a demo plugin) plugin is given below:</p> test_plugin.py<pre><code>import os\n\nimport pytest\nfrom pynxtools.testing.nexus_conversion import ReaderTest\n\n# e.g. module_dir = /pynxtools-foo/tests\nmodule_dir = os.path.dirname(os.path.abspath(__file__))\n\n\n@pytest.mark.parametrize(\n    \"nxdl,reader_name,files_or_dir\",\n    [\n        (\"NXfoo\", \"foo\", f\"{module_dir}/../tests/data/test_data_dir_1\"),\n        (\"NXfoo\", \"foo\", f\"{module_dir}/../tests/data/test_data_dir_2\")\n    ],\n)\ndef test_foo_reader(nxdl, reader_name, files_or_dir, tmp_path, caplog):\n    \"\"\"Test for the FooReader or foo reader plugin.\n\n    Parameters\n    ----------\n    nxdl : str\n        Name of the NXDL application definition that is to be tested by\n        this reader plugin (e.g. NXfoo), without the file ending .nxdl.xml.\n    reader_name : str\n        Name of the class of the reader (e.g. \"foo\")\n    files_or_dir : class\n        Name of the class of the reader.\n    tmp_path : pytest.fixture\n        Pytest fixture variable, used to create temporary file and clean up the generated files\n        after test.\n    caplog : pytest.fixture\n        Pytest fixture variable, used to capture the log messages during the test.\n    \"\"\"\n    # test plugin reader\n    test = ReaderTest(nxdl, reader_name, files_or_dir, tmp_path, caplog)\n    test.convert_to_nexus()\n    # test.convert_to_nexus(caplog_level=\"ERROR\", ignore_undocumented=True)\n    # Use `ignore_undocumented` to skip undocumented fields\n    # caplog_level can be \"ERROR\" or \"WARNING\"\n    test.check_reproducibility_of_nexus()\n    # Here, you can also pass `ignore_lines` (a list) or `ignore_sections` (a dict)\n    # if you want to ignore certain lines or lines within a section in the comparison\n    # of the log files of the reference -nxs file and the one created in the test.\n</code></pre> <p>Alongside the test data in <code>test/data</code>, it is also possible to add other types of test data inside the test directory of the plugin.</p> <p>You can also pass additional parameters to <code>test.convert_to_nexus</code>:</p> <ul> <li> <p><code>caplog_level</code> (str): Can be either \"ERROR\" (by default) or \"warning\". This parameter determines the level at which the caplog is set during testing. If it is \"WARNING\", the test will also fail if any warnings are reported by the reader.</p> </li> <li> <p><code>ignore_undocumented</code> (boolean): If true, the test skipts the verification of undocumented keys. Otherwise, a warning massages for undocumented keys is raised</p> </li> </ul>"},{"location":"how-tos/using-pynxtools-test-framework.html#how-to-write-an-integration-test-for-a-nomad-example-in-a-reader-plugin","title":"How to write an integration test for a NOMAD example in a reader plugin","text":"<p>It is also possible to ship examples for NOMAD directly with the reader plugin. As an example, <code>pynxtools-mpes</code> comes with its own NOMAD example (see here) using the ExampleUploadEntryPoint of NOMAD (see here for more documentation).</p> <p>The <code>testing</code> sub-package of <code>pynxtools</code> provides two functionalities for testing the <code>ExampleUploadEntryPoint</code> defined in a <code>pynxtools</code> plugin: 1) Test that the ExampleUploadEntryPoint can be properly loaded 2) Test that the schemas and files in the example folder(s) can be parsed by NOMAD</p> <p>We will write a test for a <code>pynxtools_foo_example_entrypoint</code> defined in the pyproject.toml file of a demo <code>pynxtools-FOO</code> (here the actual example data resides in the folder <code>src/pynxtools_foo/nomad/examples</code>):</p> pyproject.toml<pre><code>[project.entry-points.'nomad.plugin']\npynxtools_foo_example = \"pynxtools_foo.nomad.entrypoints:pynxtools_foo_example_entrypoint\"\n</code></pre> <p>src/pynxtools_foo/nomad/nomad_example_entrypoint.py<pre><code>from nomad.config.models.plugins import ExampleUploadEntryPoint\n\npynxtools_foo_example_entrypoint = ExampleUploadEntryPoint(\n    title=\"My example upload\",\n    description=\"\"\"\n        This is an example upload for the pynxtools-FOO package.\n    \"\"\",\n    plugin_package=\"pynxtools_foo\",\n    resources=[\"nomad/examples/*\"],\n)\n</code></pre> A test for the <code>pynxtools_foo_example_entrypoint</code> could look like this: test_nomad_examples.py<pre><code>import nomad\n\nfrom pynxtools.testing.nomad_example import (\n    get_file_parameter,\n    parse_nomad_examples,\n    example_upload_entry_point_valid,\n)\n\nfrom pynxtools_foo.nomad.entrypoints import pynxtools_foo_example_entrypoint\n\n\nEXAMPLE_PATH = os.path.join(\n    os.path.dirname(__file__),\n    \"..\",\n    \"src\",\n    \"pynxtools_foo\",\n    \"nomad\",\n    \"examples\",\n)\n\n\n@pytest.mark.parametrize(\n    \"mainfile\",\n    get_file_parameter(EXAMPLE_PATH),\n)\ndef test_parse_nomad_examples(mainfile):\n    \"\"\"Test if NOMAD examples work.\"\"\"\n    archive_dict = parse_nomad_examples(mainfile)\n    # Here, you can also implement more logic if you know the contents of the archive_dict\n\n\n@pytest.mark.parametrize(\n    (\"entrypoint\", \"example_path\"),\n    [\n        pytest.param(\n            pynxtools_foo_example_entrypoint,\n            EXAMPLE_PATH,\n            id=\"pynxtools_foo_example\",\n        ),\n    ],\n)\ndef test_example_upload_entry_point_valid(entrypoint, example_path):\n    \"\"\"Test if NOMAD ExampleUploadEntryPoint works.\"\"\"\n    example_upload_entry_point_valid(\n        entrypoint=entrypoint,\n        example_path=example_path,\n    )\n</code></pre></p>"},{"location":"how-tos/validate-nexus-file.html","title":"Validating NeXus files","text":"<p>Note: This is a how-to guide for using different tools to validate NeXus files. If you want to learn more about how validation is done in <code>pynxtools</code>, please visit the explanation page.</p> <p>The goal</p> <p>Use a tool to validate NeXus files to a given set of NeXus definitions:</p> <ol> <li> <p>FAIRmat</p> </li> <li> <p>NIAC</p> </li> </ol>"},{"location":"how-tos/validate-nexus-file.html#validation-of-a-nxs-file","title":"Validation of a .nxs file","text":"<p>The validity of NeXus files is fundamental to ensure FAIR data. Without specific requirements, it is not possible to understand the data. What type of experiment? What Laser Wavelength? Which voltage? What data is represented at all in the table? What is the unit of the value? Which ISO norm does this refer to? Where was this measured? Which year was this measured?</p> <p>The NeXus application definitions define the minimum set of terms that must be used in an instance of that class (i.e., the required terms that you must add to the file in order to be compliant with that application definition). Application definitions also may define terms that are optional in the NeXus data file. The requirements are set by the community via workshops or at conferences. To initiate or propose changes/additions, you can comment the FAIRMat NeXus proposal by going to the NeXus definitions, and using the hypothes.is tool (sign-up/log-in) to give us some feedback (Red boxes in the image. Expand this panel on the left by clicking on the arrow symbol). </p> <p>Oftentimes, there will be errors in a generated NeXus file (be it by hand or automatically): Typos, missing required concepts, missing attributes, using the incorrect datatype or format (e.g., array instad of list, float instead of integer, etc.). Therefore, a validation is required, to ensure that the data you want to share is FAIR.</p> <p>The NeXus file is valid if it complies with the respective NeXus application definition.</p> <p>This validation is done by software.</p>"},{"location":"how-tos/validate-nexus-file.html#validation-software","title":"Validation software","text":"<p>There are right now three tools, which can be used for validation of NeXus files. All are different and have individual advantages or disadvantages:</p> <ol> <li> <p>pynxtools </p> </li> <li> <p>cnxvalidate</p> </li> <li> <p>punx</p> </li> </ol> <p>Open software is usually shared on Github - There you find usually the most accurate information, as documentation sometimes lags behind. There you see a box with folders and files. Below is the content of the README.md file displayed. This usually shows instructions for installation and handling of the software.</p> <p>Here are the GitHub links for the three software packages:</p> <p>pynxtools</p> <p>cnxvalidate</p> <p>punx</p> <p>In the following, each package and its capabilities is presented.</p>"},{"location":"how-tos/validate-nexus-file.html#operating-systems","title":"Operating systems","text":"<p>Almost all PC users are used to Windows as operating system.</p> <p>A lot of software development is done on Linux as operating system.</p> <p>This is not a problem for big companies, but for smaller open software projects, which are often developed without funding, this is a problem.</p> <p>If you are used to Windows, consider setting up a Linux operating system to eliminate problems in the installation process and ensure compatibility.</p>"},{"location":"how-tos/validate-nexus-file.html#pynxtools","title":"pynxtools","text":"<p>pynxtools = Python Nexus Tools</p> <p>&gt; learn more about validation in pynxtools &lt;</p> <p>This is a python package which is developed by the FAIRmat consortium.</p> <p>As a python package, this can be used on Linux and Windows systems.</p> <p>The package can be installed via pip. Therefore you need to have installed:</p> <ol> <li> <p>python</p> </li> <li> <p>pip</p> </li> </ol> <p>For validation purposes, we will use the \"read_nexus\" and \"verify_nexus\" command line tools from <code>pynxtools</code>.</p>"},{"location":"how-tos/validate-nexus-file.html#pynxtools-verify_nexus","title":"pynxtools - verify_nexus","text":"<p>This tool is currently in development. It enables a command like:</p> <pre><code>verify_nexus C:\\nexusvalidation\\Raman.nxs\n</code></pre> <p>The output warning looks like this: <pre><code>...\nWARNING: Field /entry/instrument/beam_incident/wavelength/@units written without documentation.\n...\n</code></pre></p>"},{"location":"how-tos/validate-nexus-file.html#installation-of-verify_nexus","title":"Installation of verify_nexus","text":"<p>The <code>verify_nexus</code> function is currently under development (Aug 2024). Therefore, you have to install pynxtools from its feature branch until this function is published. Do this to install pynxtools with verify_nexus via;</p> <pre><code>pip install git+https://github.com/FAIRmat-NFDI/pynxtools@hdf-based-validation\n</code></pre> <p>Then, you should be able to call its help function:</p> <pre><code>verify_nexus --help\n</code></pre> <p>with this output:</p> <pre><code>Usage: verify_nexus [OPTIONS] FILE\n\n  Verifies a nexus file\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <p>Development version installation</p> <p>If this installation procedure above does not work, you can use the development installation by using git: <pre><code>python -m venv .py39\nsource .py39/bin/activate\ngit clone https://github.com/FAIRmat-NFDI/pynxtools.git\ncd pynxtools/\ngit checkout hdf-based-validation\ngit submodule sync \u2013recursive\ngit submodule update --init --recursive --jobs=4\npython -m pip install --upgrade pip\npython -m pip install -e .\npython -m pip install -e \".[dev]\u201c\nverify_nexus --help\n</code></pre></p>"},{"location":"how-tos/validate-nexus-file.html#using-verify_nexus","title":"Using verify_nexus","text":"<p>Open your terminal. Assuming there is a folder at:</p> <p>For Linux:</p> <pre><code>/home/USER/nexusvalidation\n</code></pre> <p>For Windows:</p> <pre><code>C:\\nexusvalidation\n</code></pre> <p>Put into this folder your NeXus file, for example this Raman.nxs file.</p> <p>Use verify_nexus with the command:</p> <pre><code>verify_nexus C:\\nexusvalidation\\Raman.nxs\n</code></pre> <p>The respective output is:</p> <pre><code>WARNING: Field /entry/data/spectrum_data_x/@units written without documentation.\nWARNING: Field /entry/data/spectrum_data_x_Raman/@units written without documentation.\nWARNING: Field /entry/data/spectrum_data_y/@units written without documentation.\nWARNING: Field /entry/instrument/beam_incident/wavelength/@units written without documentation.\nWARNING: Field /entry/instrument/detector_DU970BV/number_of_cycles/@units written without documentation.\nInvalid: The entry `entry` in file `Raman.nxs` is NOT a valid file according to the `NXraman` application definition.\n</code></pre>"},{"location":"how-tos/validate-nexus-file.html#pynxtools-read_nexus","title":"pynxtools - read_nexus","text":"<p>While <code>verify_nexus\u00b4 is used as a straightforward tool for validating a NeXus file,</code>read_nexus` outputs a debug log for a given NeXus file by annotating the data and metadata entries with the schema definitions from the respective NeXus base classes and application definitions to which the file refers to. This can be helpful to extract documentation and understand the concept defined in the NeXus application definition. The command used is:</p> <pre><code>read_nexus -f NXopt_minimal_example.nxs\n</code></pre> <p>The output looks like this, if the respective entry is found:</p> <pre><code>DEBUG: ===== FIELD (//entry/experiment_type): &lt;HDF5 dataset \"experiment_type\": shape (), type \"|O\"&gt;\nDEBUG: value: b'transmission spectroscopy' \nDEBUG: classpath: ['NXentry', 'NX_CHAR']\nDEBUG: classes:\nNXoptical_spectroscopy.nxdl.xml:/ENTRY/experiment_type\nDEBUG: &lt;&lt;REQUIRED&gt;&gt;\nDEBUG: enumeration (NXoptical_spectroscopy.nxdl.xml:/ENTRY/experiment_type):\nDEBUG: -&gt; photoluminescence\nDEBUG: -&gt; transmission spectroscopy\nDEBUG: -&gt; reflection spectroscopy\nDEBUG: -&gt; other\nDEBUG: documentation (NXoptical_spectroscopy.nxdl.xml:/ENTRY/experiment_type):\nDEBUG: \n                 Specify the type of the optical experiment.\n\n                 Chose other if none of these methods are suitable. You may specify\n                 fundamental characteristics or properties in the experimental sub-type.\n\n                 For Raman spectroscopy or ellipsometry use the respective specializations\n                 of NXoptical_spectroscopy.\n</code></pre> <p>or like this, if the respective entry is not found in the defintion:</p> <pre><code>DEBUG: ===== ATTRS (//entry/instrument/software_RC2/program@url)\nDEBUG: value: https://www.jawoollam.com/ellipsometry-software/completeease \nDEBUG: classpath: ['NXentry', 'NXinstrument']\nDEBUG: NOT IN SCHEMA\nDEBUG:\n</code></pre> <p>The first example was for for \"experiment_type\" entry in the \"NXoptical_spectroscopy\" definition.</p> <p>The second example was for the \"software_TYPE\" attribute @URL entry in the \"NXoptical_spectroscopy\" definition. Here the problem was that \"url\" was used instead of \"URL\".</p>"},{"location":"how-tos/validate-nexus-file.html#installation-of-read_nexus","title":"Installation of read_nexus","text":"<p>This is installed with pip:</p> <pre><code>pip install pynxtools\n</code></pre>"},{"location":"how-tos/validate-nexus-file.html#using-read_nexus","title":"Using read_nexus","text":"<p>Open your terminal. Assuming there is a folder at:</p> <p>For Linux:</p> <pre><code>/home/USER/nexusvalidation\n</code></pre> <p>For Windows:</p> <pre><code>C:\\nexusvalidation\n</code></pre> <p>Put into this folder your NeXus file, for example the Raman.nxs file.</p> <p>Then use:</p> <pre><code>read_nexus -f C:\\nexusvalidation\\Raman.nxs\n</code></pre> <p>shows the output like this:</p> <pre><code>===== FIELD (//entry/data/spectrum_data_y): &lt;HDF5 dataset \"spectrum_data_y\": shape (1600,), type \"&lt;f8\"&gt;\nDEBUG: ===== FIELD (//entry/data/spectrum_data_y): &lt;HDF5 dataset \"spectrum_data_y\": shape (1600,), type \"&lt;f8\"&gt;\nvalue: [ 288.5499878  289.         288.4500122 ... 1875.        1889.349976 ...\nDEBUG: value: [ 288.5499878  289.         288.4500122 ... 1875.        1889.349976 ...\nDataset referenced as NXdata SIGNAL\nDEBUG: Dataset referenced as NXdata SIGNAL\n===== ATTRS (//entry/data/spectrum_data_y@long_name)\nDEBUG: ===== ATTRS (//entry/data/spectrum_data_y@long_name)\nvalue: Raman Intensity \nDEBUG: value: Raman Intensity \nDataset referenced as NXdata SIGNAL\nDEBUG: Dataset referenced as NXdata SIGNAL\n===== ATTRS (//entry/data/spectrum_data_y@units)\nDEBUG: ===== ATTRS (//entry/data/spectrum_data_y@units)\nvalue: counts \nDEBUG: value: counts \n\nDEBUG: \nFor Axis #0, 1 axes have been identified: [&lt;HDF5 dataset \"spectrum_data_x_Raman\": shape (1600,), type \"&lt;f8\"&gt;]\nDEBUG: For Axis #0, 1 axes have been identified: [&lt;HDF5 dataset \"spectrum_data_x_Raman\": shape (1600,), type \"&lt;f8\"&gt;]\n</code></pre> <p>Search for fields which are not found in the NeXus definition by searching for the line: \"DEBUG: NOT IN SCHEMA\". Recheck the used NeXus definition to eliminate the problem. Be careful with upper and lower case notation and correct spelling.</p> <p>Keep in mind that the output provides quite some information. This is useful for software development, but may be a bit too much for validation purposes.</p>"},{"location":"how-tos/validate-nexus-file.html#cnxvalidate","title":"cnxvalidate","text":"<p>This package is written in C. It is allows a command line evocation like:</p> <pre><code>nxvalidate -l appdefdir datafile\n</code></pre> <ol> <li> <p>nxvalidate: calls the software function</p> </li> <li> <p>-l appdefdir: points to the location of the NeXus definitions you want to use. This is a path to a folder called \"defintions\".</p> </li> <li> <p>datafile: This is the path to the .nxs file which should be checked.</p> </li> </ol> <p>This output shows warnings like:</p> <pre><code>definition=NXoptical_spectroscopy.nxdl.xml message=\"Required attribute URL missing\" nxdlPath=/NXentry/definition sev=error dataPath=/entry/definition dataFile=NXopt_minimal_example.nxs\n</code></pre> <p>and indicates the entry of the .nxs file, which is incorrect and what the respective problem is. It also points to the NeXus definition (.nxdl.xml file), in which this conflict was found.</p>"},{"location":"how-tos/validate-nexus-file.html#installation","title":"Installation","text":"<p>Note: You can find more information about installing nxvalidate here. Note that installation on Windows can be tricky because cmake can sometimes not find the libxml2 library. Though, if you solve this, this maybe work on windows).</p> <p>Therefore: Use linux.</p> <p>The software has to be built from source. This is eased significantly by using another software called: cmake.</p> <p>Install cmake, github, hdf5 &amp; xml2 library, etc:</p> <p>Open the terminal and install all parts required to install cnxvalidate via cmake:</p> <pre><code>sudo apt-get update\nsudo apt-get install git\nsudo apt-get install build-essential\nsudo add-apt-repository universe\nsudo apt-get install libhdf5-serial-dev\nsudo apt-get -y install pkg-config     \nsudo apt upgrade -y\nsudo apt-get -y install cmake\nsudo apt-get install libxml2-dev\n</code></pre> <p>Directory location</p> <p>Create a folder named \"nexusvalidation\" via terminal or file manager.</p> <p>The folder is located at <code>/home/USER/nexusvalidation</code></p> <p>\"USER\" is your user name. (You can get your username by the terminal command: <code>echo $USER</code>)</p> <p>In the terminal, this is indicated by <code>~/nexusvalidation</code> ( \\~ = /home/USER)</p> <p>Open the thermal and go into this directory by:</p> <pre><code>cd /home/USER/nexusvalidation\n</code></pre> <p>Using GitHub</p> <p>Go to the Github Repository of cnxvalidate:</p> <p>Click on the green \"&lt;&gt; Code\" button.</p> <p>Click on \"HTTPS\".</p> <p>Copy the https link.</p> <p></p> <p>Open the terminal and ensure you are in the <code>nexusvalidation</code> folder.</p> <p>Clone the github repository (= download the files of the software).</p> <pre><code>git clone https://github.com/nexusformat/cnxvalidate.git\n</code></pre> <p>now you have a new folder at <code>~/nexusvalidation/cnxvalidate</code></p> <p>go into this folder via the command</p> <pre><code>cd cnxvalidate\n</code></pre> <p>now you are in the source tree. This should be exactly the same files, which you find on the github repository github repository</p> <p>make a new directory called \"build\":</p> <pre><code>mkdir build\n</code></pre> <p>go into this directory</p> <pre><code>cd build\n</code></pre> <p>use cmake, to compile/build the software - this puts together all pieces of software - and especially external parts such as xml2 and hdf5 library.</p> <pre><code>cmake ../\n</code></pre> <p>install cnxvalidate after it was sucessfully build</p> <pre><code>make\n</code></pre> <p>Now the above mentioned commands should be avaialble. The programm/executable is located at:</p> <pre><code>/home/USER/nexusvalidation/cnxvalidate/build/nxvalidate\n</code></pre>"},{"location":"how-tos/validate-nexus-file.html#using-cnxvalidate","title":"Using cnxvalidate","text":"<p>Now you can start to validate your created NeXus file. But before the validation, we need to get a set of NeXus definitions, which we want to use as reference. This is done again by using git:</p> <p>Getting NeXus definitions</p> <p>go to the folder nexusvalidation</p> <pre><code>cd /home/USER/nexusvalidation\n</code></pre> <p>Download a set of NeXus definitions. Choose only one:</p> <p>For FAIRmat NeXus definitions, go to this link and copy the github \"Code\" line to clone the repository. Then:</p> <pre><code>git clone https://github.com/FAIRmat-NFDI/nexus_definitions.git\n</code></pre> <p>For the NIAC NeXus definitions, go to this link and copy the github \"Code\" line to clone the repository. Then:</p> <pre><code>git clone https://github.com/nexusformat/definitions.git\n</code></pre> <p>Now you have a folder called \"definitions\" in the \"nexusvalidation\" folder. The path to this definitions folder is used as option for cnxvalidate, to tell the program which NeXus definitions shall be used.</p> <p>The respective path would be:</p> <pre><code>/home/USER/nexusvalidation/definitions\n</code></pre> <p>Get your NeXus file</p> <p>put one of created NeXus file (or this this file) into the \"nexusvalidation\" folder (filemanager/explorer).</p> <p>The file should now be loacted at (assumed the file name is \"NXopt_minimal_example.nxs\")</p> <pre><code>/home/USER/nexusvalidation/NXopt_minimal_example.nxs\n</code></pre> <p>Validating the NeXus file</p> <p>now you can use the cnxvalidate with the executable called \"nxvalidate\" to use the set of NeXus definitions called \"appdefdir\" to validate the NeXus file called \"datafile\". This is done from the terminal.</p> <pre><code>nxvalidate -l appdefdir datafile\n</code></pre> <p>All names are \"paths\" to the definition, application or file. Use the \"full path\", if you are not experienced, but relative paths work as well.</p> <p>For the provided example, the suitable command looks like:</p> <pre><code>/home/USER/nexusvalidation/cnxvalidate/build/nxvalidate -l /home/USER/nexusvalidation/definitions /home/USER/nexusvalidation/NXopt_minimal_example.nxs\n</code></pre> <p>The \"-l\" option tells the program, that it should look for the nexus definiton at the path after \"-l\".</p> <p>For the proved file above, the output should look like this:</p> <pre><code>USER@XXX:/home/USER/nexusvalidation/cnxvalidate/build/nxvalidate -l /home/USER/nexusvalidation/definitions /home/USER/nexusvalidation/NXopt_minimal_example.nxs\ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required attribute version missing\" nxdlPath=/NXentry/definition sev=error dataPath=/entry/definition dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required attribute URL missing\" nxdlPath=/NXentry/definition sev=error dataPath=/entry/definition dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required field missing\" nxdlPath=/NXentry/experiment_type sev=error dataPath=/entry/experiment_type dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXinstrument sev=error dataPath=/entry dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXsample sev=error dataPath=/entry dataFile=NXopt_minimal_example.nxs \ndefinition=NXoptical_spectroscopy.nxdl.xml message=\"Required group missing\" nxdlPath=/NXentry/NXdata sev=error dataPath=/entry dataFile=NXopt_minimal_example.nxs \n9 errors and 11 warnings found when validating NXopt_minimal_example.nxs\n</code></pre> <p>The errors tell you now which things are missing (message=\"Required group missing\"), if there is a field missing (message=\"Required field missing\"), or if an attribute is missing (message=\"Required attribute URL missing\" - here for example the attribute named URL)</p> <p>Now adjust the file creation, and add the respective fields to make your NeXus file compliant with the NeXus definitions. This way, you can ensure that your data is FAIR, which is then ready for sharing and publication.</p>"},{"location":"how-tos/validate-nexus-file.html#punx","title":"punx","text":"<p>punx - Python Utilities for NeXus HDF5 files</p> <p>This is python package, and can therefore be used on Linux and Windows systems.</p> <p>The package can be installed via pip. Therefore you need to have installed:</p> <ol> <li> <p>python</p> </li> <li> <p>pip</p> </li> </ol> <p>You can then evoke a command like this:</p> <pre><code>punx validate [-h] [--report REPORT] infile\n</code></pre> <p>\"validate\" tells the program that we want to validate a file</p> <p>\"[-h]\" tells the program to show the help message</p> <p>\"[--report REPORT]\" tells the program what findings should be reported. This is done by replacing REPORT with ={COMMENT,ERROR,NOTE,OK,TODO,UNUSED,WARN}</p> <p>Official docs</p>"},{"location":"how-tos/validate-nexus-file.html#installation_1","title":"Installation","text":"<p>Open the terminal and install punx via pip:</p> <pre><code>pip install punx\n</code></pre> <p>This software is based on other powerful software packages or libraries, therefore as well other packages have to be installed:</p> <pre><code>pip install h5py\npip install lxml\npip install numpy\npip install PyQt5\npip install requests\npip install pyRestTable\n</code></pre> <p>Then you should be able to test the package by:</p> <pre><code>punx demo\n</code></pre> <p>The output should look like this:</p> <pre><code>C:\\&gt;punx demo\n\n!!! WARNING: this program is not ready for distribution.\n\n\nconsole&gt; punx validate C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5\ndata file: C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5\nNeXus definitions: main, dated 2024-01-02 03:04:05, sha=xxxx21fxcef02xfbaa6x04e182e3d67dace7ef1b\n\nfindings\n============================ ======== ==================================== ==========================================================\naddress                      status   test                                 comments\n============================ ======== ==================================== ==========================================================\n/                            TODO     NeXus base class                     NXroot: more validations needed\n/                            OK       known NXDL                           NXroot: recognized NXDL specification\n/                            OK       NeXus base class                     NXroot: known NeXus base class\n/                            OK       NeXus default plot                   found by v3: /Scan/data/counts\n/                            OPTIONAL NXDL group in data file              not found:  in //entry\n/Scan                        TODO     NeXus base class                     NXentry: more validations needed\n/Scan                        OK       group in base class                  not defined: NXroot/Scan\n/Scan                        OK       known NXDL                           NXentry: recognized NXDL specification\n/Scan                        OK       NeXus base class                     NXentry: known NeXus base class\n/Scan                        OK       NXDL group in data file              found:  in /Scan/data\n/Scan                        NOTE     validItemName                        relaxed pattern: [a-zA-Z0-9_]([a-zA-Z0-9_.]*[a-zA-Z0-9_])?\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/collection_description\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/collection_identifier\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/collection_time\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/definition\n/Scan                        OPTIONAL NXDL field in data file              not found: /Scan/definition_local\n...\n...\n...\n/Scan/data@signal            OK       known attribute                      known: NXdata@signal\n/Scan/data@signal            OK       value of @signal                     found: /Scan/data/counts\n/Scan/data@signal            OK       NeXus default plot v3, NXdata@signal correct default plot setup in /NXentry/NXdata\n/Scan/data@two_theta_indices TODO     attribute value                      implement\n/Scan/data@two_theta_indices OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data@two_theta_indices OK       known attribute                      unknown: NXdata@two_theta_indices\n/Scan/data/counts            OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data/counts            OK       field in base class                  not defined: NXdata/counts\n/Scan/data/counts@units      TODO     attribute value                      implement\n/Scan/data/counts@units      OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data/two_theta         OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n/Scan/data/two_theta         OK       field in base class                  not defined: NXdata/two_theta\n/Scan/data/two_theta@units   TODO     attribute value                      implement\n/Scan/data/two_theta@units   OK       validItemName                        strict pattern: [a-z_][a-z0-9_]*\n============================ ======== ==================================== ==========================================================\n\n\nsummary statistics\n======== ===== =========================================================== =========\nstatus   count description                                                 (value)\n======== ===== =========================================================== =========\nOK       35    meets NeXus specification                                   100\nNOTE     1     does not meet NeXus specification, but acceptable           75\nWARN     0     does not meet NeXus specification, not generally acceptable 25\nERROR    0     violates NeXus specification                                -10000000\nTODO     7     validation not implemented yet                              0\nUNUSED   0     optional NeXus item not used in data file                   0\nCOMMENT  0     comment from the punx source code                           0\nOPTIONAL 40    allowed by NeXus specification, not identified              99\n         --\nTOTAL    83\n======== ===== =========================================================== =========\n\n&lt;finding&gt;=99.144737 of 76 items reviewed\nNeXus definitions version: main\n\nconsole&gt; punx tree C:\\Users\\rh83hixu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5\nC:\\Users\\rh83hixu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\punx\\data\\writer_1_3.hdf5 : NeXus data file\n  Scan:NXentry\n    @NX_class = \"NXentry\"\n    data:NXdata\n      @NX_class = \"NXdata\"\n      @axes = \"two_theta\"\n      @signal = \"counts\"\n      @two_theta_indices = [0]\n      counts:NX_INT32[31] = [1037, 1318, 1704, '...', 1321]\n        @units = \"counts\"\n      two_theta:NX_FLOAT64[31] = [17.92608, 17.92591, 17.92575, '...', 17.92108]\n        @units = \"degrees\"\n</code></pre> <p>Then you should be able to use this package.</p> <p>Official docs for punx installation</p>"},{"location":"how-tos/validate-nexus-file.html#using-punx","title":"Using punx","text":"<p>Open your terminal. Assuming there is a folder at:</p> <p>For Linux:</p> <pre><code>/home/USER/nexusvalidation\n</code></pre> <p>For Windows:</p> <pre><code>C:\\nexusvalidation\n</code></pre> <p>Put a NeXus file into this folder. For example, the file: SiO2onSi.ellips.nxs.</p> <p>then the command is (for Windows):</p> <pre><code>punx validate C:\\nexusvalidation\\SiO2onSi.ellips.nxs\n</code></pre> <p>For Linux:</p> <pre><code>punx validate C:\\nexusvalidation\\SiO2onSi.ellips.nxs\n</code></pre> <p>The output tables \"findings\" and \"summary statistics\" can be used to find error present in the NeXus file.</p> <p>Which NeXus definition?</p> <p>The program selects the NeXus definitions (set of nxdl.xml files) by itself. It can in principle also be modified with different repositories. The functionality to add a new repository is right now not possible (Aug 2024).</p> <p>Therefore, only the NIAC repository as NeXus definitions is functional.</p> <p>You may update the repository for the lastest version via:</p> <pre><code>punx install\n</code></pre> <p>The NeXus respective definitions are found here:</p> <p>NIAC NeXus definitions</p> <p>Search on the right side under \"quick search\" for \"NXopt\":</p> <p>NXopt NeXus definition</p> <p>This python code creates the respective python file with all required fields:</p> <p>NXopt_minimal_example_NIAC_NeXus_Def.nxs</p> <p>Here is the python code:</p> <p>h5py_nexus_file_creation_NIAC_NeXus_Def.py</p> <p>The command:</p> <pre><code>punx validate --report ERROR C:\\nexusvalidation\\NXopt_minimal_example_NIAC_NeXus_Def.nxs\n</code></pre> <p>then gives this output:</p> <pre><code>findings\n======= ====== ========== ======================================\naddress status test       comments                              \n======= ====== ========== ======================================\n/entry  ERROR  known NXDL NXopt: unrecognized NXDL specification\n======= ====== ========== ======================================\n\n\nsummary statistics\n======== ===== =========================================================== =========\nstatus   count description                                                 (value)  \n======== ===== =========================================================== =========\nOK       148   meets NeXus specification                                   100      \nNOTE     0     does not meet NeXus specification, but acceptable           75       \nWARN     0     does not meet NeXus specification, not generally acceptable 25       \nERROR    1     violates NeXus specification                                -10000000\nTODO     16    validation not implemented yet                              0        \nUNUSED   0     optional NeXus item not used in data file                   0        \nCOMMENT  0     comment from the punx source code                           0        \nOPTIONAL 213   allowed by NeXus specification, not identified              99       \n         --                                                                         \nTOTAL    378                                                                        \n======== ===== =========================================================== =========\n</code></pre> <p>The last error message:</p> <pre><code>======= ====== ========== ======================================\n/entry  ERROR  known NXDL NXopt: unrecognized NXDL specification\n======= ====== ========== ======================================\n</code></pre> <p>can be ignored and is a bug right now. If this is the only Error message, then your NeXus file is compliant with the NeXus definitions and you can share and publish your data.</p>"},{"location":"how-tos/validate-nexus-file.html#further-notes","title":"Further notes","text":"<ol> <li> <p>Punx only uses the NeXus definiton from the NIAC NeXus definiton from the NIAC. The use of the FAIRmat NeXus definition is not possible right now.</p> </li> <li> <p>Other punx commands are availble</p> </li> <li> <p>More details for installation</p> </li> <li> <p>Github project</p> </li> </ol>"},{"location":"how-tos/validate-nexus-file.html#summary","title":"Summary","text":"<p>This tutorial showed:</p> <ol> <li> <p>3 different tools for NeXus file validation</p> </li> <li> <p>How to install these tools</p> </li> <li> <p>How to use them via Examples</p> </li> </ol>"},{"location":"how-tos/validate-nexus-file.html#recommended-workflow","title":"Recommended workflow","text":"<p>As pynxtools verify_nexus method is right now in development, not all situations are covered right now. Therefore, the most reliable method right now is a combination of Human Manual Validation + Software solutions.</p>"},{"location":"how-tos/validate-nexus-file.html#pynxtools-parsers","title":"Pynxtools Parsers","text":"<p>For a specifically structured set of data, a parser can be written, which uses the meta data and a pre-structured meta data file, to create a NeXus file. Tough, the parser depends on: Experimental Technique and Setup and has therefore to be written individually. Take a look here.</p>"},{"location":"how-tos/validate-nexus-file.html#feedback-and-contact","title":"Feedback and contact","text":"<ol> <li> <p>Best way is to contact the software development team directly via a Github Issue.</p> </li> <li> <p>ron.hildebrandt(at)physik.hu-berlin.de</p> </li> </ol>"},{"location":"how-tos/writing-an-appdef.html","title":"Writing a Simple Application Definition","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p> <p>Concept of this How-to:</p> <p>Create an example file NXdouble_slit</p> <p>NXslit_experiments --&gt; NXdouble_slit NXslit_experiments --&gt; NXsingle_slit</p> <p>They should learn the basic principles of how nexus works, the different path notations - Principles of nexus     - concepts     - appdefs     - base classes - Inheritance of application definitions and base classes - Connection of concept paths and instance paths - Description of appdef/base class notation (upper and lower case) - Basic tools for creation (pynxtools) and verification (pynxtools?) of nexus files</p> <p>Additional information (i.e., not in this tutorial but linked to this): - Creating a reader in pynxtools - Reading/writing nexus data in nomad</p>"},{"location":"learn/dataconverter-and-readers.html","title":"Data conversion in pynxtools","text":"<p>One of the main motivations for pynxtools is to develop a tool for combining various instrument output formats and electronic lab notebook (ELN) into a file according to NeXus application definitions. </p> <p>The <code>dataconverter</code> API in pynxtools provides exactly that: it converts experimental as well as simulation data, together with the results from analysis of such data, to NeXus files based on any provided NXDL schemas. Here, we are using HDF5 as the serialization format.</p> <p>The dataconverter currently has essentially three functionalities:</p> <ol> <li>Read in experimental data using <code>readers</code></li> <li>Validate the data and metadata against a NeXus application definition of choice (i.e., check that the output data matches all existence, shape, and format constraints of application definition)</li> <li>Write a valid NeXus/HDF5 file</li> </ol> <p>A set of readers has been developed which the converter calls to read in a set of experiment/method-specific file(s) and for a specific set of application definitions (NXDL XML file). These data files can be in a proprietary format, or of a certain format used in the respective scientific community, or text files. Only in combination, these files hold all the required pieces of information which the application definition demands and which are thus required to make a NeXus/HDF5 file compliant. Users can store additional pieces of information in an NeXus/HDF5 file. In this case readers will issue a warning that these data are not properly documented from the perspective of NeXus.</p> <p>There exists two different subsets of readers:</p> <ol> <li>Built-in readers, which are implemented directly in pynxtools and are typically used either as superclasses for new reader implementations or for generic reading purposes not directly related to any specific technique.</li> <li>Reader plugins for `pynxtools, which are used for reading data of specific experimental techniques and are typically available as their own Python packages.</li> </ol>"},{"location":"learn/dataconverter-and-readers.html#matching-to-nexus-application-definitions","title":"Matching to NeXus application definitions","text":"<p>The purpose of the dataconverter is to create NeXus/HDF5 files with content that matches a specific NeXus application definition. Such application definitions are useful for collecting a set of pieces of information about a specific experiment in a given scientific field. The pieces of information are numerical and categorical (meta)data. The application definition is used to provide these data in a format that serves a data delivery contract: The HDF5 file, or so-called NeXus file, delivers all those pieces of information which the application definition specifies. Required and optional pieces of information are distinguished. NeXus classes can recommend the inclusion of certain pieces of information. Recommended data are essentially optional. The idea is that flagging these data as recommended motivates users to collect these, but does not require to write dummy or nonsense data if the recommended data is not available.</p>"},{"location":"learn/dataconverter-and-readers.html#getting-started","title":"Getting started","text":"<p>Each of the built-in readers comes with the main <code>pynxtools</code> package. Hence, they can be used after after pip installation: <pre><code>user@box:~$ pip install pynxtools\n</code></pre></p> <p>The different FAIRmat-supported plugins can be installed together with pynxtools by passing the name of the plugin as an extra to the pip install call. For example, for the <code>pynxtools-mpes</code> plugin: <pre><code>pip install pynxtools[mpes]\n</code></pre></p> <p>In addition, it is also possible to install all of the pynxtools reader plugins which are maintained by FAIRmat by passing the <code>[convert]</code> extra to the pip install call:</p> <pre><code>pip install pynxtools[convert]\n</code></pre> <p>Note that in this case, the latest version of the plugin from PyPI is installed.</p>"},{"location":"learn/dataconverter-and-readers.html#usage","title":"Usage","text":"<p>See here for the documentation of the <code>dataconverter</code> API.</p>"},{"location":"learn/dataconverter-and-readers.html#use-with-multiple-input-files","title":"Use with multiple input files","text":"<pre><code>user@box:~$ dataconverter metadata data.raw otherfile --nxdl nxdl --reader &lt;reader-name&gt;\n</code></pre>"},{"location":"learn/dataconverter-and-readers.html#merge-partial-nexus-files-into-one","title":"Merge partial NeXus files into one","text":"<pre><code>user@box:~$ dataconverter --nxdl nxdl partial1.nxs partial2.nxs\n</code></pre>"},{"location":"learn/dataconverter-and-readers.html#map-an-hdf5-filejson-file","title":"Map an HDF5 file/JSON file","text":"<pre><code>user@box:~$ dataconverter --nxdl nxdl any_data.hdf5 --mapping my_custom_map.mapping.json\n</code></pre> <p>You can find actual examples with data files at <code>examples/json_map</code>.</p>"},{"location":"learn/dataconverter-and-readers.html#example-data-for-testing-and-development-purposes","title":"Example data for testing and development purposes","text":"<p>Before using your own data we strongly encourage you to download a set of open-source test data for testing the pynxtools readers andreader  plugins. For this purpose, pynxtools and its plugins come  with <code>examples</code> and <code>test</code> directories including reader-specific examples. These examples can be used for downloading test data and use specific readers as a standalone converter to translate given data into a NeXus/HDF5 file.</p> <p>Once you have practized with these tools how to convert these examples, feel free to use the tools for converting your own data. You should feel invited to contact the respective corresponding author(s) of each reader if you run into issues with the reader or feel there is a necessity to include additional data into the NeXus file for your respective application.</p> <p>We are looking forward to learning from your experience and learn from your use cases. You can find the contact persons in the respective README.md of each reader (plugin).</p>"},{"location":"learn/multi-format-reader.html","title":"The MultiFormatReader as a reader superclass","text":"<p>There are three options for building a new <code>pynxtools</code> reader:</p> <ol> <li>build the reader from scratch</li> <li>inherit and extend the <code>BaseReader</code></li> <li>inherit and extend the <code>MultiFormatReader</code></li> </ol> <p>While option 1 is generally not recommended, inheriting and extending the <code>BaseReader</code> has traditionally been the default solution for all existing pynxtools readers and reader plugins. The <code>BaseReader</code>, which is an abstract base class, has an essentially empty <code>read</code> function and is  thus only helpful for implementing the correct input/output design of the <code>read</code> function of any reader which is implemented off of it.</p> <p>While building on the <code>BaseReader</code> allows for the most flexibility, in most cases it is desirable to implement a reader that can read in multiple file formats and then populate the NeXus file based on the read data, in compliance with a NeXus application definition. For this purpose, <code>pynxtools</code> has the <code>MultiFormatReader</code>, which can be readily extended for any new data.</p> <p>Here, we will explain the inner workings of the <code>MultiFormatReader</code>. Note that there is also a how-to guide on how to implement a new reader off of the <code>MultiFormatReader</code> using a concrete example. In case you simply want to use the <code>MultiFormatReader</code> without understanding its inner logic, we recommend you start there.</p>"},{"location":"learn/multi-format-reader.html#the-basic-structure","title":"The basic structure","text":"<p>For extending the <code>MultiFormatReader</code>, the following basic structure must be implemented: multi/reader.py<pre><code>\"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\nfrom typing import Tuple, Any\n\nfrom pynxtools.dataconverter.readers.base.reader import MultiFormatReader\n\nclass MyDataReader(MultiFormatReader):\n    \"\"\"MyDataReader implementation for the DataConverter to convert mydata to NeXus.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.extensions = {\n            \".yml\": self.handle_eln_file,\n            \".yaml\": self.handle_eln_file,\n            \".json\": self.set_config_file,\n            # Here, one must add functions for handling any other file extension(s)\n        }\n# This has to be set to allow the convert script to use this reader. Set it to \"MyDataReader\".\nREADER = MyDataReader\n</code></pre></p> <p>In order to understand the capabilities of the <code>MultiFormatReader</code> and which methods need to be implemented when extending it, we will have a look at its <code>read</code> method: multi/reader.py<pre><code>def read(\n    self,\n    template: dict = None,\n    file_paths: Tuple[str] = None,\n    objects: Optional[Tuple[Any]] = None,\n    **kwargs,\n) -&gt; dict:\n    self.kwargs = kwargs\n    self.config_file = self.kwargs.get(\"config_file\", self.config_file)\n    self.overwrite_keys = self.kwargs.get(\"overwrite_keys\", self.overwrite_keys)   \n</code></pre></p>"},{"location":"learn/multi-format-reader.html#template-initialization-and-processing-order","title":"Template initialization and processing order","text":"<p>An empty <code>Template</code> object is initialized that later gets filled from the data files later. multi/reader.py<pre><code>    template = Template(overwrite_keys=self.overwrite_keys)\n\n    def get_processing_order(path: str) -&gt; Tuple[int, Union[str, int]]:\n        \"\"\"\n        Returns the processing order of the file.\n        \"\"\"\n        ext = os.path.splitext(path)[1]\n        if self.processing_order is None or ext not in self.processing_order:\n            return (1, ext)\n        return (0, self.processing_order.index(ext))\n\n    sorted_paths = sorted(file_paths, key=get_processing_order)\n</code></pre> If the reader has a <code>self.processing_order</code>, the input files get sorted in this order. If <code>self.overwrite_keys</code> is True, later files get precedent. For example, if <code>self.processing_order = [\".yaml\", \".hdf5\"]</code>, any values coming from HDF5 files would overwrite values from the YAML files.</p>"},{"location":"learn/multi-format-reader.html#reading-of-input-files","title":"Reading of input files","text":"<p>multi/reader.py<pre><code>    for file_path in sorted_paths:\n        extension = os.path.splitext(file_path)[1].lower()\n        if extension not in self.extensions:\n            logger.warning(\n                f\"File {file_path} has an unsupported extension, ignoring file.\"\n            )\n            continue\n        if not os.path.exists(file_path):\n            logger.warning(f\"File {file_path} does not exist, ignoring entry.\")\n            continue\n\n        template.update(self.extensions.get(extension, lambda _: {})(file_path))\n</code></pre> This parts reads in the data from all data files. The <code>MultiFormatReader</code> has an <code>extensions</code> property, which is a dictionary that for each file extension calls a function that reads in data from files with that extension. If the reader shall handle e.g. an HDF5 file, a method for handling this type of file should be added, i.e., <code>self.extensions[\".hdf5\"] = self.handle_hdf5</code>. Note that these methods should also implement any logic depending on the provided data, i.e., it may not be sufficient to rely on the filename suffix, but the reader may also need to check for different file versions, binary signature, mimetype, etc.</p> <p>Any of these methods should take as input only the file path, e.g. multi/reader.py<pre><code>def handle_eln_file(self, file_path: str) -&gt; Dict[str, Any]\n</code></pre> These methods must return a dictionary. One possibility is to return a dictionary that directly fills the template (see the <code>template.update</code> call above) with the data from the file. Another option is to return an empty dictionary (i.e., not fill the template at this stage) and only later fill the template from a config file (see below).</p> <p>Note that for several input formats, standardized parser functions already exist within the <code>MultiFormatReader</code>. For example, YAML files can be parsed using the <code>pynxtools.dataconverter.readers.utils.parse_yml</code> function.</p>"},{"location":"learn/multi-format-reader.html#setting-default-values-in-the-template","title":"Setting default values in the template","text":"<p>multi/reader.py<pre><code>    template.update(self.setup_template())\n</code></pre> Next, the <code>setup_template</code> method can be implemented, which is used to populate the template with initial data that does not come from the files themselves. This may be used to set fixed information, e.g., about the reader. As an example, <code>NXentry/program_name</code> (which is defined as the name of program used to generate the NeXus file) scan be set to <code>pynxtools-plugin</code> by making <code>setup_template</code> return a dictionary of the form <pre><code>{\n  \"/ENTRY[my_entry]/program_name\": \"pynxtools-plugin\",\n  \"/ENTRY[my_entry]/program_name/@version\": \"v0.1.0\"\n}\n</code></pre></p>"},{"location":"learn/multi-format-reader.html#handling-objects","title":"Handling objects","text":"<p>multi/reader.py<pre><code>    if objects is not None:\n        template.update(self.handle_objects(objects))\n</code></pre> Aside from data files, it is also possible to directly pass any Python objects to the <code>read</code> function (e.g., a numpy array with measurement data). In order to exploit this, the <code>handle_objects</code> method must implemented, which should return a dictionary that populates the template.</p>"},{"location":"learn/multi-format-reader.html#parsing-the-config-file","title":"Parsing the config file","text":"<p>multi/reader.py<pre><code>    if self.config_file is not None:\n        self.config_dict = parse_flatten_json(\n            self.config_file, create_link_dict=False\n        )\n</code></pre> Next up, we can make use of the config file, which is a JSON file that tells the reader which input data to use to populate the template. In other words, the config.json is used for ontology mapping between the input file paths and the NeXus application definition. Essentially, the config file should contain all keys that are present in the NXDL. A subset of a typical config file may look like this: <pre><code>{\n  \"/ENTRY/title\": \"@attrs:metadata/title\", \n  \"/ENTRY/USER[user]\": {\n    \"name\": \"my_name\",\n  }, \n  \"/ENTRY/INSTRUMENT[instrument]\": {\n    \"name\":\"@eln\",\n    \"temperature_sensor\": {\n      \"value\": \"@attrs:metadata/temp\",\n      \"value/@units\": \"K\"\n    }\n  },\n  \"/ENTRY/SAMPLE[sample]\": {\n    \"temperature_env\": {\n      \"temperature_sensor\": \"@link:/entry/instrument/temperature_sensor\"\n    }\n  },  \n  \"/ENTRY/data\": {\n    \"@axes\": \"@data:dims\",\n    \"AXISNAME_indices[@*_indices]\": \"@data:*.index\",\n    \"@signal\": \"data\",\n    \"data\": \"@data:mydata\",\n  }\n}\n</code></pre> Here, the <code>parse_flatten_json</code> method is used that allows us to write the config dict in the structured manner above and internally flattens it (so that it has a similar structure as the Template).</p> <p>In the config file, one can</p> <ol> <li>hard-code values (like the unit <code>\"K\"</code> in <code>\"/ENTRY/INSTRUMENT[instrument]/temperature_sensor/value/@units\"</code>) or</li> <li>tell the reader where to search for data using the <code>@</code>-prefixes. For more on these prefixes, see below.</li> </ol> <p>Note that in order to use a <code>link_callback</code> (see below), <code>create_link_dict</code> must be set to <code>False</code>, which means that at this stage, config values of the form <code>\"@link:\"/path/to/source/data\"</code> get NOT yet converted to <code>{\"link\": \"/path/to/source/data\"}</code>.</p>"},{"location":"learn/multi-format-reader.html#data-post-processing","title":"Data post processing","text":"<p>multi/reader.py<pre><code>   self.post_process()\n</code></pre> In case there is the need for any post-processing on the data and/or config dictionary after they have been read, the <code>post_process</code> method can be implemented. For example, this can be helpful if there are multiple entities of a given NX_CLASS (for example, multiple detectors) on the same level and the config dict shall be set up to fill the template with all of these entities.</p>"},{"location":"learn/multi-format-reader.html#filling-the-template-from-the-read-in-data","title":"Filling the template from the read-in data","text":"<p>multi/reader.py<pre><code>    if self.config_dict:\n        suppress_warning = kwargs.pop(\"suppress_warning\", False)\n        template.update(\n            fill_from_config(\n                self.config_dict,\n                self.get_entry_names(),\n                self.callbacks,\n                suppress_warning=suppress_warning,\n            )\n        )\n\n    return template\n</code></pre> As a last step, the template is being filled from the config dict using the data. If there is more than one entry, the <code>get_entry_names</code> method must be implemented, which shall return a list of all entry names. The <code>fill_from_config</code> method iterates through all of the them and replaces the generic <code>/ENTRY/</code> in the config file by keys of the form <code>/ENTRY[my-entry]/</code> to fill the template.</p> <p>Here, we are using callbacks, which are used to bring in data based on <code>@</code>-prefixes in the config file. These are defined in the reader's <code>__init__</code> call using the <code>pynxtools.dataconverter.readers.multi.ParseJsonCallbacks</code> class: multi/reader.py<pre><code>self.callbacks = ParseJsonCallbacks(\n    attrs_callback=self.get_attr,\n    data_callback=self.get_data,\n    eln_callback=self.get_eln_data,\n    dims=self.get_data_dims,\n)\n</code></pre> The <code>ParseJsonCallbacks</code> class has an attribute called <code>special_key_map</code> that makes use of these callbacks to populate the template based on the starting prefix of the config dict value: multi/reader.py<pre><code>self.special_key_map = {\n    \"@attrs\": attrs_callback if attrs_callback is not None else self.identity,\n    \"@link\": link_callback if link_callback is not None else self.link_callback,\n    \"@data\": data_callback if data_callback is not None else self.identity,\n    \"@eln\": eln_callback if eln_callback is not None else self.identity,\n}\n</code></pre> That means, if the config file has an entry <code>{\"/ENTRY/title\": \"@attrs:metadata/title\"}</code>, the <code>get_attr</code> method of the reader gets called and should return an attribute from the given path, i.e., in this case from <code>metadata/title</code>.</p> <p>By default, the MultiFormatReader supports the following special prefixes:</p> <ul> <li><code>@attrs</code>: To get metadata from the read-in experiment file(s). You need to implement the <code>get_attr</code> method in the reader.</li> <li><code>@data</code>: To get measurement data from the read-in experiment file(s). You need to implement the <code>get_data</code> method in the reader.</li> <li><code>@eln</code>: To get metadata from addtional ELN files. You need to implement the <code>get_eln_data</code> method in the reader.</li> <li><code>@link</code>: To implement a link between two entities in the NeXus file. By default, the link callback returns a dict of the form {\"link\": value.replace(\"/entry/\", f\"/{self.entry_name}/\")}, i.e., a generic <code>/entry/</code> get replaced by the actual <code>entry_name</code>.</li> </ul> <p>The destinction between data and metadata is somewhat arbitrary here. The reason to have both of these prefixes is to have different methods to access different parts of the read-in data. For example, <code>@attrs</code> may just access key-value pairs of a read-in dictionary, whereas <code>@data</code> can handle different object types, e.g. xarrays. The implementation in the reader decides how to distinguish data and metadata and what each of the callbacks shall do.</p> <p>In addition, the reader can also implement the <code>get_data_dims</code> method, which is used to return a list of the data dimensions (see below for more details).</p> <p>All of <code>get_attr</code>, <code>get_data</code>, and <code>get_eln_data</code>  (as well as any similar method that might be implemented) should have the same call signature: <pre><code>def get_data(self, key: str, path: str) -&gt; Any:\n</code></pre> Here, <code>key</code> is the config dict key (e.g., <code>\"/ENTRY[my-entry]/data/data\"</code>) and path is the path that comes after the prefix in the config file. In the example config file above, <code>path</code> would be <code>mydata</code>. With these two inputs, the reader should be able to return the correct data for this template key.</p>"},{"location":"learn/multi-format-reader.html#special-rules","title":"Special rules","text":"<ul> <li> <p>Lists as config value: It is possible to write a list of possible configurations of the sort   <pre><code>\"/ENTRY/title\":\"['@attrs:my_title', '@eln', 'no title']\"\n</code></pre>   The value must be a string which can be parsed as a list, with each item being a string itself. This allows to provide different options depending if the data exists for a given callback. For each list item , it is checked if a value can be returned and if so, the value is written. In this example, the converter would check (in order) the <code>@attrs</code> (with path <code>\"my_title\"</code>) and <code>@eln</code> (with path <code>\"\"</code>) tokens and write the respective value if it exists. If not, it defaults to \"no title\".   This concept can be particularly useful if the same config file is used for multiple measurement configurations, where for some setup, the same metadata may or may not be available.</p> <p>Note that if this notation is used, it may be helpful to pass the <code>suppress_warning</code> keyword as <code>True</code> to the read function. Otherwise, there will be a warning for every non-existent value.</p> </li> <li> <p>Wildcard notation: There exists a wildcard notation (using <code>*</code>)   <pre><code>\"/ENTRY/data/AXISNAME[*]\": \"@data:*.data\",\n</code></pre>   that allows filling multiple fields of the same type from a list of dimensions. This can be particularly helpful for writing <code>DATA</code> and <code>AXISNAME</code> fields that are all stored under similar paths in the read-in data.   For this, the <code>get_data_dims</code> method needs to be implemented. For a given path, it should return a list of all data axes available to replace the wildcard.</p> <p>The same wildcard notation can also be used within a name to repeat entries with different names (e.g., field_*{my, name, etc} is converted into three keys with * replaced by my, name, etc, respectively). As an example, for multiple lenses and their voltage readouts, one could write:   <pre><code>\"LENS_EM[lens_*{A,B,Foc}]\": {\n  \"name\": \"*\",\n  \"voltage\": \"@attrs:metadata/file/Lens:*:V\",\n  \"voltage/@units\": \"V\"\n},\n</code></pre>   which would write <code>NXlens_em</code> instances named <code>lens_A</code>, <code>lens_B</code>, and <code>lens_Foc</code>.</p> </li> <li> <p>Required fields in optional groups: There will sometimes be the situation that there is an optional NeXus group in an application definition, that (if implemented) requires some sub-element. As an example, for the instrument's energy resolution, the only value expected to come from a data source is the <code>resolution</code>, whereas other fields are hardcoded.   <pre><code>\"ENTRY/INSTRUMENT[instrument]/energy_resolution\": {\n  \"resolution\": \"@attrs:metadata/instrument/electronanalyser/energy_resolution\",\n  \"resolution/@units\": \"meV\",\n  \"physical_quantity\": \"energy\"\n}\n</code></pre>   Now, if there is no data for <code>@attrs:metadata/instrument/electronanalyser/energy_resolution</code> available in a dataset, this will be skipped by the reader, and not available, yet the other entries are present. During validation, this means that the required field <code>resolution</code> of the optional group <code>energy_resolution</code> is not present, and thus a warning or error would be raised:   <pre><code>LookupError: The data entry, /ENTRY[entry]/INSTRUMENT[instrument]/ELECTRONANALYSER[electronanalyser]/energy_resolution/physical_quantity, has an optional parent, /ENTRY[entry]/INSTRUMENT[instrument]/ELECTRONANALYSER[electronanalyser]/energy_resolution, with required children set. Either provide no children for /ENTRY[entry]/INSTRUMENT[instrument]/ELECTRONANALYSER[electronanalyser]/energy_resolution or provide all required ones.\n</code></pre></p> <p>To circumvent this problem, there exists a notation using the <code>\"!\"</code> prefix. If you write <pre><code>\"ENTRY/INSTRUMENT[instrument]/energy_resolution/resolution\": \"!@attrs:metadata/instrument/electronanalyser/energy_resolution\"\n</code></pre> the whole parent group <code>/ENTRY/INSTRUMENT[instrument]/energy_resolution</code> will not be written in case that there is no value for <code>@attrs:metadata/instrument/electronanalyser/energy_resolution\"</code>, thus preventing the aforementioned error.</p> </li> </ul>"},{"location":"learn/multiple-appdefs.html","title":"Multiple Application Definitions in NeXus","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p> <p>This tutorial showcases how to employ multiple application definitions in NeXus for creating a file that conforms to various definitions simultaneously.</p> <p>Prerequisites</p> <p>Familiarity with the basics of NeXus and its application definitions is required. For an introduction to NeXus, please refer to the basic documentation.</p> <p>In a laboratory setting, the data we collect can vary significantly depending on the experiment's specific setup. Consider, for instance, an experiment characterized using the <code>NXexperiment</code> application definition. Suppose we want to enhance this experiment by incorporating energy resolution details. A straightforward approach might involve creating a specialized sub-application definition, like <code>NXexperiment_energy_resolved</code>, to include metadata about the experiment's energy resolution.</p> <p>While this method is effective for initial expansions of the metadata, it becomes cumbersome when trying to merge multiple enhancements into a single application definition. Imagine we wish to integrate additional elements that provide time resolution data for our experiment.  We need to create three sub application definitions to reflect all combinations: <code>NXexperiment_time_resolved</code>, <code>NXexperiment_energy_resolved</code> and <code>NXexperiment_energy_time_resolved</code>. For three experimental facets we already need 7 sub application definitions. An additional problem is that we have to repeat the whole procedure for all experiments we like to add the specific traits to. So if we have three different parent application definitions we already need to create 9 sub application definitions just to add energy and time resolution.</p> <p>The solution for this problem is to specify multiple application definitions while writing a NeXus file to follow different traits of the experiment. This allows us to simply create <code>NXtime_resolved</code> and <code>NXenergy_resolved</code> and combine it with any experiment we want to use it with. This comes, however, with a few drawbacks. One of them is that it is currently not possible to write a file which wants to use two different application definitions which have conflicting fields. While this is generally possible in the framework of NeXus, since every application definition creates their own namespace, this is not supported when the paths are reduced to entry path notation.</p> <p>ToDo: - Make an example of NXexperiment, NXtime_resolved and NXenergy_resolved and show how it is combined into the instance path. - Also show this for a conflict. Compare concept path (no problem) to instance path (colliding). - Write a part how it is described in the file that it follows two appdefs <code>/entry/definitions</code> as array containing both appdefs. - Explain that this is no problem with the expanded concept path notation but fails when we only use the instance path. - Explain the reader concept: One reader for one appdef, then pynxtools will figure out how to combine them (this is domain knowledge for the FAIRmat reader -&gt; will be different when a read/write tool is written somewhere else).</p>"},{"location":"learn/nexus-primer.html","title":"A primer on NeXus","text":"<p>Work in progress</p> <p>This part of the documentation is still being written and it might be confusing or incomplete.</p> <p>NeXus is is a description of a common data exchange format initially developed for neutron, X-ray, and muon experiments. Within FAIRmat we extensively extended the format to cover a range of experiments with major support for APM, ARPES, XPS, and optical spectroscopy, but we also give advice and guidance for developing standards for other formats as well.</p> <p>NeXus as a tool for FAIR data</p> <p>NeXus is supported be the research data management platform NOMAD. Experimental data following an NeXus application definition can easily be uploaded and is recognized by NOMAD's search system. If you want to learn more about uploading NeXus data to NOMAD, please refer to the NeXus to NOMAD tutorial of this documentation. Accordingly, if you want to build data according to the FAIR principles, you can think of NeXus fulfilling the interoperability and reproducibility part and a research data management platform like NOMAD the findable and accessible part.</p>"},{"location":"learn/nexus-primer.html#what-is-nexus","title":"What is NeXus?","text":"<p>Sometimes, NeXus is seen as writing data to some form of file in HDF5 format. While this is partly true, NeXus is independent of the actual storage format, but is typically written into an HDF5 file.</p> <p>But what is NeXus then? It is the conceptual layer above the file structure. It is a contract on which data has to be present and how to name them in a given dataset. Hence, the use of NeXus helps to make data FAIR. It especially covers the interoperability and reproducibility part of research data.</p> <p>NeXus path notations</p> <p>There are several methods for referencing concepts or data paths within NeXus:</p> <ul> <li> <p>Concept Path Notation: This notation describes the hierarchical structure of NeXus concepts using class names. For example, <code>NXexperiment:/NXentry/NXinstrument/NXdetector</code> indicates the creation of a new NXdetector class within the NXexperiment concept. This path typically forms automatically when an application definition extends a base class's fields.</p> </li> <li> <p>Instance Path Notation: It represents the actual location of a field or group in a NeXus data instance (e.g., an HDF5 file). An example is <code>my_file.nxs:/entry/instrument/detector</code>.</p> </li> <li> <p>Combined Notation: This combines concept and instance paths. For example, <code>NXexperiment:/NXentry[my_file.nxs:entry]/NXinstrument[instrument]/NXdetector[detector]</code>. Here, concept paths are outside and instance paths within square brackets. The leftmost entries may include the NeXus class or file reference.</p> </li> <li> <p>Appdef Notation: This format is used in application definitions, where uppercase indicates a selectable name and lowercase a fixed name. Examples include <code>NXexperiment:ENTRY[my_experiment.nxs:entry]/INSTRUMENT[instrument]/DETECTOR[detector]</code> and <code>NXexperiment:ENTRY[my_experiment.nxs:entry]/my_INSTRUMENT[my_instrument]/DETECTOR[detector]</code>.</p> </li> </ul>"},{"location":"learn/nexus-rules.html","title":"Rules for storing data in NeXus","text":"<p>There are several rules which apply for storing single data items in NeXus. There exists a summary in the NeXus documentation outlining most of these rules. However, to guide data providers even further, we have compiled here additional information and explanations.</p>"},{"location":"learn/nexus-rules.html#namefitting","title":"Namefitting","text":"<p>In general, the names of NeXus group and field items are validated according to the boundaries outlined in the Rules for Storing Data Items in NeXus Files, section \"NXDL group and field names\": - Recommended names   - lower case words separated by underscores and, if needed, with a trailing number</p> <ul> <li>Allowed names</li> <li>any combination of upper and lower case letter, numbers, underscores and periods, except that periods cannot be at the start or end of the string</li> <li>This statement is equivalent to matching  this regular expression (named <code>validItemName</code> in the nxdl.xsd) XML Schema file:   <pre><code>^[a-zA-Z0-9_]([a-zA-Z0-9_.]*[a-zA-Z0-9_])?$\n</code></pre></li> <li>Invalid names:</li> <li>any name not matching this <code>validItemName</code> regular expression</li> </ul> <p>Note that this explicitly also means that it is not allowed to have whitespace (including \" \") in NeXus names.</p> <p>In NeXus base classes and application definitions, there are two options for defining a concept name. If the group or field in the definition is lowercase, that means that any instance must have the exact same (fixed) name. As an example, if there is a field called <code>my_field</code> in an application definition, the only allowed name in a file would be <code>my_field</code>.</p> <p>Aside from this lower case notation, there is also the option to allow for selectable names. This is achieved by uppercase notation. As an example, if a field in an application definition is called <code>FIELD</code>, the name can be any name as long as it maches the regular expression above. For example, <code>field</code>, <code>field0</code>, <code>any_other_name</code> would be allowed names, while <code>any other name</code> would not be allowed.</p> <p>There is also the possibility of mixed lowercase and uppercase notation in base classes and application definitions. For example, there might be a <code>userID(NXuser)</code> group. In this case, allowed names include any name that start with <code>user</code>, e.g., <code>user0</code>, <code>user_abcde</code>, as long as the part that replaces the docstring is still valid according to the regex above. Note that here it is also allowed to write <code>user</code> without replacing the uppercase part of the name.</p> <p>The validation of names is performed by namefitting, i.e., fitting the name that is used by the data provider to the name given in the base class / application definitions.</p> <p>A python implementation of this process can be found in this function. This function returns twice the length for an exact match, otherwise the number of matching characters (case insensitive) or zero, if <code>name_any</code> is set to True, is returned. This is also the function that is used in the validation implemented in pynxtools.</p>"},{"location":"learn/nexus-rules.html#special-rules-for-names-and-namefitting","title":"Special rules for names and namefitting","text":"<p>Aside from these general rules, there are a number of special rules for NeXus names that need to be considered:</p> <ul> <li> <p>There is a set of UPPERCASE reserved words (like <code>BLUESKY_</code>, <code>DECTRIS_</code>, <code>IDF_</code>, etc.) that are reserved for certain projects and communities. These are prefixes (typically written as uppercase + undersorce) that cannot be overwritten by namefitting. For the full list, see Rules for Storing Data Items in NeXus Files, section \"Reserved prefixes\".</p> </li> <li> <p>There is also a set of reserved suffixes that are used to give additional information for a group or field. For the full list, see Rules for Storing Data Items in NeXus Files, section \"Reserved suffixes\".</p> </li> <li> <p>Additionally to namefitting, data annotation can use further information. For example, in case of NXdata, the axes listed among the <code>@axes</code> shall fit to any instances of <code>AXISNAME</code> and data objects listed in <code>@signal</code> or <code>@auxiliary_signals</code> shall fit to instances of <code>DATA</code>. Such rules are typically given in the base classes (e.g., see here for NXdata). Any tool that makes use of the base classes should implement these special rules in its validation procedure. As an example, pynxtools has a special function for handling NXdata.</p> </li> </ul>"},{"location":"learn/nexus-validation.html","title":"NeXus validation","text":"<p>Work in progress</p> <p>This page is intended to give more information about the validation tools that are part of <code>pynxtools</code>. Please also have a look at our comprehensive how-to guide on NeXus validation.</p> <p>One of the main advantages of using pynxtools is that it comes with its own validation tools. That is, it can be used to validate that a given NeXus/HDF5 file is compliant with a NeXus application definition.</p>"},{"location":"learn/nexus-validation.html#as-part-of-the-dataconverter","title":"As part of the dataconverter","text":"<p>During data conversion, before writing the HDF5 file, the data is first checked against the provided application definition.</p>"},{"location":"learn/nexus-validation.html#read_nexus-nexus-file-reader-and-debugger","title":"read_nexus: NeXus file reader and debugger","text":"<p>This utility outputs a debug log for a given NeXus file by annotating the data and metadata entries with the schema definitions from the respective NeXus base classes and application definitions to which the file refers to. See here for the API documentation.</p> <p>The following example dataset can be used to test the <code>read_nexus</code> module: src/pynxtools/data/201805_WSe2_arpes.nxs.</p> <p>This is an angular-resolved photoelectron spectroscopy (ARPES) dataset that is formatted according to the NXarpes application definition of NeXus.</p>"},{"location":"learn/nexus-validation.html#using-a-different-set-of-nexus-definitions","title":"Using a different set of NeXus definitions","text":"<p>The environment variable \"NEXUS_DEF_PATH\" can be set to a directory which contains the NeXus definitions as NXDL XML files. If this environment variable is not defined, the module will use the definitions in its bundle (see <code>src/pynxtools/definitions</code>)._</p> <p>The environment variable can be set as follows: <pre><code>export 'NEXUS_DEF_PATH'=&lt;folder_path_that_contains_nexus_defs&gt;\n</code></pre></p>"},{"location":"learn/nexus-validation.html#a-note-to-windows-users","title":"A note to Windows users","text":"<p>If you run <code>read_nexus</code> from <code>git bash</code>, you need to set the environmental variable <code>MSYS_NO_PATHCONV</code> to avoid the path translation in Windows Git MSys. The easiest way is to prefix the <code>read_nexus</code> call with <code>MSYS_NO_PATHCONV=1</code>:</p> <pre><code>MSYS_NO_PATHCONV=1 read_nexus -c /NXarpes/ENTRY/INSTRUMENT/analyser\n</code></pre> <p>This workaround was tested with Windows 11, but should very likely also work with Windows 10 and lower.</p>"},{"location":"learn/nexus-validation.html#other-approaches-not-part-of-pynxtools","title":"Other approaches (not part of pynxtools)","text":"<p>Aside from the tools we developed within FAIRmat, the official NeXus website lists two more programs for the validation of NeXus files:</p> <ol> <li>cnxvalidate</li> <li>punx</li> </ol> <p>We will not discuss the details of these two programs here, but you can find some information about the in the how-to guide linked above.</p>"},{"location":"reference/built-in-readers.html","title":"Built-in readers","text":"<p>There exists a number of readers directly in pynxtools. These are typically used either as superclasses for new reader implementations or for generic reading purposes not directly related to any specific technique.</p>"},{"location":"reference/built-in-readers.html#the-basereader","title":"The BaseReader","text":"<p>This is the most simple reader, which is an abstract base class, on top of which a new reader implementation can build. It has an essentially empty read function and is thus only helpful for implementing the correct input/ouput design of the <code>read</code> function of any reader that is inheriting from this base reader.</p>"},{"location":"reference/built-in-readers.html#the-multiformatreader","title":"The MultiFormatReader","text":"<p>Another reader that can act as the basis for any reader implementation is the <code>MultiFormatReader</code>, which can be used to implement a reader that can read in multiple file formats and then populate the NeXus file using the read data. Note that this reader has a lot of already built-in functionality, which is extensively described here. There is also a how-to guide on how to implement a new reader off of the <code>MultiFormatReader</code> using a concrete example.</p>"},{"location":"reference/built-in-readers.html#the-jsonmapreader","title":"The JsonMapReader","text":"<p>This reader is designed to allow users of <code>pynxtools</code> to convert their existing data with the help of a map file. The map file tells the reader which concept and instance data to pick from the data files and how to convert these to NeXus files. The following formats are supported as input files:</p> <ul> <li>HDF5</li> <li>JSON</li> <li>Python Dict Objects pickled with pickle. These can contain xarray.DataArray objects as well as regular Python types and Numpy types. Note that while it is supported, we strongly recommend note to use pickle due to its known security concerns.</li> </ul> <p>It accepts any XML file that follows the NXDL schema definition language file as long as your mapping file contains all the required fields. Please use the <code>--generate-template</code> function of the <code>dataconverter</code> to create a <code>.mapping.json</code> file:</p> <pre><code>user@box:~$ dataconverter --nxdl NXmynxdl --generate-template &gt; mynxdl.mapping.json\n</code></pre>"},{"location":"reference/built-in-readers.html#the-mappingjson-file","title":"The mapping.json file","text":"<p>This file is designed to let you fill in the requirements of a NeXus Application Definition without writing any code. If you already have data in the formats listed above, you just need to use this mapping file to help the dataconverter pick your data correctly.</p> <p>The mapping files will always be based on the template the dataconverter generates. See above on how to generate a mapping file. The right hand side values of the template keys are what you can modify. These keys are called NeXus template paths, because they combine the actual path that will be used in the HDF5 hierarchy with additional NeXus datatype hints to guide the dataconverter to add NX_class annotations.</p> <p>Here are the three different ways you can fill the right hand side of the template keys:</p> <ul> <li>Write the nested path in your datafile. This is indicated by a leading <code>/</code> before the word <code>entry</code> to make <code>/entry/data/current_295C</code> below. Example:</li> </ul> <p><pre><code>  \"/ENTRY[entry]/DATA[data]/current_295C\": \"/entry/data/current_295C\",\n  \"/ENTRY[entry]/NXODD_name/posint_value\": \"/a_level_down/another_level_down/posint_value\",\n</code></pre> Here, <code>\"/entry/data/current_295C\"</code> is the path in the original HDF5 file, while the key shown here is the template path (see above).</p> <ul> <li>Write the values directly in the mapping file for missing data from your data file.</li> </ul> <pre><code>  \"/ENTRY[entry]/PROCESS[process]/program\": \"Bluesky\",\n  \"/ENTRY[entry]/PROCESS[process]/program/@version\": \"1.6.7\"\n</code></pre> <ul> <li>Write JSON objects with a link key. This follows the same link mechanism that the dataconverter implements. In the context of this reader, you can only use external links to your data files. In the example below, <code>current.nxs</code> is an already existing HDF5 file that we link to in our new NeXus file without copying over the data. The format is as follows: <code>\"link\": \"&lt;filename&gt;:&lt;path_in_file&gt;\"</code> Note: This only works for HDF5 files currently.</li> </ul> <pre><code>  \"/ENTRY[entry]/DATA[data]/current_295C\": {\"link\": \"current.nxs:/entry/data/current_295C\"},\n  \"/ENTRY[entry]/DATA[data]/current_300C\": {\"link\": \"current.nxs:/entry/data/current_300C\"},\n</code></pre>"},{"location":"reference/built-in-readers.html#examples","title":"Examples","text":""},{"location":"reference/built-in-readers.html#basic-mappings","title":"Basic mappings","text":"<p>There are some example files you can use:</p> <p>data.mapping.json</p> <p>data.json</p> <pre><code>user@box:~$ dataconverter --nxdl NXtest data.json --mapping data.mapping.json\n</code></pre>"},{"location":"reference/built-in-readers.html#example-with-hdf5-files","title":"Example with HDF5 files","text":"<p>You can find example data files for using the mapping with HDF5 files at <code>examples/json_map</code>.</p> <p>The example can be run by calling</p> <pre><code>user@box:~$ dataconverter --nxdl nxdl any_data.hdf5 --mapping my_custom_map.mapping.json\n</code></pre>"},{"location":"reference/built-in-readers.html#the-yamljsonreader","title":"The YamlJsonReader","text":"<p>Work in progress</p>"},{"location":"reference/built-in-readers.html#installation","title":"Installation","text":"<p>Each of the built-in readers are shipped/installed with the main <code>pynxtools</code> package. Hence, these readers are available after pip installation: <pre><code>user@box:~$ pip install pynxtools\n</code></pre></p>"},{"location":"reference/cli-api.html","title":"API for command line tools","text":"<p><code>pynxtools</code> supports a number of command line applications. This page provides documentation for their current API.</p>"},{"location":"reference/cli-api.html#data-conversion","title":"Data conversion","text":"<p>Note that simply calling <code>dataconverter</code> defaults to <code>dataconverter convert</code>.</p>"},{"location":"reference/cli-api.html#dataconverter","title":"dataconverter","text":"<p>Usage:</p> <pre><code>dataconverter [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>convert: This command allows you to use the converter functionality of the dataconverter.</li> <li>generate-template: Generates and prints a template to use for your nxdl.</li> <li>get-readers: Prints a list of all installed readers.</li> </ul>"},{"location":"reference/cli-api.html#dataconverter-convert","title":"dataconverter convert","text":"<p>This command allows you to use the converter functionality of the dataconverter.</p> <p>Usage:</p> <pre><code>dataconverter convert [OPTIONS] [FILES]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--input-file</code> text Deprecated: Please use the positional file arguments instead. The path to the input data file to read. Repeat for more than one file. default=[] This option is required if no '--params-file' is supplied. <code>[]</code> <code>--reader</code> choice (<code>example</code> | <code>json_map</code> | <code>json_yml</code> | <code>multi</code>) The reader to use. Examples are json_map or readers from a pynxtools plugin. default='json_map' This option is required if no '--params-file' is supplied. <code>json_map</code> <code>--nxdl</code> text The name of the NeXus application definition file to use without the extension nxdl.xml. This option is required if no '--params-file' is supplied. None <code>--output</code> text The path to the output NeXus file to be generated. default='output.nxs' <code>output.nxs</code> <code>--params-file</code> filename Allows to pass a .yaml file with all the parameters the converter supports. None <code>--ignore-undocumented</code> boolean Ignore all undocumented fields during validation. <code>False</code> <code>--fail</code> boolean Fail conversion and don't create an output file if the validation fails. <code>False</code> <code>--skip-verify</code> boolean Skips the verification routine during conversion. <code>False</code> <code>--mapping</code> text Takes a .mapping.json file and converts data from given input files. None <code>-c</code>, <code>--config</code> file A json config file for the reader None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli-api.html#dataconverter-generate-template","title":"dataconverter generate-template","text":"<p>Generates and prints a template to use for your nxdl.</p> <p>Usage:</p> <pre><code>dataconverter generate-template [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--nxdl</code> text The name of the NeXus application definition file to use without extension. For example: NXmpes _required <code>--required</code> boolean Use this flag to only get the required template. <code>False</code> <code>--pythonic</code> boolean Prints a valid Python dictionary instead of JSON <code>False</code> <code>--output</code> path Writes the output into the filepath provided. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli-api.html#dataconverter-get-readers","title":"dataconverter get-readers","text":"<p>Prints a list of all installed readers.</p> <p>Usage:</p> <pre><code>dataconverter get-readers [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli-api.html#nexus-file-validation","title":"NeXus file validation","text":""},{"location":"reference/cli-api.html#read_nexus","title":"read_nexus","text":"<p>Functionality to extract documentation and concept definition information about the individual parts of a NeXus/HDF5 file.</p> <p>Usage:</p> <pre><code>read_nexus [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>-f</code>, <code>--nexus-file</code> text NeXus file with extension .nxs. None <code>-d</code>, <code>--documentation</code> text Definition path in nexus output (.nxs) file. Returns debug log relevant with that definition path. Example: /entry/data/delays None <code>-c</code>, <code>--concept</code> text Concept path from application definition file (.nxdl,xml). Finds out all the available concept definition (IS-A realation) for rendered concept path. Example: /NXarpes/ENTRY/INSTRUMENT/analyser None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>NOTE: Only one option from (<code>-d</code> and <code>-c</code>) is acceptable.</p>"},{"location":"reference/cli-api.html#eln-generation","title":"ELN generation","text":""},{"location":"reference/cli-api.html#generate_eln","title":"generate_eln","text":"<p>Helper tool for generating ELN files in YAML format.</p> <p>Usage:</p> <pre><code>generate_eln [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--nxdl</code> text Name of NeXus definition without extension (.nxdl.xml). _required <code>--skip-top-levels</code> integer To skip the level of parent hierarchy level. For example, by default the part Entry[ENTRY] from /Entry[ENTRY]/Instrument[INSTRUMENT]/... will be skiped. <code>0</code> <code>--output-file</code> text Name of file that is needed to generated output file. None <code>--eln-type</code> choice (<code>reader</code> | <code>schema</code>) Choose a type of ELN output (reader or schema). <code>eln</code> <code>--optionality</code> choice (<code>required</code> | <code>recommended</code> | <code>optional</code>) Level of requiredness to generate. If any of ('required', 'recommended', 'optional', only those concepts matching this requiredness level are created. <code>required</code> <code>--filter-file</code> text JSON configuration file to filter NeXus concepts (based on the presence of the '@eln' keyword). This is a positive filter, i.e., all concepts in the filter file will be included in the ELN. None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/definitions.html","title":"NeXus definitions","text":"<p>We link two references here. The first links to the official definitions by the NIAC and the second one links to latest FAIRmat definitions.</p> <ul> <li>Official NIAC definitions</li> <li>Latest FAIRmat definitions</li> </ul> <p>The FAIRmat definitions are regularly contributed to NIAC (around every 6 months), but generally reflect a state which is still under development and may contain new or improved application definitions or base classes. Consider it as the public review stage of these application definitions. However, there might be some parts which are still under discussion and will be subject to change.</p> <p>Note: To connect NeXus concepts with semantic web tools, efforts are underway to represent them using the W3C Web Ontology Language (OWL). See the NeXusOntology for more details.</p>"},{"location":"reference/plugins.html","title":"Plugins","text":"<p>There are a number of plugins available for pynxtools that are maintained within FAIRmat. These are extensions of pynxtools used for reading data of specific experimental techniques and/or file formats.</p>"},{"location":"reference/plugins.html#photoemission-spectroscopy","title":"Photoemission spectroscopy","text":"<ul> <li>pynxtools-mpes: A reader for multi-dimensional photoelectron spectroscopy (MPES) data.</li> <li>pynxtools-xps: A reader for X-ray photoelectron spectroscopy (XPS) data from various vendors. Documentation can be found here.</li> </ul>"},{"location":"reference/plugins.html#electron-microscopy","title":"Electron microscopy","text":"<ul> <li>pynxtools-em: A reader for electron microscopy data from various vendors. Documentation can be found here.</li> </ul>"},{"location":"reference/plugins.html#atom-probe-tomography","title":"Atom probe tomography","text":"<ul> <li>pynxtools-apm: A reader for atom probe as well as related field ion microscopy data. Documentation can be found here.</li> </ul>"},{"location":"reference/plugins.html#optical-spectroscopy","title":"Optical spectroscopy","text":"<ul> <li>pynxtools-ellips: A reader for ellipsometry data. Documentation can be found here.</li> <li>pynxtools-raman: A reader for Raman data.</li> </ul>"},{"location":"reference/plugins.html#scanning-probe-microscopy","title":"Scanning probe microscopy","text":"<ul> <li>pynxtools-spm: A reader for scanning tunneling microscopy (SPM) domain data (STM, STS and AFM).</li> </ul>"},{"location":"reference/plugins.html#x-ray-diffraction","title":"X-ray diffraction","text":"<ul> <li>pynxtools-xrd: A reader for X-ray diffraction data.</li> </ul>"},{"location":"reference/plugins.html#others","title":"Others","text":"<ul> <li>pynxtools-igor: A general reader for Igor Pro Binary Wave data. Documentation can be found here.</li> </ul>"},{"location":"reference/plugins.html#installation","title":"Installation","text":"<p>You can install each of the plugins together with pynxtools by passing the name of the plugin as an extra to the pip install call. For example, for the <code>pynxtools-mpes</code> plugin:</p> <pre><code>pip install pynxtools[mpes]\n</code></pre> <p>In addition, you can also install all of the pynxtools reader plugins which are maintained by FAIRmat by passing the <code>[convert]</code> extra to the pip install call:</p> <pre><code>pip install pynxtools[convert]\n</code></pre>"},{"location":"tutorial/converting-data-to-nexus.html","title":"Converting research data to NeXus","text":""},{"location":"tutorial/converting-data-to-nexus.html#who-is-this-tutorial-for","title":"Who is this tutorial for?","text":"<p>The document is for people who want to standardize their research data by converting their research data into a NeXus standardized format. We cover the basic principles and common principles of NeXus, here. For a more detailed description on the general principles of NeXus we recommend reading our learning page for NeXus or the official NeXus user manual.</p>"},{"location":"tutorial/converting-data-to-nexus.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<ul> <li>You should have a basic understanding of NeXus - A primer on NeXus</li> <li>You should have a basic understanding of FAIR data</li> </ul>"},{"location":"tutorial/converting-data-to-nexus.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will have</p> <ul> <li>a basic understanding how to use the NeXus data converter from the pynxtools package</li> </ul>"},{"location":"tutorial/converting-data-to-nexus.html#setup","title":"Setup","text":"<p>We use a Python tool to make converting our research data easier. This has a number of readers that support multiple file formats. You can browse the separate folders to find the reader that might work for you. A generic reader is the JSON Map Reader. In addition, we provide multiple reader plugins for different experimental techniques.</p> <p>We will use the XPS reader plugin with a SpecsLabProdigy file (file extension: .sle) as an example.</p>"},{"location":"tutorial/converting-data-to-nexus.html#steps","title":"Steps","text":"<ol> <li>Download the example files from here: Example files</li> <li>Extract the zip and copy the files in your current working directory. You can find the working directory by typing the following in your terminal: <pre><code>pwd\n</code></pre></li> <li>Install pynxtools with the XPS reader plugin: <pre><code>pip install pynxtools[xps]\n</code></pre></li> <li>Verify you can run the <code>dataconverter</code> in a terminal window. Open a terminal with the Python environment where you installed <code>pynxtools</code>. Then type the following: <pre><code>dataconverter --help\n</code></pre></li> </ol>"},{"location":"tutorial/converting-data-to-nexus.html#converting-the-example-files","title":"Converting the example files","text":"<p>Once you have your files copied into the working directory, your directory structure should look like this: <pre><code>\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 EX439_S718_Au.sle\n\u251c\u2500\u2500 eln_data_sle.yaml\n\u2514\u2500\u2500 params.yaml\n</code></pre></p> <p>The <code>eln_data_sle.yaml</code> YAML file is another data file containing additional information (e.g., information about the experimentator) that is not provided in the main data file.</p> <p>Next, you will run the conversion routine from your Python environment: <pre><code>dataconverter --params-file params.yaml\n</code></pre></p> <p>Here we use a <code>params.yaml</code> parameter file to configure the converter.  This will create a file called <code>Au_25_mbar_O2_no_align.nxs</code> in your current directory.</p> <p>Congrats! You now have a FAIR NeXus file!</p> <p>You can try out other examples from pynxtools.</p>"},{"location":"tutorial/nexus-to-nomad.html","title":"Uploading NeXus files to NOMAD","text":"<p>Great choice! NOMAD makes it easier than ever to work with your research data. At this point you probably have an idea of what FAIR data is. Even if you don't, it doesn't matter. NOMAD provides a simple graphical interface that let's you collect and have your data ready for publication.</p> <p>In this tutorial, we will go through how one can upload their NeXus files to NOMAD.</p> <p>NOMAD, as a FAIR data platform, supports NeXus and allows users to upload their NeXus (.nxs) files directly. These files get interpreted and added to your NOMAD account with complete control on how you would like to present and publish them alongside your research.</p>"},{"location":"tutorial/nexus-to-nomad.html#create-an-account","title":"Create an account","text":"<p>The very first thing you need to do is get a NOMAD account. If you don't have one you can register here.</p> <ol> <li>Navigate to nomad-lab.eu</li> <li>Click on <code>Login / Register</code> on the top right corner.</li> </ol> <p></p>"},{"location":"tutorial/nexus-to-nomad.html#create-an-upload","title":"Create an Upload","text":"<p>NOMAD allows you to have a draft working space called an upload. This allows you to test and prepare how your data will look in NOMAD before you publish it.</p> <p>Go to <code>Publish -&gt; Uploads</code></p> <p></p> <p></p> <p>Click <code>Create a new upload</code></p> <p></p>"},{"location":"tutorial/nexus-to-nomad.html#upload-your-nexus-file","title":"Upload your NeXus file","text":"<p>Now we can upload your FAIR NeXus file and let NOMAD interpret it for us.</p> <p>Click the <code>Drop files here...</code> button and choose your NeXus file from your device. </p> <p>Once NOMAD has interpreted your data, this is what your screen will look like.</p> <p></p>"},{"location":"tutorial/nexus-to-nomad.html#browsing-your-nexus-data","title":"Browsing your NeXus data","text":"<p>You can find the NOMAD interpretation of your data under entries. If you click on this arrow, you will be able to see an Overview of your NeXus file.</p> <p></p> <p></p> <p>On the Overview page you will be presented with <code>H5Web</code> that let's you browse the data in your <code>NeXus</code> file directly.</p> <p></p> <p></p> <p>NOMAD also interprets and <code>normalizes</code> this data to make it interoperable with other corners of Material's research. To browse this <code>normalized</code> data you can browse the <code>DATA</code> tab. Here you see all the information NOMAD has picked up and made available for search and comparison with synthesis, experimental, and computational materials data.</p> <p></p> <p>Feel free to explore more!</p>"}]}