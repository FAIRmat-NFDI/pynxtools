{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad4167a-e4e7-498d-909a-c04da9f177ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Postprocessing Multidimensional Photoemission Spectroscopy (MPES) data and converting it into the NeXus format\n",
    "\n",
    "In this example, we pull data from a time-resolved ARPES on WSe2 measurement from Zenodo, and load it into the sed package using functions of the mpes package. Then, we run a conversion pipeline on it, containing steps for visualizing the channels, correcting image distortions, calibrating the momentum space, correcting for energy distortions and calibrating the energy axis. Finally, the data are binned in calibrated axes and stored in the standardised [MPES NExus format](https://fairmat-nfdi.github.io/nexus_definitions/classes/contributed_definitions/NXmpes.html#nxmpes).\n",
    "For performance reasons, best store the data on a locally attached storage (no network drive). This can also be achieved transparently using the included MirrorUtil class.\n",
    "\n",
    "This example works on a rather large dataset (~6GB) and hence it takes some time and resources to execute. If you just want to learn how to convert already processed data in an xarray based h5 file into the NeXus format you may have a look at the simpler [Convert to NeXus example](./E1%20Convert%20to%20NeXus.ipynb), which is runs quicker and has lower requirements.\n",
    "\n",
    "Further information on the postprocessing pipeline can be found in the [documentation of sed](https://opencompes.github.io/sed/) or in [R.P. Xian et al., Sci Data 7, 442 (2020)](https://www.nature.com/articles/s41597-020-00769-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb045e17-fa89-4c11-9d51-7f06e80d96d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sed\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f092b-df92-4abb-b00c-444f0351efd3",
   "metadata": {},
   "source": [
    "## Download RAW data (trARPES data of WSe2)\n",
    "\n",
    "Here, we just set the main file folder for holding the measurement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a45c3-b8d0-4aa0-8469-f2c641fdb236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FDIR = f'{os.getcwd()}/data/Scan049_1'\n",
    "ECAL = f'{os.getcwd()}/data/energycal_2019_01_08'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd67d7-2a2b-42ec-ba9e-28c1e64d6dce",
   "metadata": {},
   "source": [
    "Since the provided measurement files are rather large (~6GB), they are not directly provided with the example.\n",
    "You can [download](https://zenodo.org/record/6369728/files/WSe2.zip) it from zenodo. This may take some time. Place the file in the directory of this notebook afterwards. Under Linux, macOS and in a NORTH container you can directly use the cell below to download the file with curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334632d0-84d1-46fe-a4c0-3966feb1e69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! curl -o WSe2.zip \"https://zenodo.org/records/6369728/files/WSe2.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a6c18-a6c6-417f-b016-1c7e11fe9116",
   "metadata": {},
   "source": [
    "Now we extract the measurement files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c9e03-7f8a-4917-97f9-bf94fc36270e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! unzip WSe2.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6afaa-17dd-4637-ba75-a28c4ead1adf",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906abf04-6232-4b72-90f1-3843d51b5108",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "# manual Meta data. These should ideally come from an Electronic Lab Notebook.\n",
    "#General\n",
    "metadata['experiment_summary'] = 'WSe2 XUV NIR pump probe data.'\n",
    "metadata['entry_title'] = 'Valence Band Dynamics - 800 nm linear s-polarized pump, 0.6 mJ/cm2 absorbed fluence'\n",
    "metadata['experiment_title'] = 'Valence band dynamics of 2H-WSe2'\n",
    "\n",
    "#User\n",
    "# Fill general parameters of NXuser\n",
    "# TODO: discuss how to deal with multiple users?\n",
    "metadata['user0'] = {}\n",
    "metadata['user0']['name'] = 'Julian Maklar'\n",
    "metadata['user0']['role'] = 'Principal Investigator'\n",
    "metadata['user0']['affiliation'] = 'Fritz Haber Institute of the Max Planck Society'\n",
    "metadata['user0']['address'] = 'Faradayweg 4-6, 14195 Berlin'\n",
    "metadata['user0']['email'] = 'maklar@fhi-berlin.mpg.de'\n",
    "\n",
    "#NXinstrument\n",
    "metadata['instrument'] = {}\n",
    "metadata['instrument']['energy_resolution'] = 140.\n",
    "#analyzer\n",
    "metadata['instrument']['analyzer']={}\n",
    "metadata['instrument']['analyzer']['slow_axes'] = \"delay\" # the scanned axes\n",
    "metadata['instrument']['analyzer']['spatial_resolution'] = 10.\n",
    "metadata['instrument']['analyzer']['energy_resolution'] = 110.\n",
    "metadata['instrument']['analyzer']['momentum_resolution'] = 0.08\n",
    "metadata['instrument']['analyzer']['working_distance'] = 4.\n",
    "metadata['instrument']['analyzer']['lens_mode'] = \"6kV_kmodem4.0_30VTOF.sav\"\n",
    "\n",
    "#probe beam\n",
    "metadata['instrument']['beam']={}\n",
    "metadata['instrument']['beam']['probe']={}\n",
    "metadata['instrument']['beam']['probe']['incident_energy'] = 21.7\n",
    "metadata['instrument']['beam']['probe']['incident_energy_spread'] = 0.11\n",
    "metadata['instrument']['beam']['probe']['pulse_duration'] = 20.\n",
    "metadata['instrument']['beam']['probe']['frequency'] = 500.\n",
    "metadata['instrument']['beam']['probe']['incident_polarization'] = [1, 1, 0, 0] # p pol Stokes vector\n",
    "metadata['instrument']['beam']['probe']['extent'] = [80., 80.]\n",
    "#pump beam\n",
    "metadata['instrument']['beam']['pump']={}\n",
    "metadata['instrument']['beam']['pump']['incident_energy'] = 1.55\n",
    "metadata['instrument']['beam']['pump']['incident_energy_spread'] = 0.08\n",
    "metadata['instrument']['beam']['pump']['pulse_duration'] = 35.\n",
    "metadata['instrument']['beam']['pump']['frequency'] = 500.\n",
    "metadata['instrument']['beam']['pump']['incident_polarization'] = [1, -1, 0, 0] # s pol Stokes vector\n",
    "metadata['instrument']['beam']['pump']['incident_wavelength'] = 800.\n",
    "metadata['instrument']['beam']['pump']['average_power'] = 300.\n",
    "metadata['instrument']['beam']['pump']['pulse_energy'] = metadata['instrument']['beam']['pump']['average_power']/metadata['instrument']['beam']['pump']['frequency']#ÂµJ\n",
    "metadata['instrument']['beam']['pump']['extent'] = [230., 265.]\n",
    "metadata['instrument']['beam']['pump']['fluence'] = 0.15\n",
    "\n",
    "#sample\n",
    "metadata['sample']={}\n",
    "metadata['sample']['preparation_date'] = '2019-01-13T10:00:00+00:00'\n",
    "metadata['sample']['preparation_description'] = 'Cleaved'\n",
    "metadata['sample']['sample_history'] = 'Cleaved'\n",
    "metadata['sample']['chemical_formula'] = 'WSe2'\n",
    "metadata['sample']['description'] = 'Sample'\n",
    "metadata['sample']['name'] = 'WSe2 Single Crystal'\n",
    "\n",
    "metadata['file'] = {}\n",
    "metadata['file'][\"trARPES:Carving:TEMP_RBV\"] = 300.\n",
    "metadata['file'][\"trARPES:XGS600:PressureAC:P_RD\"] = 5.e-11\n",
    "metadata['file'][\"KTOF:Lens:Extr:I\"] = -0.12877\n",
    "metadata['file'][\"KTOF:Lens:UDLD:V\"] = 399.99905\n",
    "metadata['file'][\"KTOF:Lens:Sample:V\"] = 17.19976\n",
    "metadata['file'][\"KTOF:Apertures:m1.RBV\"] = 3.729931\n",
    "metadata['file'][\"KTOF:Apertures:m2.RBV\"] = -5.200078\n",
    "metadata['file'][\"KTOF:Apertures:m3.RBV\"] = -11.000425\n",
    "\n",
    "# Sample motor positions\n",
    "metadata['file']['trARPES:Carving:TRX.RBV'] = 7.1900000000000004\n",
    "metadata['file']['trARPES:Carving:TRY.RBV'] = -6.1700200225439552\n",
    "metadata['file']['trARPES:Carving:TRZ.RBV'] = 33.4501953125\n",
    "metadata['file']['trARPES:Carving:THT.RBV'] = 423.30500940561586\n",
    "metadata['file']['trARPES:Carving:PHI.RBV'] = 0.99931647456264949\n",
    "metadata['file']['trARPES:Carving:OMG.RBV'] = 11.002500171914066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9e4a2-e6fd-4ab0-bd55-417cc3995e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = '.'\n",
    "data_path = f'{base_path}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f82054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The Scan directory\n",
    "fdir = data_path + '/Scan049_1'\n",
    "# create sed processor using the config file:\n",
    "sp = sed.SedProcessor(\n",
    "    folder=fdir,\n",
    "    config=f\"{base_path}/sed_config/mpes_example_config.yaml\",\n",
    "    metadata=metadata,\n",
    "    collect_metadata=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0a3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply jittering to X, Y, t, ADC columns.\n",
    "# Columns are defined in the config, or can be provided as list.\n",
    "sp.add_jitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d336b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot of the count rate through the scan\n",
    "rate, secs = sp.loader.get_count_rate(range(100))\n",
    "plt.plot(secs, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb42777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The time elapsed in the scan\n",
    "sp.loader.get_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb074f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect data in dataframe Columns:\n",
    "# axes = ['X', 'Y', 't', 'ADC']\n",
    "# bins = [100, 100, 100, 100]\n",
    "# ranges = [(0, 1800), (0, 1800), (130000, 140000), (0, 9000)]\n",
    "# sp.view_event_histogram(dfpid=1, axes=axes, bins=bins, ranges=ranges)\n",
    "sp.view_event_histogram(dfpid=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa4343",
   "metadata": {},
   "source": [
    "## Distortion correction and Momentum Calibration workflow\n",
    "### Distortion correction\n",
    "#### 1. step: \n",
    "Bin and load part of the dataframe in detector coordinates, and choose energy plane where high-symmetry points can well be identified. Either use the interactive tool, or pre-select the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf8aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sp.bin_and_load_momentum_calibration(df_partitions=20, plane=170)\n",
    "sp.bin_and_load_momentum_calibration(df_partitions=100, plane=33, width=10, apply=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3ca76",
   "metadata": {},
   "source": [
    "#### 2. Step:\n",
    "Next, we select a number of features corresponding to the rotational symmetry of the material, plus the center. These can either be auto-detected (for well-isolated points), or provided as a list (these can be read-off the graph in the cell above).\n",
    "These are then symmetrized according to the rotational symmetry, and a spline-warping correction for the x/y coordinates is calculated, which corrects for any geometric distortions from the perfect n-fold rotational symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9666c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#features = np.array([[203.2, 341.96], [299.16, 345.32], [350.25, 243.70], [304.38, 149.88], [199.52, 152.48], [154.28, 242.27], [248.29, 248.62]])\n",
    "#sp.define_features(features=features, rotation_symmetry=6, include_center=True, apply=True)\n",
    "# Manual selection: Use a GUI tool to select peaks:\n",
    "#sp.define_features(rotation_symmetry=6, include_center=True)\n",
    "#sp.generate_splinewarp(rotation_symmetry=6, include_center=True, fwhm=10, sigma=12, sigma_radius=4)\n",
    "# Autodetect: Uses the DAOStarFinder routine to locate maxima.\n",
    "# Parameters are:\n",
    "#   fwhm: Full-width at half maximum of peaks.\n",
    "#   sigma: Number of standard deviations above the mean value of the image peaks must have.\n",
    "#   sigma_radius: number of standard deviations around a peak that peaks are fitted\n",
    "sp.define_features(rotation_symmetry=6, auto_detect=True, include_center=True, fwhm=10, sigma=12, sigma_radius=4, apply=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7519ff8",
   "metadata": {},
   "source": [
    "#### 3. Step: \n",
    "Generate nonlinear correction using splinewarp algorithm. If no landmarks have been defined in previous step, default parameters from the config are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cd7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option whether a central point shall be fixed in the determiantion fo the correction\n",
    "sp.generate_splinewarp(include_center=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4211ac21",
   "metadata": {},
   "source": [
    "#### Optional (Step 3a): \n",
    "Save distortion correction parameters to configuration file in current data folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated distortion correction parameters for later reuse\n",
    "sp.save_splinewarp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e69ffa",
   "metadata": {},
   "source": [
    "#### 4. Step:\n",
    "To adjust scaling, position and orientation of the corrected momentum space image, you can apply further affine transformations to the distortion correction field. Here, first a postential scaling is applied, next a translation, and finally a rotation around the center of the image (defined via the config). One can either use an interactive tool, or provide the adjusted values and apply them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abfa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp.pose_adjustment(xtrans=14, ytrans=18, angle=2)\n",
    "sp.pose_adjustment(xtrans=8, ytrans=7, angle=-4, apply=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a68e9",
   "metadata": {},
   "source": [
    "#### 5. Step:\n",
    "Finally, the momentum correction is applied to the dataframe, and corresponding meta data are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.apply_momentum_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9810488",
   "metadata": {},
   "source": [
    "### Momentum calibration workflow\n",
    "#### 1. Step:\n",
    "First, the momentum scaling needs to be calibtrated. Either, one can provide the coordinates of one point outside the center, and provide its distane to the Brillouin zone center (which is assumed to be located in the center of the image), one can specify two points on the image and their distance (where the 2nd point marks the BZ center),or one can provide absolute k-coordinates of two distinct momentum points.\n",
    "\n",
    "If no points are provided, an interactive tool is created. Here, left mouse click selectes the off-center point (brillouin_zone_cetnered=True) or toggle-selects the off-center and center point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_distance = 2/np.sqrt(3)*np.pi/3.28 # k-distance of the K-point in a hexagonal Brilloiun zone\n",
    "#sp.calibrate_momentum_axes(k_distance = k_distance)\n",
    "point_a = [308, 345]\n",
    "sp.calibrate_momentum_axes(point_a=point_a, k_distance = k_distance, apply=True)\n",
    "#point_b = [247, 249]\n",
    "#sp.calibrate_momentum_axes(point_a=point_a, point_b = point_b, k_coord_a = [.5, 1.1], k_coord_b = [1.3, 0], equiscale=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3697b1",
   "metadata": {},
   "source": [
    "##### Optional (Step 1a): \n",
    "Save momentum calibration parameters to configuration file in current data folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bedfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated momentum calibration parameters for later reuse\n",
    "sp.save_momentum_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8a513",
   "metadata": {},
   "source": [
    "#### 2. Step:\n",
    "Now, the distortion correction and momentum calibration needs to be applied to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.apply_momentum_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce2388",
   "metadata": {},
   "source": [
    "## Energy Correction (optional)\n",
    "The purpose of the energy correction is to correct for any momentum-dependent distortion of the energy axis, e.g. from geometric effects in the flight tube, or from space charge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5289de59",
   "metadata": {},
   "source": [
    "#### 1st step:\n",
    "Here, one can select the functional form to be used, and adjust its parameters. The binned data used for the momentum calibration is plotted around the Fermi energy (defined by tof_fermi), and the correction function is plotted ontop. Possible correction functions are: \"sperical\" (parameter: diameter), \"Lorentzian\" (parameter: gamma), \"Gaussian\" (parameter: sigma), and \"Lorentzian_asymmetric\" (parameters: gamma, amplitude2, gamma2).\n",
    "\n",
    "One can either use an interactive alignment tool, or provide parameters directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp.adjust_energy_correction(amplitude=2.5, center=(730, 730), gamma=920, tof_fermi = 66200)\n",
    "sp.adjust_energy_correction(amplitude=2.5, center=(730, 730), gamma=920, tof_fermi = 66200, apply=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fbf33",
   "metadata": {},
   "source": [
    "##### Optional (Step 1a): \n",
    "Save energy correction parameters to configuration file in current data folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated energy correction parameters for later reuse\n",
    "sp.save_energy_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6a3e6",
   "metadata": {},
   "source": [
    "#### 2. Step\n",
    "After adjustment, the energy correction is directly applied to the TOF axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.apply_energy_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b571b4c",
   "metadata": {},
   "source": [
    "## 3. Energy calibration\n",
    "For calibrating the energy axis, a set of data taken at different bias voltages around the value where the measurement was taken is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc28642",
   "metadata": {},
   "source": [
    "#### 1. Step:\n",
    "In a first step, the data are loaded, binned along the TOF dimension, and normalized. The used bias voltages can be either provided, or read from attributes in the source files if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load energy calibration EDCs\n",
    "energycalfolder = data_path + \"/energycal_2019_01_08/\"\n",
    "scans = np.arange(1,12)\n",
    "voltages = np.arange(12,23,1)\n",
    "files = [energycalfolder + r'Scan' + str(num).zfill(3) + '_' + str(num+11) + '.h5' for num in scans]\n",
    "sp.load_bias_series(data_files=files, normalize=True, biases=voltages, ranges=[(64000, 75000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a79c8",
   "metadata": {},
   "source": [
    "#### 2. Step:\n",
    "Next, the same peak or feature needs to be selected in each curve. For this, one needs to define \"ranges\" for each curve, within which the peak of interest is located. One can either provide these ranges manually, or provide one range for a \"reference\" curve, and infer the ranges for the other curves using a dynamic time warping algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f843244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 = specify the ranges containing a common feature (e.g an equivalent peak) for all bias scans\n",
    "# rg = [(129031.03103103103, 129621.62162162163), (129541.54154154155, 130142.14214214214), (130062.06206206206, 130662.66266266267), (130612.61261261262, 131213.21321321322), (131203.20320320321, 131803.8038038038), (131793.7937937938, 132384.38438438438), (132434.43443443443, 133045.04504504506), (133105.10510510512, 133715.71571571572), (133805.8058058058, 134436.43643643643), (134546.54654654654, 135197.1971971972)]\n",
    "# sp.find_bias_peaks(ranges=rg, infer_others=False)\n",
    "# Option 2 = specify the range for one curve and infer the others\n",
    "# This will open an interactive tool to select the correct ranges for the curves.\n",
    "# IMPORTANT: Don't choose the range too narrow about a peak, and choose a refid\n",
    "# somewhere in the middle or towards larger biases!\n",
    "rg = (66100, 67000)\n",
    "sp.find_bias_peaks(ranges=rg, ref_id=5, infer_others=True, apply=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2638818",
   "metadata": {},
   "source": [
    "#### 3. Step:\n",
    "Next, the detected peak positions and bias voltages are used to determine the calibration function. This can be either done by fitting the functional form d^2/(t-t0)^2 via lmfit (\"lmfit\"), or using a polynomial approxiamtion (\"lstsq\" or \"lsqr\"). Here, one can also define a reference id, and a reference energy. Those define the absolute energy position of the feature used for calibration in the \"reference\" trace, at the bias voltage where the final measurement has been performed. The energy scale can be either \"kientic\" (decreasing energy with increasing TOF), or \"binding\" (increasing energy with increasing TOF).\n",
    "\n",
    "After calculating the calibration, all traces corrected with the calibration are plotted ontop of each other, the calibration function together with the extracted features is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e15f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the refid of the bias that the measurement was taken at\n",
    "# Eref can be used to set the absolute energy (kinetic energy, E-EF) of the feature used for energy calibration (if known)\n",
    "refid=4\n",
    "Eref=-0.5\n",
    "# the lmfit method uses a fit of (d/(t-t0))**2 to determine the energy calibration\n",
    "sp.calibrate_energy_axis(ref_energy=Eref, ref_id=refid, energy_scale=\"kinetic\", method=\"lmfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63c6c7",
   "metadata": {},
   "source": [
    "##### Optional (Step 3a): \n",
    "Save energy calibration parameters to configuration file in current data folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated energy calibration parameters for later reuse\n",
    "sp.save_energy_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563709c7",
   "metadata": {},
   "source": [
    "#### 4. Step:\n",
    "Finally, the the energy axis is added to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.append_energy_axis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8cdf9",
   "metadata": {},
   "source": [
    "## 4. Delay calibration:\n",
    "The delay axis is calculated from the ADC input column based on the provided delay range. ALternatively, the delay scan range can also be extracted from attributes inside a source file, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pathlib import Path\n",
    "#datafile = \"file.h5\"\n",
    "#print(datafile)\n",
    "#sp.calibrate_delay_axis(datafile=datafile)\n",
    "delay_range = (-500, 1500)\n",
    "sp.calibrate_delay_axis(delay_range=delay_range, preview=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0b018",
   "metadata": {},
   "source": [
    "## 5. Visualization of calibrated histograms\n",
    "With all calibrated axes present in the dataframe, we can visualize the corresponding histograms, and determine the respective binning ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ['kx', 'ky', 'energy', 'delay']\n",
    "ranges = [[-3, 3], [-3, 3], [-6, 2], [-600, 1600]]\n",
    "sp.view_event_histogram(dfpid=1, axes=axes, ranges=ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902fd56-1456-4da6-83a4-0f3f6b831eb6",
   "metadata": {},
   "source": [
    "## Define the binning ranges and compute calibrated data volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7601cd7-cd51-40a9-8fc7-8b7d32ff15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ['kx', 'ky', 'energy', 'delay']\n",
    "bins = [100, 100, 200, 50]\n",
    "ranges = [[-2, 2], [-2, 2], [-4, 2], [-600, 1600]]\n",
    "res = sp.compute(bins=bins, axes=axes, ranges=ranges, normalize_to_acquisition_time=\"delay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523794dc",
   "metadata": {},
   "source": [
    "## Some visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7d136-b677-4c16-bc8f-31ba8216579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(6, 18), constrained_layout=True)\n",
    "res.loc[{'energy':slice(-.1, 0)}].sum(axis=(2,3)).T.plot(ax=axs[0])\n",
    "res.loc[{'kx':slice(-.8, -.5)}].sum(axis=(0,3)).T.plot(ax=axs[1])\n",
    "res.loc[{'ky':slice(-.2, .2)}].sum(axis=(1,3)).T.plot(ax=axs[2])\n",
    "res.loc[{'kx':slice(-.8, -.5), 'energy':slice(.5, 2)}].sum(axis=(0,1)).plot(ax=axs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to NXmpes NeXus (including standardized metadata)\n",
    "sp.save(\"WSe2.nxs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bb6c9-cfea-4987-8ac1-8d2884dd11f3",
   "metadata": {},
   "source": [
    "## View the data with H5Web\n",
    "H5Web is a tool for visualizing any data in the h5 data format. Since the NeXus format builds opon h5 it can be used to view this data as well. We just import the package and call H5Web with the output filename from the convert command above. For an analysis on NeXus data files please refer to [analysis example](./E3%20pyARPES%20analysis.ipynb).\n",
    "\n",
    "You can also view this data with the H5Viewer or other tools from your local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35934a0f-b7bd-4fd4-bcda-054cc2f034f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jupyterlab_h5web import H5Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc16e59-4c61-4530-87b7-786e60c990b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "H5Web('WSe2.nxs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0940aee-f887-4b60-b70d-23f231bede20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "728003ee06929e5fa5ff815d1b96bf487266025e4b7440930c6bf4536d02d243"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "undefined": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_view_name": "ErrorWidgetView",
       "error": {},
       "msg": "Model class 'VBoxModel' from module '@jupyter-widgets/controls' is loaded but can not be instantiated"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
