{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1aea0-545b-446b-a3d1-1574af72f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rsciio import bruker, emd, digitalmicrograph\n",
    "from jupyterlab_h5web import H5Web\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import xraydb\n",
    "from ase.data import chemical_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889c47f-11c4-4bf3-97de-04fc52f0798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"/home/kaiobach/Research/paper_paper_paper/scidat_nomad_ebsd/bb_analysis/data/development_spctrscpy\"\n",
    "fnms = [(\"pdi\", \"InGaN_nanowires_spectra.edaxh5\"),\n",
    "        (\"ikz\", \"AlGaO.nxs\"),\n",
    "        (\"ikz\", \"GeSi.nxs\"),\n",
    "        (\"ikz\", \"GeSn_13.nxs\"),\n",
    "        (\"ikz\", \"VInP_108_L2.h5\"),\n",
    "        (\"bruker\", \"pynx/46_ES-LP_L1_brg.bcf\"),\n",
    "        (\"emd\", \"pynx/1613_Si_HAADF_610_kx.emd\"),\n",
    "        (\"digitalmicrograph\", \"pynx/EELS_map_2_ROI_1_location_4.dm3\"),\n",
    "        (\"oxfordinstruments\", \"pynx/H5OINA_examples_Specimen_1_Map_EDS_+_EBSD_Map_Data_2.h5oina\")]\n",
    "# pyUSID, HSMA\n",
    "case = 2 # len(fnms) - 1  # len(fnms) - 1\n",
    "fnm = f\"{src}/{fnms[case][0]}/{fnms[case][1]}\"\n",
    "print(fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9ef96-3c70-4c12-80ba-ea4a7d716d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5Web(fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221abf67-0d88-4088-9cc7-e0d9b85c4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5Web(f\"debug.{fnms[case][1]}.nxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b883a7a-f6aa-4151-8ee4-f3c8c79ccc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fnm, \"r\") as h5r:\n",
    "    src = \"/VInP/VInP_108_L2/Area 10/Live Map 1\"  # /ROIs/InL.dat\"\n",
    "    tmp = h5r[f\"{src}/ELEMENTOVRLAYIMGCOLLECTIONPARAMS\"][0][\"ResolutionX\"]\n",
    "    # tmp = h5r[f\"{src}\"]\n",
    "    # for key in h5r[src].keys():\n",
    "    #     tmp = h5r[f\"{src}/{key}\"]\n",
    "    print(f\"{type(tmp)}, {np.shape(tmp)}, {tmp.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99588fe-67dc-48df-8d60-28187d8daa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fnm, \"r\") as h5r:\n",
    "    # src = \"/InGaN_nanowires_spectra/InGaN nanowires/Area 1/Full Area 1\"\n",
    "    src = \"/VInP/VInP_108_L2/Area 10/LineScan 1/\"\n",
    "    if f\"{src}/LSD\" in h5r.keys():\n",
    "        # for key, val in enumerate(h5r[f\"{src}/LSD\"].attrs.items()):\n",
    "        #     print(f\"{key}, {val}\")\n",
    "        tmp = np.asarray(h5r[f\"{src}/LSD\"][0])\n",
    "        print(f\"{type(tmp)}, {np.shape(tmp)}, {tmp.dtype}\")\n",
    "        for idx in np.arange(0, 2):\n",
    "            # src/ROIs/<element Xray line> is the integral\n",
    "            print(f\"{idx}\\t\\tIn L\\t\\t{np.sum(tmp[idx,323:335 + 1])}\")\n",
    "            print(f\"{idx}\\t\\tK K\\t\\t{np.sum(tmp[idx,326:337 + 1])}\")\n",
    "            print(f\"{idx}\\t\\tP K\\t\\t{np.sum(tmp[idx,197:206 + 1])}\")\n",
    "        # plt.plot(np.arange(323, 335 + 1), tmp[0,323:335 + 1])\n",
    "        plt.plot(np.arange(197, 206 + 1), tmp[0,197:206 + 1])\n",
    "    # for idx, val in enumerate(tmp.dtype.names):\n",
    "    #     print(f\"{idx}, {val}, {tmp[val][0]}\")\n",
    "\n",
    "    \"\"\"\n",
    "    if f\"{src}/SPC\" in h5r.keys():\n",
    "        spc = np.asarray(h5r[f\"{src}/SPC\"])\n",
    "    # print(f\"{type(spc)}, {np.shape(spc)}, {spc.dtype}\")\n",
    "    reqs = [\"eVOffset\", \"evPch\"]  # , \"evPerChannel\", \"DeadTime\", \"CountRate\"]\n",
    "    for req in reqs:  # \"\"SpectrumCounts\", \"\n",
    "        if req in spc.dtype.names:\n",
    "            print(f\"{req}, {spc[req][0]}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unable to find metadata entry {req}!\")\n",
    "    # for idx, val in enumerate(spc.dtype.names):\n",
    "    #     print(f\"{idx}, {val}, {spc[val][0]}\")\n",
    "    print(\"DataStart\" in spc.dtype.names)\n",
    "    print(f\"{type(spc['SpectrumCounts'][0])}, {np.shape(spc['SpectrumCounts'][0])}, {spc['SpectrumCounts'][0].dtype}\")  # [0])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58972c-dcd3-45ea-9fae-36c81de1ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dat[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441aaf8f-88df-47ea-9516-44f9666d717b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc341bf3-fefa-4a69-84d5-5abe576f2b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e721dee-7b6f-4dd0-b50e-ea8ff05d4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_lines = {}\n",
    "for symbol in chemical_symbols[1:]:\n",
    "    # print(f\"{symbol}\")\n",
    "    for name, line in xraydb.xray_lines(symbol).items():\n",
    "        xray_lines[f\"{symbol}-{name}\"] = line.energy\n",
    "        # print(f\"{name}, {line.energy} eV\")\n",
    "print(len(xray_lines))\n",
    "\n",
    "def get_xray_line_candidates(e_min=1200., e_max=1250.):\n",
    "    cand = []\n",
    "    for key, val in xray_lines.items():\n",
    "        if val < e_min:\n",
    "            continue\n",
    "        if val > e_max:\n",
    "            continue\n",
    "        cand.append(key)\n",
    "    return cand\n",
    "\n",
    "print(get_xray_line_candidates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7f9ac-1ade-43d7-aedd-b2572d163b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class NxObject:\n",
    "    \"\"\"An object in a graph e.g. an attribute, dataset, or group in NeXus.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name: str = None,\n",
    "                 unit: str = None,\n",
    "                 dtype=str,\n",
    "                 value=None,\n",
    "                 **kwargs):\n",
    "        if (name is not None) and (name == \"\"):\n",
    "            raise ValueError(f\"Value for argument name needs to be a non-empty string !\")\n",
    "        if (unit is not None) and (unit == \"\"):\n",
    "            raise ValueError(f\"Value for argument unit needs to be a non-empty string !\")\n",
    "        if (dtype is not None) and isinstance(dtype, type) is False:\n",
    "            raise ValueError(f\"Value of argument dtype must not be None \" \\\n",
    "                             f\" and a valid, ideally a numpy datatype !\")\n",
    "        # self.doc = None  # docstring\n",
    "        self.name = name  # name of the field\n",
    "        self.unit = unit  # not unit category but actual unit\n",
    "        # use special values \"unitless\" for NX_UNITLESS (e.g. 1) and\n",
    "        # \"dimensionless\" for NX_DIMENSIONLESS (e.g. 1m / 1m)\n",
    "        self.dtype = dtype  # use np.dtype if possible\n",
    "        if value is None or dtype is str:\n",
    "            self.unit = \"unitless\"\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "        # value should be a numpy scalar, tensor, or string if possible\n",
    "        self.eqv_hdf = None\n",
    "        if \"eqv_hdf\" in kwargs:\n",
    "            if kwargs[\"eqv_hdf\"] in [\"group\", \"dataset\", \"attribute\"]:\n",
    "                self.eqv_hdf = kwargs[\"eqv_hdf\"]\n",
    "            else:\n",
    "                raise ValueError(f\"Value of keyword argument eqv_hdf needs to be one of grp, dset, attr !\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Report values.\"\"\"\n",
    "        return f\"Name: {self.name}, unit: {self.unit}, dtype: {self.dtype}, eqv_hdf: {self.eqv_hdf}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3a10f-903a-4d7e-883b-779c6c34f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NX_IMAGE_REAL_SPACE_SET_HDF_PATH = [\"image_oned/axis_x-field\",\n",
    "\"image_oned/axis_x@long_name-attribute\",\n",
    "\"image_oned/intensity-field\",\n",
    "\"image_threed/axis_x-field\",\n",
    "\"image_threed/axis_x@long_name-attribute\",\n",
    "\"image_threed/axis_y-field\",\n",
    "\"image_threed/axis_y@long_name-attribute\",\n",
    "\"image_threed/axis_z-field\",\n",
    "\"image_threed/axis_z@long_name-attribute\",\n",
    "\"image_threed/intensity-field\",\n",
    "\"image_twod/axis_x-field\",\n",
    "\"image_twod/axis_x@long_name-attribute\",\n",
    "\"image_twod/axis_y-field\",\n",
    "\"image_twod/axis_y@long_name-attribute\",\n",
    "\"image_twod/intensity-field\",\n",
    "\"stack_oned/axis_image_identifier-field\",\n",
    "\"stack_oned/axis_image_identifier@long_name-attribute\",\n",
    "\"stack_oned/axis_x-field\",\n",
    "\"stack_oned/axis_x@long_name-attribute\",\n",
    "\"stack_oned/intensity-field\",\n",
    "\"stack_threed/axis_image_identifier-field\",\n",
    "\"stack_threed/axis_image_identifier@long_name-attribute\",\n",
    "\"stack_threed/axis_x-field\",\n",
    "\"stack_threed/axis_x@long_name-attribute\",\n",
    "\"stack_threed/axis_y-field\",\n",
    "\"stack_threed/axis_y@long_name-attribute\",\n",
    "\"stack_threed/axis_z-field\",\n",
    "\"stack_threed/axis_z@long_name-attribute\",\n",
    "\"stack_threed/intensity-field\",\n",
    "\"stack_twod/axis_image_identifier-field\",\n",
    "\"stack_twod/axis_image_identifier@long_name-attribute\",\n",
    "\"stack_twod/axis_x-field\",\n",
    "\"stack_twod/axis_x@long_name-attribute\",\n",
    "\"stack_twod/axis_y-field\",\n",
    "\"stack_twod/axis_y@long_name-attribute\",\n",
    "\"stack_twod/intensity-field\"]\n",
    "\n",
    "class NxEmImageRealSpaceSet():\n",
    "    def __init__(self):\n",
    "        self.tmp: Dict = {}\n",
    "        for entry in NX_IMAGE_REAL_SPACE_SET_HDF_PATH:\n",
    "            if entry.endswith(\"-field\") is True:\n",
    "                self.tmp[entry[0:len(entry)-len(\"-field\")]] = NxObject(eqv_hdf=\"dataset\")\n",
    "            elif entry.endswith(\"-attribute\") is True:\n",
    "                self.tmp[entry[0:len(entry)-len(\"-attribute\")]] = NxObject(eqv_hdf=\"attribute\")\n",
    "            else:\n",
    "                self.tmp[entry[0:len(entry)-len(\"-group\")]] = NxObject(eqv_hdf=\"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbaa03-0aac-43fb-941a-f63910496fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = NxEmImageRealSpaceSet()\n",
    "# print(tmp.tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58052fb7-723f-476d-a8ca-df99efffcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fnm, \"r\") as h5r:\n",
    "    src = \"/VInP/VInP_108_L2/Area 10/VInP/VInP_108_L2/Area 10/Live Map 1\"\n",
    "    if f\"{src}/FOVIMAGECOLLECTIONPARAMS\" in h5r.keys():\n",
    "        ipr = np.asarray(h5r[f\"{src}/FOVIPR\"])\n",
    "    print(f\"{type(ipr)}, {np.shape(ipr)}, {ipr.dtype}\")\n",
    "    print(ipr[\"MicronsPerPixelY\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5892cb-476e-453d-99e0-befb766fa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fnm, \"r\") as h5r:\n",
    "    src = \"/VInP/VInP_108_L2/Area 10/Live Map 1\"\n",
    "    trg = \"SPD\"\n",
    "    reqs = [\"MicronPerPixelX\", \"MicronPerPixelY\", \"NumberOfLines\", \"NumberOfPoints\", \"NumberofChannels\"]\n",
    "    for req in reqs:\n",
    "        if req not in h5r[f\"{src}/{trg}\"].attrs.keys():\n",
    "            # also check for shape\n",
    "            raise ValueError(f\"Required attribute named {req} not found in {src}/{trg} !\")\n",
    "    nyxe = {\"y\": h5r[f\"{src}/{trg}\"].attrs[\"NumberOfLines\"][0],\n",
    "            \"x\": h5r[f\"{src}/{trg}\"].attrs[\"NumberOfPoints\"][0],\n",
    "            \"e\": h5r[f\"{src}/{trg}\"].attrs[\"NumberofChannels\"][0]}\n",
    "    print(nyxe)\n",
    "    # the native APEX SPD concept instance is a two-dimensional array of arrays of length e (n_energy_bins)\n",
    "    # likely EDAX has in their C(++) code a vector of vector or something equivalent either way we faced\n",
    "    # nested C arrays of the base data type (here (u)int 16\n",
    "    # even worse, chunked in HDF5 thus the e-long arrays are just some payload inside the compressed\n",
    "    # chunk without some extra logic to resolve the third (energy) dimension:\n",
    "    # how to reshape this efficiently without creating unnecessary copies\n",
    "    # the following code is ugly as it needs a maximum large copy of the dataset\n",
    "    spd_edax = h5r[f\"{src}/{trg}\"]\n",
    "    print(f\"edax: {np.shape(spd_edax)}, {type(spd_edax)}, {spd_edax.dtype}\")\n",
    "    spd_naive = np.zeros((nyxe[\"y\"], nyxe[\"x\"], nyxe[\"e\"]), \"<i2\")\n",
    "    spd_chunk = np.zeros((nyxe[\"y\"], nyxe[\"x\"], nyxe[\"e\"]), \"<i2\")\n",
    "    # spd = spd_edax.view().reshape((400, 512, 1000))\n",
    "    \n",
    "    chk_one = [(0, 102), (102, 102 + 102), (102 + 102, 102 + 102 + 102), (102 + 102 + 102, 400)]\n",
    "    print(chk_one)\n",
    "    chk_two = [(0, 512), (0, 512), (0, 512), (0, 512)]\n",
    "    print(chk_two)\n",
    "    for chk_idx in np.arange(0, 4):\n",
    "        print(f\"{chk_idx}\")\n",
    "        spd_chunk[chk_one[chk_idx][0]:chk_one[chk_idx][1], chk_two[chk_idx][0]:chk_two[chk_idx][1], :] \\\n",
    "            = spd_edax[chk_one[chk_idx][0]:chk_one[chk_idx][1], chk_two[chk_idx][0]:chk_two[chk_idx][1]]\n",
    "    print(\"Chunking down\")   \n",
    "    for one in np.arange(0, 400):\n",
    "        print(f\"{one}\")\n",
    "        for two in np.arange(0, 512):\n",
    "            spd_naive[one, two, :] = spd_edax[one, two]\n",
    "    print(\"Naive done\")\n",
    "   \n",
    "    if False is True:        \n",
    "        img.tmp[\"image_twod/intensity\"] = np.reshape(np.asarray(h5r[f\"{src}/FOVIMAGE\"]), (nyx[\"y\"], nyx[\"x\"]))\n",
    "    \n",
    "        syx = {\"x\": 1., \"y\": 1.}\n",
    "        scan_unit = {\"x\": \"px\", \"y\": \"px\"}\n",
    "        if f\"{src}/FOVIMAGECOLLECTIONPARAMS\" in h5r.keys():\n",
    "            ipr = np.asarray(h5r[f\"{src}/FOVIPR\"])\n",
    "            syx = {\"x\": ipr[\"MicronsPerPixelX\"][0], \"y\": ipr[\"MicronsPerPixelY\"][0]}\n",
    "            scan_unit = {\"x\": \"µm\", \"y\": \"µm\"}\n",
    "        dims = [\"y\", \"x\"]\n",
    "        for dim in dims:\n",
    "            img.tmp[f\"image_twod/axis_{dim}\"] = np.asarray(np.linspace(0, nyx[dim] - 1, num=nyx[dim], endpoint=True) * syx[dim], np.float64)\n",
    "            img.tmp[f\"image_twod/axis_{dim}@long_name\"] = f\"Calibrated pixel position along {dim} ({scan_unit[dim]})\"\n",
    "    \n",
    "        for key, val in img.tmp.items():\n",
    "            if key.startswith(\"image_twod\"):\n",
    "                print(f\"{key}, {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d637cdc-0729-45aa-91f7-a12346307004",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = spd_chunk[0:10, :, :] - spd_naive[0:10, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc034d09-b089-4f85-a4a0-b0689d76108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fnm, \"r\") as h5r:\n",
    "    src = \"/VInP/VInP_108_L2/Area 10/Live Map 1\"\n",
    "    cps = h5r[f\"{src}/CPS\"]\n",
    "    print(cps.chunks)\n",
    "    spd = h5r[f\"{src}/SPD\"]\n",
    "    print(spd.chunks)\n",
    "    print(h5r[f\"{src}/SPD\"][0, 0].dtype)\n",
    "    spd_chunk = np.zeros((nyxe[\"y\"], nyxe[\"x\"], nyxe[\"e\"]), h5r[f\"{src}/SPD\"][0, 0].dtype)\n",
    "    print(spd_chunk.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b1022-beea-4996-ab06-b120531c3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_bnds = {\"x\": [], \"y\": []}\n",
    "ifo = {\"ny\": 400,\n",
    "       \"cy\": spd.chunks[0],\n",
    "       \"nx\": 512,\n",
    "       \"cx\": spd.chunks[1]}\n",
    "for dim in [\"y\", \"x\"]:\n",
    "    idx = 0\n",
    "    while idx < ifo[f\"n{dim}\"]:\n",
    "        if idx + ifo[f\"c{dim}\"] < ifo[f\"n{dim}\"]:\n",
    "            chk_bnds[f\"{dim}\"].append((idx, idx + ifo[f\"c{dim}\"]))\n",
    "        else:\n",
    "            chk_bnds[f\"{dim}\"].append((idx, ifo[f\"n{dim}\"]))\n",
    "        idx += ifo[f\"c{dim}\"]\n",
    "for key, val in chk_bnds.items():\n",
    "    print(f\"{key}, {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692b704-6a28-4e4c-a6b3-58864e0f98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #    plt.imshow(fov, interpolation='nearest')\n",
    "    #    plt.show()\n",
    "    #    print(f\"{type(cmpd)}, {np.shape(cmpd)}, {cmpd.dtype}\")\n",
    "    #    print(cmpd[\"DetectorLabel\"][0].decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570da751-a38c-4902-b929-ef32cf19b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_all_plugins = False\n",
    "if report_all_plugins is True:\n",
    "    for plugin in rsciio.IO_PLUGINS:\n",
    "        print(f\"\\n\\n\")\n",
    "        for key, val in plugin.items():\n",
    "            print(f\"{key}, {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5287d-7441-4141-b161-351de4bf7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = bruker.file_reader(f\"{src}/{fnms[2][1]}\")\n",
    "# objs = emd.file_reader(f\"{src}/{fnms[3][1]}\")\n",
    "# objs = digitalmicrograph.file_reader(f\"{src}/{fnms[4][1]}\")\n",
    "if isinstance(objs, list) is True:\n",
    "    for entry in objs:\n",
    "        print(f\"Loading type(entry) {type(entry)}\")\n",
    "        if isinstance(entry, dict) is True:\n",
    "            for key, val in entry.items():\n",
    "                print(key)\n",
    "                print(val)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b0a71-e9d8-460e-99b5-b12208b56258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b275f-bc59-4fbc-8c56-ae4d6e964d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f31e6c-1554-4476-8688-5f5323d513c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://codereview.stackexchange.com/a/21035\n",
    "# https://stackoverflow.com/questions/38852822/how-to-flatten-xml-file-in-python\n",
    "from collections import OrderedDict\n",
    "\n",
    "def flatten_dict(d):\n",
    "    def items():\n",
    "        for key, value in d.items():\n",
    "            # nested subtree\n",
    "            if isinstance(value, dict):\n",
    "                for subkey, subvalue in flatten_dict(value).items():\n",
    "                    yield '{}.{}'.format(key, subkey), subvalue\n",
    "            # nested list\n",
    "            elif isinstance(value, list):\n",
    "                for num, elem in enumerate(value):\n",
    "                    for subkey, subvalue in flatten_dict(elem).items():\n",
    "                        yield '{}.[{}].{}'.format(key, num, subkey), subvalue\n",
    "            # everything else (only leafs should remain)\n",
    "            else:\n",
    "                yield key, value\n",
    "    return OrderedDict(items())\n",
    "\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5cbb4-c5a2-44a1-b6a4-277167582869",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(fnm, mode=\"r\") as fp:\n",
    "    fp.load()  # Needed only for .png EXIF data (see citation above)\n",
    "    if \"MicroscopeControlImage\" in fp.info.keys():\n",
    "        # print(fp.info[\"MicroscopeControlImage\"])\n",
    "        xml_content = xmltodict.parse(fp.info[\"MicroscopeControlImage\"])\n",
    "        flattened_xml = flatten_dict(xml_content)\n",
    "        for k,v in flattened_xml.items():\n",
    "            print('{} = {}'.format(k,v))\n",
    "    elif fnm.lower().endswith(\".png\") is True:  # check for mime type instead\n",
    "        print(f\"There is no iTXt chunk in {fnm} which has embedded XML within the AXON namespace MicroscopeControlImage!\")\n",
    "    else:\n",
    "        print(f\"There is nothing to harvest here!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bf73d-66b7-414b-abb1-db99b2bf370a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963afb6-6e48-4628-a0e8-d2da0874701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle TIFF\n",
    "with Image.open(fnm, mode=\"r\") as fp:\n",
    "    for key in fp.tag_v2:\n",
    "        if key in [34118, 34119]:\n",
    "            print(type(fp.tag[key]))\n",
    "            print(len(fp.tag[key]))        \n",
    "            # print(f\"{key}, {fp.tag[key]}\")\n",
    "        if key not in TAGS.keys():\n",
    "            print(f\"--->tag {key}, is not in PIL.TiffTAGS !\")\n",
    "    # self.tags = {TAGS[key] : fp.tag[key] for key in fp.tag_v2}\n",
    "    # for key, val in self.tags.items():\n",
    "    #     print(f\"{key}, {val}\")\n",
    "    nparr = np.array(fp)\n",
    "    print(f\"{type(nparr)}\")\n",
    "    print(f\"{nparr.dtype}\")\n",
    "    print(f\"{np.shape(nparr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef2a35-a260-4a54-9b83-eae1d588966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(fnm, mode=\"r\") as fp:\n",
    "    if True is False:\n",
    "        czi_keys = [34118, 34119]\n",
    "        for czi_key in czi_keys:\n",
    "            if czi_key in fp.tag_v2:\n",
    "                print(f\"Found czi_key {tfs_key}...\")\n",
    "                utf = fp.tag[czi_key]\n",
    "                print(type(utf))\n",
    "                if len(utf) == 1:\n",
    "                    print(utf[0])\n",
    "    # exit(1)\n",
    "    tfs_keys = [34682]\n",
    "    for tfs_key in tfs_keys:\n",
    "        if tfs_key in fp.tag_v2:\n",
    "            print(f\"Found tfs_key {tfs_key}...\")\n",
    "            utf = fp.tag[tfs_key]\n",
    "            print(type(utf))\n",
    "            if len(utf) == 1:\n",
    "                print(utf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28687c0e-6f14-484c-b511-3a4906d9672e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ada062-e308-4288-8f00-b3e620f3c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# https://www.geeksforgeeks.org/python-program-to-sort-a-list-of-tuples-by-second-item/\n",
    "def sort_tuple(tup):\n",
    "    # convert the list of tuples to a numpy array with data type (object, int)\n",
    "    arr = np.array(tup, dtype=[('col1', object), ('col2', int)])\n",
    "    # get the indices that would sort the array based on the second column\n",
    "    indices = np.argsort(arr['col2'])\n",
    "    # use the resulting indices to sort the array\n",
    "    sorted_arr = arr[indices]\n",
    "    # convert the sorted numpy array back to a list of tuples\n",
    "    sorted_tup = [(row['col1'], row['col2']) for row in sorted_arr]\n",
    "    return sorted_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27df293-626c-4d37-80df-96c182d4f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_str_represents_float(s):\n",
    "    try:\n",
    "        return isinstance(float(s), float)\n",
    "        # return str(float(s)) == s\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647fa79-330b-48b2-8360-f92fc5ead187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"10\".isdigit()\n",
    "# isinstance(float(\"8.99306e-010\"), float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f0864-f8b3-4d53-bf9d-08a5787c32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFS sections based on IKZ ALN_baoh_021.tif example\n",
    "import mmap\n",
    "\n",
    "tfs_section_names = [\"[User]\",\n",
    "                     \"[System]\",\n",
    "                     \"[Beam]\",\n",
    "                     \"[EBeam]\",                 \n",
    "                     \"[GIS]\",\n",
    "                     \"[Scan]\",\n",
    "                     \"[EScan]\",\n",
    "                     \"[Stage]\",\n",
    "                     \"[Image]\",\n",
    "                     \"[Vacuum]\",\n",
    "                     \"[Specimen]\",\n",
    "                     \"[Detectors]\",\n",
    "                     \"[T2]\",\n",
    "                     \"[Accessories]\",\n",
    "                     \"[EBeamDeceleration]\",\n",
    "                     \"[CompoundLensFilter]\",\n",
    "                     \"[PrivateFei]\",\n",
    "                     \"[HiResIllumination]\",\n",
    "                     \"[EasyLift]\",\n",
    "                     \"[HotStageMEMS]\",\n",
    "                     \"[HotStage]\",\n",
    "                     \"[HotStageHVHS]\",\n",
    "                     \"[ColdStage]\"]\n",
    "\n",
    "tfs_section_details = {\"[System]\": [\"Type\", \"Dnumber\", \"Software\", \"BuildNr\", \"Source\", \"Column\", \"FinalLens\", \"Chamber\", \"Stage\", \"Pump\",\n",
    "              \"ESEM\", \"Aperture\", \"Scan\", \"Acq\", \"EucWD\", \"SystemType\", \"DisplayWidth\", \"DisplayHeight\"]}\n",
    "tfs_section_offsets = {}\n",
    "\n",
    "with open(fnm, 'rb', 0) as file:\n",
    "    s = mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "    for section_name in tfs_section_names:\n",
    "        pos = s.find(bytes(section_name, \"utf8\"))  # != -1\n",
    "        tfs_section_offsets[section_name] = pos\n",
    "    print(tfs_section_offsets)\n",
    "\n",
    "    # define search offsets\n",
    "    tpl = []\n",
    "    for key, value in tfs_section_offsets.items():\n",
    "        tpl.append((key, value))\n",
    "    # print(tpl)\n",
    "    tpl = sort_tuple(tpl)\n",
    "    print(tpl)\n",
    "    # if section_name == \"[System]\":\n",
    "    pos_s = None\n",
    "    pos_e = None\n",
    "    for idx in np.arange(0, len(tpl)):\n",
    "        if tpl[idx][0] != \"[System]\":\n",
    "            continue\n",
    "        else:\n",
    "            pos_s = tpl[idx][1]\n",
    "            if idx <= len(tpl) - 1:\n",
    "                pos_e = tpl[idx + 1][1]\n",
    "            break\n",
    "    print(f\"Search in between byte offsets {pos_s} and {pos_e}\")\n",
    "    # fish metadata of e.g. the system section\n",
    "    section_metadata = {}\n",
    "    for term in tfs_section_details[\"[System]\"]:\n",
    "        \n",
    "        s.seek(pos_s, 0)\n",
    "        pos = s.find(bytes(term, \"utf8\"))\n",
    "        if pos < pos_e:  # check if pos_e is None\n",
    "            s.seek(pos, 0)\n",
    "            section_metadata[f\"{term}\"] = f\"{s.readline().strip().decode('utf8').replace(f'{term}=', '')}\"\n",
    "            if if_str_represents_float(section_metadata[f\"{term}\"]) is True:\n",
    "                section_metadata[f\"{term}\"] = np.float64(section_metadata[f\"{term}\"])\n",
    "            elif section_metadata[f\"{term}\"].isdigit() is True:\n",
    "                section_metadata[f\"{term}\"] = np.int64(section_metadata[f\"{term}\"])\n",
    "            else:\n",
    "                pass\n",
    "            # print(f\"{term}, {pos}, {pos + len(term) + 1}\")\n",
    "    #        tfs_section_offswr\n",
    "    #        file.seek(pos, 0)  #\n",
    "    print(section_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3eb287-8f55-424c-a016-a07fc59f068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'2'.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1341e30-fcce-4a3d-a099-d342b8bbe318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
